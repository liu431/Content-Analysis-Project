{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DWMMsrgw2Gfi"
   },
   "source": [
    "# HM7_YIMIN LI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sZ9WACpa2nvM"
   },
   "source": [
    "## <span style=\"color:red\">*Exercise 1*</span>\n",
    "\n",
    "<span style=\"color:red\">Construct cells immediately below this that estimate a deep classification model with Keras (and LSTM) and also BERT in order to predict pre-established data labels relevant to your final project (as for week 3's homework). Which works better? Are the errors the same or different?\n",
    "\n",
    "<span style=\"color:red\">***Stretch***</span>: <span style=\"color:red\">Now alter the neural network by stacking network layers, adjusting the embedding dimension, compare its performance with your model above, and interpret why it might be different."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "u3PMNfsO2PYG"
   },
   "source": [
    "## 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "tYOHpSUZ8IAn",
    "outputId": "a4573cc4-2b5f-4dc0-bfe7-f5da9763d26e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found GPU at: /device:GPU:0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Get the GPU device name.\n",
    "device_name = tf.test.gpu_device_name()\n",
    "\n",
    "# The device name should look like the following:\n",
    "if device_name == '/device:GPU:0':\n",
    "    print('Found GPU at: {}'.format(device_name))\n",
    "else:\n",
    "    raise SystemError('GPU device not found')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "DZEP6GNH8MDd",
    "outputId": "c24b8b91-aab1-46a4-ebc8-beae9839e3bc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1 GPU(s) available.\n",
      "We will use the GPU: Tesla T4\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# If there's a GPU available...\n",
    "if torch.cuda.is_available():    \n",
    "\n",
    "    # Tell PyTorch to use the GPU.    \n",
    "    device = torch.device(\"cuda\")\n",
    "\n",
    "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
    "\n",
    "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
    "\n",
    "# If not...\n",
    "else:\n",
    "    print('No GPU available, using the CPU instead.')\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 772
    },
    "colab_type": "code",
    "id": "c1O9uipT86-p",
    "outputId": "af3520d0-4ea7-4ae3-f8df-4c1b28c56e73"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/22/97/7db72a0beef1825f82188a4b923e62a146271ac2ced7928baa4d47ef2467/transformers-2.9.1-py3-none-any.whl (641kB)\n",
      "\r",
      "\u001b[K     |▌                               | 10kB 23.7MB/s eta 0:00:01\r",
      "\u001b[K     |█                               | 20kB 30.2MB/s eta 0:00:01\r",
      "\u001b[K     |█▌                              | 30kB 34.7MB/s eta 0:00:01\r",
      "\u001b[K     |██                              | 40kB 30.6MB/s eta 0:00:01\r",
      "\u001b[K     |██▌                             | 51kB 13.8MB/s eta 0:00:01\r",
      "\u001b[K     |███                             | 61kB 12.8MB/s eta 0:00:01\r",
      "\u001b[K     |███▋                            | 71kB 12.4MB/s eta 0:00:01\r",
      "\u001b[K     |████                            | 81kB 12.6MB/s eta 0:00:01\r",
      "\u001b[K     |████▋                           | 92kB 12.0MB/s eta 0:00:01\r",
      "\u001b[K     |█████                           | 102kB 12.0MB/s eta 0:00:01\r",
      "\u001b[K     |█████▋                          | 112kB 12.0MB/s eta 0:00:01\r",
      "\u001b[K     |██████▏                         | 122kB 12.0MB/s eta 0:00:01\r",
      "\u001b[K     |██████▋                         | 133kB 12.0MB/s eta 0:00:01\r",
      "\u001b[K     |███████▏                        | 143kB 12.0MB/s eta 0:00:01\r",
      "\u001b[K     |███████▋                        | 153kB 12.0MB/s eta 0:00:01\r",
      "\u001b[K     |████████▏                       | 163kB 12.0MB/s eta 0:00:01\r",
      "\u001b[K     |████████▊                       | 174kB 12.0MB/s eta 0:00:01\r",
      "\u001b[K     |█████████▏                      | 184kB 12.0MB/s eta 0:00:01\r",
      "\u001b[K     |█████████▊                      | 194kB 12.0MB/s eta 0:00:01\r",
      "\u001b[K     |██████████▏                     | 204kB 12.0MB/s eta 0:00:01\r",
      "\u001b[K     |██████████▊                     | 215kB 12.0MB/s eta 0:00:01\r",
      "\u001b[K     |███████████▎                    | 225kB 12.0MB/s eta 0:00:01\r",
      "\u001b[K     |███████████▊                    | 235kB 12.0MB/s eta 0:00:01\r",
      "\u001b[K     |████████████▎                   | 245kB 12.0MB/s eta 0:00:01\r",
      "\u001b[K     |████████████▊                   | 256kB 12.0MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████▎                  | 266kB 12.0MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████▉                  | 276kB 12.0MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████▎                 | 286kB 12.0MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████▉                 | 296kB 12.0MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████▎                | 307kB 12.0MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████▉                | 317kB 12.0MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████▍               | 327kB 12.0MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████▉               | 337kB 12.0MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████▍              | 348kB 12.0MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████▉              | 358kB 12.0MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████▍             | 368kB 12.0MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████             | 378kB 12.0MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████▍            | 389kB 12.0MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████            | 399kB 12.0MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████▍           | 409kB 12.0MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████           | 419kB 12.0MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████▍          | 430kB 12.0MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████          | 440kB 12.0MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████▌         | 450kB 12.0MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████         | 460kB 12.0MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████▌        | 471kB 12.0MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████        | 481kB 12.0MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████▌       | 491kB 12.0MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████       | 501kB 12.0MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████▌      | 512kB 12.0MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████      | 522kB 12.0MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████▌     | 532kB 12.0MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████     | 542kB 12.0MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████▋    | 552kB 12.0MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████████    | 563kB 12.0MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████████▋   | 573kB 12.0MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████████   | 583kB 12.0MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████████▋  | 593kB 12.0MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████████▏ | 604kB 12.0MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████████▋ | 614kB 12.0MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████████▏| 624kB 12.0MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████████▋| 634kB 12.0MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████████████| 645kB 12.0MB/s \n",
      "\u001b[?25hRequirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.7)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.4)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n",
      "Collecting sacremoses\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
      "\u001b[K     |████████████████████████████████| 890kB 41.9MB/s \n",
      "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
      "Collecting sentencepiece\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/a4/d0a884c4300004a78cca907a6ff9a5e9fe4f090f5d95ab341c53d28cbc58/sentencepiece-0.1.91-cp36-cp36m-manylinux1_x86_64.whl (1.1MB)\n",
      "\u001b[K     |████████████████████████████████| 1.1MB 47.8MB/s \n",
      "\u001b[?25hCollecting tokenizers==0.7.0\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/14/e5/a26eb4716523808bb0a799fcfdceb6ebf77a18169d9591b2f46a9adb87d9/tokenizers-0.7.0-cp36-cp36m-manylinux1_x86_64.whl (3.8MB)\n",
      "\u001b[K     |████████████████████████████████| 3.8MB 49.4MB/s \n",
      "\u001b[?25hRequirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.9)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.4.5.1)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.12.0)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.15.1)\n",
      "Building wheels for collected packages: sacremoses\n",
      "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893260 sha256=123d320761ec02ca16138c4ea65a683f1d4e34071135cb324677fcf469c411d2\n",
      "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
      "Successfully built sacremoses\n",
      "Installing collected packages: sacremoses, sentencepiece, tokenizers, transformers\n",
      "Successfully installed sacremoses-0.0.43 sentencepiece-0.1.91 tokenizers-0.7.0 transformers-2.9.1\n",
      "Requirement already satisfied: keras in /usr/local/lib/python3.6/dist-packages (2.3.1)\n",
      "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from keras) (1.12.0)\n",
      "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras) (2.10.0)\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras) (3.13)\n",
      "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from keras) (1.0.8)\n",
      "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from keras) (1.1.2)\n",
      "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from keras) (1.18.4)\n",
      "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from keras) (1.4.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers\n",
    "!pip install keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PPGoFP-P89kO"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "5vhSpJD09O04",
    "outputId": "d5396764-b1b4-4e16-8856-b4445184df8a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ['KERAS_BACKEND'] = 'tensorflow'\n",
    "from keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2jRMjPJo9UHf"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import BertTokenizer, BertConfig\n",
    "from transformers import AdamW, BertForSequenceClassification\n",
    "from tqdm import tqdm, trange\n",
    "import pandas as pd\n",
    "import io\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 363
    },
    "colab_type": "code",
    "id": "vhzIa6Z_-SzS",
    "outputId": "d0555f51-ede8-47d9-ef4a-970cbb92cd04"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>overall</th>\n",
       "      <th>verified</th>\n",
       "      <th>reviewTime</th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>asin</th>\n",
       "      <th>reviewerName</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>summary</th>\n",
       "      <th>unixReviewTime</th>\n",
       "      <th>vote</th>\n",
       "      <th>style</th>\n",
       "      <th>image</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>True</td>\n",
       "      <td>10 17, 2015</td>\n",
       "      <td>A1HP7NVNPFMA4N</td>\n",
       "      <td>700026657</td>\n",
       "      <td>Ambrosia075</td>\n",
       "      <td>This game is a bit hard to get the hang of, bu...</td>\n",
       "      <td>but when you do it's great.</td>\n",
       "      <td>1445040000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>False</td>\n",
       "      <td>07 27, 2015</td>\n",
       "      <td>A1JGAP0185YJI6</td>\n",
       "      <td>700026657</td>\n",
       "      <td>travis</td>\n",
       "      <td>I played it a while but it was alright. The st...</td>\n",
       "      <td>But in spite of that it was fun, I liked it</td>\n",
       "      <td>1437955200</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "      <td>02 23, 2015</td>\n",
       "      <td>A1YJWEXHQBWK2B</td>\n",
       "      <td>700026657</td>\n",
       "      <td>Vincent G. Mezera</td>\n",
       "      <td>ok game.</td>\n",
       "      <td>Three Stars</td>\n",
       "      <td>1424649600</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>02 20, 2015</td>\n",
       "      <td>A2204E1TH211HT</td>\n",
       "      <td>700026657</td>\n",
       "      <td>Grandma KR</td>\n",
       "      <td>found the game a bit too complicated, not what...</td>\n",
       "      <td>Two Stars</td>\n",
       "      <td>1424390400</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>True</td>\n",
       "      <td>12 25, 2014</td>\n",
       "      <td>A2RF5B5H74JLPE</td>\n",
       "      <td>700026657</td>\n",
       "      <td>jon</td>\n",
       "      <td>great game, I love it and have played it since...</td>\n",
       "      <td>love this game</td>\n",
       "      <td>1419465600</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   overall  verified   reviewTime  ... vote style image\n",
       "0        5      True  10 17, 2015  ...  NaN   NaN   NaN\n",
       "1        4     False  07 27, 2015  ...  NaN   NaN   NaN\n",
       "2        3      True  02 23, 2015  ...  NaN   NaN   NaN\n",
       "3        2      True  02 20, 2015  ...  NaN   NaN   NaN\n",
       "4        5      True  12 25, 2014  ...  NaN   NaN   NaN\n",
       "\n",
       "[5 rows x 12 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "csv_url = \"https://raw.githubusercontent.com/minminfly68/Content-Analysis-2020/master/week-7/first5000.csv\"\n",
    "df = pd.read_csv(csv_url)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 127
    },
    "colab_type": "code",
    "id": "eLf_49Cm9eOS",
    "outputId": "44146c76-bc99-45b0-ba59-e5ec788f983b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5    3388\n",
       "4     880\n",
       "3     376\n",
       "1     192\n",
       "2     164\n",
       "Name: overall, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We try to predict based on text whether we can infer how much stars the reviewers might give\n",
    "# We manually label five stars = 1, others = 0\n",
    "df['overall'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "colab_type": "code",
    "id": "VKTDN0uO-BGT",
    "outputId": "2e003a26-f4f8-4087-aaad-147788e2b37c"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>reviewText</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>A1HP7NVNPFMA4N</td>\n",
       "      <td>This game is a bit hard to get the hang of, bu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>A1JGAP0185YJI6</td>\n",
       "      <td>I played it a while but it was alright. The st...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>A1YJWEXHQBWK2B</td>\n",
       "      <td>ok game.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>A2204E1TH211HT</td>\n",
       "      <td>found the game a bit too complicated, not what...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>A2RF5B5H74JLPE</td>\n",
       "      <td>great game, I love it and have played it since...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label      reviewerID                                         reviewText\n",
       "0      1  A1HP7NVNPFMA4N  This game is a bit hard to get the hang of, bu...\n",
       "1      0  A1JGAP0185YJI6  I played it a while but it was alright. The st...\n",
       "2      0  A1YJWEXHQBWK2B                                           ok game.\n",
       "3      0  A2204E1TH211HT  found the game a bit too complicated, not what...\n",
       "4      1  A2RF5B5H74JLPE  great game, I love it and have played it since..."
      ]
     },
     "execution_count": 9,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df[['overall', 'reviewerID', 'reviewText']]\n",
    "df['label'] = df.apply(lambda x: int(x['overall'] == 5), axis=1)\n",
    "df = df[['label', 'reviewerID', 'reviewText']]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VIP5k6hH-5J1"
   },
   "outputs": [],
   "source": [
    "# Create sentence and label lists\n",
    "sentences = df.reviewText.values\n",
    "\n",
    "# We need to add special tokens at the beginning and end of each sentence for BERT to work properly\n",
    "sentences = [\"[CLS] \" + sentence + \" [SEP]\" for sentence in sentences]\n",
    "labels = df.label.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 104,
     "referenced_widgets": [
      "a4accf8171d44d4880e4bd43819aa5d5",
      "e9e6f1a0b59f4fd280aa009f71be3c13",
      "45a711b337074edfa2d659bf79223403",
      "be79b6d5ba8a48a6bc1026dbc330a4c7",
      "042f2b5a25e943c9908f106b7b2f355a",
      "3b3a32d10f234ddf98ecfc3ada4a8a48",
      "81af3fbef12b401da6c9f0e4111a0479",
      "edcbe40bc41c41d4bcfc747baf0a4425"
     ]
    },
    "colab_type": "code",
    "id": "EcaLITZqAfff",
    "outputId": "8d1113e2-0446-4dc0-80fe-0075419bd398"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4accf8171d44d4880e4bd43819aa5d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=231508.0, style=ProgressStyle(descripti…"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tokenize the first sentence:\n",
      "['[CLS]', 'this', 'game', 'is', 'a', 'bit', 'hard', 'to', 'get', 'the', 'hang', 'of', ',', 'but', 'when', 'you', 'do', 'it', \"'\", 's', 'great', '.', '[SEP]']\n"
     ]
    }
   ],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n",
    "tokenized_texts = [tokenizer.tokenize(sent) for sent in sentences]\n",
    "print (\"Tokenize the first sentence:\")\n",
    "print (tokenized_texts[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lRt6Qc4LAk5E"
   },
   "outputs": [],
   "source": [
    "MAX_LEN = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "R2A16hmiAsYG"
   },
   "outputs": [],
   "source": [
    "input_ids = [tokenizer.convert_tokens_to_ids(x) for x in tokenized_texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ntYf1OEFAvC7"
   },
   "outputs": [],
   "source": [
    "# Pad our input tokens\n",
    "input_ids = pad_sequences(input_ids, maxlen=MAX_LEN, dtype=\"long\", truncating=\"post\", padding=\"post\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "y2zSCsZZA2rC"
   },
   "outputs": [],
   "source": [
    "# Create attention masks\n",
    "attention_masks = []\n",
    "\n",
    "# Create a mask of 1s for each token followed by 0s for padding\n",
    "for seq in input_ids:\n",
    "    seq_mask = [float(i>0) for i in seq]\n",
    "    attention_masks.append(seq_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Tewm-ZLYA5uh"
   },
   "outputs": [],
   "source": [
    "# Use train_test_split to split our data into train and validation sets for training\n",
    "train_inputs, validation_inputs, train_labels, validation_labels = train_test_split(input_ids, labels, \n",
    "                                                            random_state=2020, test_size=0.1)\n",
    "train_masks, validation_masks, _, _ = train_test_split(attention_masks, input_ids,\n",
    "                                             random_state=2020, test_size=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TOYC_NCyBClq"
   },
   "source": [
    "## Deep Neural Nets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MUk2h4ofA7Fd"
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM, Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oNqn0MelBFjx"
   },
   "outputs": [],
   "source": [
    "vocab_in_size = tokenizer.vocab_size\n",
    "embedding_dim = 32\n",
    "unit = 100\n",
    "no_labels = len(np.unique(train_labels))\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 274
    },
    "colab_type": "code",
    "id": "59DGUK2eBHu-",
    "outputId": "b20f77c2-3a1e-40f9-dae5-2bdb60bb1976"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 128, 32)           976704    \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 100)               53200     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 2)                 202       \n",
      "=================================================================\n",
      "Total params: 1,030,106\n",
      "Trainable params: 1,030,106\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_lstm = Sequential()\n",
    "model_lstm.add(Embedding(vocab_in_size, embedding_dim, input_length=MAX_LEN))\n",
    "model_lstm.add(LSTM(unit))\n",
    "model_lstm.add(Dense(no_labels, activation='softmax'))\n",
    "model_lstm.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model_lstm.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 384
    },
    "colab_type": "code",
    "id": "gtsgRgnoBJIU",
    "outputId": "788c3321-8e72-4ee0-ad4e-a1137a6bfffe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "4500/4500 [==============================] - 31s 7ms/step - loss: 0.6249 - accuracy: 0.6758\n",
      "Epoch 2/10\n",
      "4500/4500 [==============================] - 29s 6ms/step - loss: 0.6035 - accuracy: 0.6987\n",
      "Epoch 3/10\n",
      "4500/4500 [==============================] - 28s 6ms/step - loss: 0.5381 - accuracy: 0.7558\n",
      "Epoch 4/10\n",
      "4500/4500 [==============================] - 28s 6ms/step - loss: 0.6088 - accuracy: 0.6798\n",
      "Epoch 5/10\n",
      "4500/4500 [==============================] - 28s 6ms/step - loss: 0.5047 - accuracy: 0.7704\n",
      "Epoch 6/10\n",
      "4500/4500 [==============================] - 28s 6ms/step - loss: 0.5450 - accuracy: 0.7584\n",
      "Epoch 7/10\n",
      "4500/4500 [==============================] - 28s 6ms/step - loss: 0.4611 - accuracy: 0.8029\n",
      "Epoch 8/10\n",
      "4500/4500 [==============================] - 28s 6ms/step - loss: 0.4631 - accuracy: 0.8096\n",
      "Epoch 9/10\n",
      "4500/4500 [==============================] - 28s 6ms/step - loss: 0.4016 - accuracy: 0.8324\n",
      "Epoch 10/10\n",
      "4500/4500 [==============================] - 27s 6ms/step - loss: 0.3628 - accuracy: 0.8529\n"
     ]
    }
   ],
   "source": [
    "history_lstm = model_lstm.fit(train_inputs, train_labels, \n",
    "                              epochs=10,batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jwV23-jUBgDe"
   },
   "source": [
    "The General model (LSTM) performs fairly ok in our dataset but with quite great variance. It can predict good classification in around 67% - 85%. Adding one more layer is more time consuming, but based on my test on small dataset, it would not significantly influence our result."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YzYXClgQCKuB"
   },
   "source": [
    "## BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3qJTsvHOBOfN"
   },
   "outputs": [],
   "source": [
    "# Convert all of our data into torch tensors, the required datatype for our model\n",
    "train_inputs = torch.tensor(train_inputs)\n",
    "validation_inputs = torch.tensor(validation_inputs)\n",
    "train_labels = torch.tensor(train_labels)\n",
    "validation_labels = torch.tensor(validation_labels)\n",
    "train_masks = torch.tensor(train_masks)\n",
    "validation_masks = torch.tensor(validation_masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-Z5VhhjrCVxQ"
   },
   "outputs": [],
   "source": [
    "# Select a batch size for training. For fine-tuning BERT on a specific task, the authors recommend a batch size of 16 or 32\n",
    "batch_size = 32\n",
    "\n",
    "# Create an iterator of our data with torch DataLoader. This helps save on memory during training because, unlike a for loop, \n",
    "# with an iterator the entire dataset does not need to be loaded into memory\n",
    "\n",
    "train_data = TensorDataset(train_inputs, train_masks, train_labels)\n",
    "train_sampler = RandomSampler(train_data)\n",
    "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
    "\n",
    "validation_data = TensorDataset(validation_inputs, validation_masks, validation_labels)\n",
    "validation_sampler = SequentialSampler(validation_data)\n",
    "validation_dataloader = DataLoader(validation_data, sampler=validation_sampler, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "01249c2b1f104082b8070479e4043808",
      "5d27a0cf2a14477dad73e8b16c5eacbc",
      "bac88cf800394fe98399de3fbb86ea89",
      "b0f683c507c5439bbd8f6e211b752709",
      "a3c24acd4ce2402eab3a2d97c1c4f5ad",
      "79d2848613fc45b3bb2bc5578266a371",
      "fb48b20987db4618ac9b2e1437834e30",
      "2fcbd06b3cc9490b9ffee23acc3b5aa6",
      "d00b9b0a94274ad1a51ef8000939d56f",
      "3b69eeb18bc04a1b8950f4c143553c2d",
      "33ec2c6e4859464795d9dad4525bfa0c",
      "da721c98cbee469b8319e3a8bd206e9e",
      "3a75b77536714613afc59b048b5ac2ac",
      "6688ea7fa17546329b080db4a5a5b05a",
      "11f73023400f463dad2016e31445c5df",
      "10b558ce9fb546d8b815d746976cb518"
     ]
    },
    "colab_type": "code",
    "id": "-LuNQH0ZCXa-",
    "outputId": "7d9a3984-b2ac-410a-9f94-bd95360ee299"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01249c2b1f104082b8070479e4043808",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=433.0, style=ProgressStyle(description_…"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d00b9b0a94274ad1a51ef8000939d56f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=440473133.0, style=ProgressStyle(descri…"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 37,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=2)\n",
    "model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1jAd05j5CeP4"
   },
   "outputs": [],
   "source": [
    "param_optimizer = list(model.named_parameters())\n",
    "no_decay = ['bias', 'gamma', 'beta']\n",
    "optimizer_grouped_parameters = [\n",
    "    {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)],\n",
    "     'weight_decay_rate': 0.01},\n",
    "    {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)],\n",
    "     'weight_decay_rate': 0.0}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "x_zSMN9aClWk"
   },
   "outputs": [],
   "source": [
    "# This variable contains all of the hyperparemeter information our training loop needs\n",
    "optimizer = AdamW(model.parameters(),\n",
    "                  lr = 2e-5, # args.learning_rate - default is 5e-5, our notebook had 2e-5\n",
    "                  eps = 1e-8 # args.adam_epsilon  - default is 1e-8.\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YwnN0YLVCmrr"
   },
   "outputs": [],
   "source": [
    "from transformers import get_linear_schedule_with_warmup\n",
    "\n",
    "# Number of training epochs (authors recommend between 2 and 4)\n",
    "epochs = 4\n",
    "\n",
    "# Total number of training steps is number of batches * number of epochs.\n",
    "total_steps = len(train_dataloader) * epochs\n",
    "\n",
    "# Create the learning rate scheduler.\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
    "                                            num_warmup_steps = 0, # Default value in run_glue.py\n",
    "                                            num_training_steps = total_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iKam1qdyCoO2"
   },
   "outputs": [],
   "source": [
    "# Function to calculate the accuracy of our predictions vs labels\n",
    "def flat_accuracy(preds, labels):\n",
    "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
    "    labels_flat = labels.flatten()\n",
    "    return np.sum(pred_flat == labels_flat) / len(labels_flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wDLAiylICpbm"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import datetime\n",
    "\n",
    "def format_time(elapsed):\n",
    "    '''\n",
    "    Takes a time in seconds and returns a string hh:mm:ss\n",
    "    '''\n",
    "    # Round to the nearest second.\n",
    "    elapsed_rounded = int(round((elapsed)))\n",
    "    \n",
    "    # Format as hh:mm:ss\n",
    "    return str(datetime.timedelta(seconds=elapsed_rounded))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "IaII_T8lCq2V",
    "outputId": "d7faa54c-e56d-41a0-891e-b0c647b94e69"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======== Epoch 1 / 4 ========\n",
      "Training...\n",
      "  Batch    40  of    141.    Elapsed: 0:00:16.\n",
      "  Batch    80  of    141.    Elapsed: 0:00:31.\n",
      "  Batch   120  of    141.    Elapsed: 0:00:46.\n",
      "\n",
      "  Average training loss: 0.53\n",
      "  Training epcoh took: 0:00:54\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.78\n",
      "  Validation took: 0:00:02\n",
      "\n",
      "======== Epoch 2 / 4 ========\n",
      "Training...\n",
      "  Batch    40  of    141.    Elapsed: 0:00:15.\n",
      "  Batch    80  of    141.    Elapsed: 0:00:30.\n",
      "  Batch   120  of    141.    Elapsed: 0:00:45.\n",
      "\n",
      "  Average training loss: 0.40\n",
      "  Training epcoh took: 0:00:53\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.81\n",
      "  Validation took: 0:00:02\n",
      "\n",
      "======== Epoch 3 / 4 ========\n",
      "Training...\n",
      "  Batch    40  of    141.    Elapsed: 0:00:15.\n",
      "  Batch    80  of    141.    Elapsed: 0:00:30.\n",
      "  Batch   120  of    141.    Elapsed: 0:00:45.\n",
      "\n",
      "  Average training loss: 0.30\n",
      "  Training epcoh took: 0:00:53\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.80\n",
      "  Validation took: 0:00:02\n",
      "\n",
      "======== Epoch 4 / 4 ========\n",
      "Training...\n",
      "  Batch    40  of    141.    Elapsed: 0:00:15.\n",
      "  Batch    80  of    141.    Elapsed: 0:00:30.\n",
      "  Batch   120  of    141.    Elapsed: 0:00:45.\n",
      "\n",
      "  Average training loss: 0.22\n",
      "  Training epcoh took: 0:00:53\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.80\n",
      "  Validation took: 0:00:02\n",
      "\n",
      "Training complete!\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "# This training code is based on the `run_glue.py` script here:\n",
    "# https://github.com/huggingface/transformers/blob/5bfcd0485ece086ebcbed2d008813037968a9e58/examples/run_glue.py#L128\n",
    "\n",
    "# Set the seed value all over the place to make this reproducible.\n",
    "seed_val = 42\n",
    "\n",
    "random.seed(seed_val)\n",
    "np.random.seed(seed_val)\n",
    "torch.manual_seed(seed_val)\n",
    "torch.cuda.manual_seed_all(seed_val)\n",
    "\n",
    "# Store the average loss after each epoch so we can plot them.\n",
    "loss_values = []\n",
    "\n",
    "# For each epoch...\n",
    "for epoch_i in range(0, epochs):\n",
    "    \n",
    "    # ========================================\n",
    "    #               Training\n",
    "    # ========================================\n",
    "    \n",
    "    # Perform one full pass over the training set.\n",
    "\n",
    "    print(\"\")\n",
    "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
    "    print('Training...')\n",
    "\n",
    "    # Measure how long the training epoch takes.\n",
    "    t0 = time.time()\n",
    "\n",
    "    # Reset the total loss for this epoch.\n",
    "    total_loss = 0\n",
    "\n",
    "    # Put the model into training mode. Don't be mislead--the call to \n",
    "    # `train` just changes the *mode*, it doesn't *perform* the training.\n",
    "    # `dropout` and `batchnorm` layers behave differently during training\n",
    "    # vs. test (source: https://stackoverflow.com/questions/51433378/what-does-model-train-do-in-pytorch)\n",
    "    model.train()\n",
    "\n",
    "    # For each batch of training data...\n",
    "    for step, batch in enumerate(train_dataloader):\n",
    "\n",
    "        # Progress update every 40 batches.\n",
    "        if step % 40 == 0 and not step == 0:\n",
    "            # Calculate elapsed time in minutes.\n",
    "            elapsed = format_time(time.time() - t0)\n",
    "            \n",
    "            # Report progress.\n",
    "            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
    "\n",
    "        # Unpack this training batch from our dataloader. \n",
    "        #\n",
    "        # As we unpack the batch, we'll also copy each tensor to the GPU using the \n",
    "        # `to` method.\n",
    "        #\n",
    "        # `batch` contains three pytorch tensors:\n",
    "        #   [0]: input ids \n",
    "        #   [1]: attention masks\n",
    "        #   [2]: labels \n",
    "        b_input_ids = batch[0].to(device)\n",
    "        b_input_mask = batch[1].to(device)\n",
    "        b_labels = batch[2].to(device)\n",
    "\n",
    "        # Always clear any previously calculated gradients before performing a\n",
    "        # backward pass. PyTorch doesn't do this automatically because \n",
    "        # accumulating the gradients is \"convenient while training RNNs\". \n",
    "        # (source: https://stackoverflow.com/questions/48001598/why-do-we-need-to-call-zero-grad-in-pytorch)\n",
    "        model.zero_grad()        \n",
    "\n",
    "        # Perform a forward pass (evaluate the model on this training batch).\n",
    "        # This will return the loss (rather than the model output) because we\n",
    "        # have provided the `labels`.\n",
    "        # The documentation for this `model` function is here: \n",
    "        # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n",
    "        outputs = model(b_input_ids, \n",
    "                    token_type_ids=None, \n",
    "                    attention_mask=b_input_mask, \n",
    "                    labels=b_labels)\n",
    "        \n",
    "        # The call to `model` always returns a tuple, so we need to pull the \n",
    "        # loss value out of the tuple.\n",
    "        loss = outputs[0]\n",
    "\n",
    "        # Accumulate the training loss over all of the batches so that we can\n",
    "        # calculate the average loss at the end. `loss` is a Tensor containing a\n",
    "        # single value; the `.item()` function just returns the Python value \n",
    "        # from the tensor.\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        # Perform a backward pass to calculate the gradients.\n",
    "        loss.backward()\n",
    "\n",
    "        # Clip the norm of the gradients to 1.0.\n",
    "        # This is to help prevent the \"exploding gradients\" problem.\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "\n",
    "        # Update parameters and take a step using the computed gradient.\n",
    "        # The optimizer dictates the \"update rule\"--how the parameters are\n",
    "        # modified based on their gradients, the learning rate, etc.\n",
    "        optimizer.step()\n",
    "\n",
    "        # Update the learning rate.\n",
    "        scheduler.step()\n",
    "\n",
    "    # Calculate the average loss over the training data.\n",
    "    avg_train_loss = total_loss / len(train_dataloader)            \n",
    "    \n",
    "    # Store the loss value for plotting the learning curve.\n",
    "    loss_values.append(avg_train_loss)\n",
    "\n",
    "    print(\"\")\n",
    "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
    "    print(\"  Training epcoh took: {:}\".format(format_time(time.time() - t0)))\n",
    "        \n",
    "    # ========================================\n",
    "    #               Validation\n",
    "    # ========================================\n",
    "    # After the completion of each training epoch, measure our performance on\n",
    "    # our validation set.\n",
    "\n",
    "    print(\"\")\n",
    "    print(\"Running Validation...\")\n",
    "\n",
    "    t0 = time.time()\n",
    "\n",
    "    # Put the model in evaluation mode--the dropout layers behave differently\n",
    "    # during evaluation.\n",
    "    model.eval()\n",
    "\n",
    "    # Tracking variables \n",
    "    eval_loss, eval_accuracy = 0, 0\n",
    "    nb_eval_steps, nb_eval_examples = 0, 0\n",
    "\n",
    "    # Evaluate data for one epoch\n",
    "    for batch in validation_dataloader:\n",
    "        \n",
    "        # Add batch to GPU\n",
    "        batch = tuple(t.to(device) for t in batch)\n",
    "        \n",
    "        # Unpack the inputs from our dataloader\n",
    "        b_input_ids, b_input_mask, b_labels = batch\n",
    "        \n",
    "        # Telling the model not to compute or store gradients, saving memory and\n",
    "        # speeding up validation\n",
    "        with torch.no_grad():        \n",
    "\n",
    "            # Forward pass, calculate logit predictions.\n",
    "            # This will return the logits rather than the loss because we have\n",
    "            # not provided labels.\n",
    "            # token_type_ids is the same as the \"segment ids\", which \n",
    "            # differentiates sentence 1 and 2 in 2-sentence tasks.\n",
    "            # The documentation for this `model` function is here: \n",
    "            # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n",
    "            outputs = model(b_input_ids, \n",
    "                            token_type_ids=None, \n",
    "                            attention_mask=b_input_mask)\n",
    "        \n",
    "        # Get the \"logits\" output by the model. The \"logits\" are the output\n",
    "        # values prior to applying an activation function like the softmax.\n",
    "        logits = outputs[0]\n",
    "\n",
    "        # Move logits and labels to CPU\n",
    "        logits = logits.detach().cpu().numpy()\n",
    "        label_ids = b_labels.to('cpu').numpy()\n",
    "        \n",
    "        # Calculate the accuracy for this batch of test sentences.\n",
    "        tmp_eval_accuracy = flat_accuracy(logits, label_ids)\n",
    "        \n",
    "        # Accumulate the total accuracy.\n",
    "        eval_accuracy += tmp_eval_accuracy\n",
    "\n",
    "        # Track the number of batches\n",
    "        nb_eval_steps += 1\n",
    "\n",
    "    # Report the final accuracy for this validation run.\n",
    "    print(\"  Accuracy: {0:.2f}\".format(eval_accuracy/nb_eval_steps))\n",
    "    print(\"  Validation took: {:}\".format(format_time(time.time() - t0)))\n",
    "\n",
    "print(\"\")\n",
    "print(\"Training complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 90
    },
    "colab_type": "code",
    "id": "SkY8ykYHDdsi",
    "outputId": "a9b23c20-ee58-4640-dc38-69597c54060e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.5259505567398477,\n",
       " 0.39601450376476804,\n",
       " 0.29674616947453075,\n",
       " 0.22333387803312735]"
      ]
     },
     "execution_count": 44,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 427
    },
    "colab_type": "code",
    "id": "ByCre0kRCumm",
    "outputId": "a6595eb2-fb5b-4286-d0a1-c6859b524b0f"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "# Use plot styling from seaborn.\n",
    "sns.set(style='darkgrid')\n",
    "\n",
    "# Increase the plot size and font size.\n",
    "sns.set(font_scale=1.5)\n",
    "plt.rcParams[\"figure.figsize\"] = (12,6)\n",
    "\n",
    "# Plot the learning curve.\n",
    "plt.plot(loss_values, 'b-o')\n",
    "\n",
    "# Label the plot.\n",
    "plt.title(\"Training loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DUC878xBCyT_"
   },
   "source": [
    "As we can see from the data above, BERT performs similar with LSTM, with an accuracy rate at around 78-81% and its variance is smaller than LSTM. As graph shows above, as epoch number increases, the average training loss decreases, having better prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LV8jrzG4D5lC"
   },
   "source": [
    "## Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "eH5Y6TKkDWQl",
    "outputId": "e12e832f-b000-465a-ca1f-fbdd3d0d7a9f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (658 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (665 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (570 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (528 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (746 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1219 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (704 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of test sentences: 5,000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (520 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (642 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (566 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (631 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (593 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (991 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1539 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (650 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (535 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (551 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (908 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (622 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (753 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (593 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (665 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (572 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (801 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (899 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (569 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (743 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (604 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1025 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (798 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (823 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (714 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (834 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1609 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (613 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (703 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (748 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (787 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (876 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (629 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (540 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (546 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (619 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (770 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (615 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1151 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (4011 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (779 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (808 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (988 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1186 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1345 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (577 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (594 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1174 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (783 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1362 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1271 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (521 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1270 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (570 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1110 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (759 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (716 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1054 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (537 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (577 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (530 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (4271 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (916 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (645 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (792 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (656 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (588 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1078 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (523 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (679 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (775 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (737 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (619 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (718 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (633 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1170 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (570 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1690 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1193 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (526 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (548 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (2418 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (608 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (678 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (973 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (575 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (2460 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1194 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1070 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1260 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (767 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (725 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (578 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (592 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1221 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (616 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (764 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (581 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (714 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (527 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (616 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (777 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1309 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (542 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (714 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (558 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (568 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1190 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (957 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (574 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (843 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (571 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1250 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1258 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (613 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (609 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (524 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (607 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (683 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1195 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1672 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (592 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1096 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1518 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (659 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1199 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (928 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (665 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (783 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (516 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1765 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (754 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (585 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1928 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (805 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1256 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1111 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (790 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (778 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1027 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1541 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (654 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (565 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (771 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (552 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (770 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (607 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (576 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (512 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (638 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1059 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (614 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (598 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (728 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (541 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (534 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1408 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1629 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (603 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (970 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (782 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (878 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (534 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (656 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (597 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (836 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (524 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1940 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (564 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (784 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (646 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (527 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1361 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (569 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (714 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1015 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1379 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (524 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (667 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (730 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (702 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (812 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (611 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (544 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (525 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1531 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (879 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (511 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (4878 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1033 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (840 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1338 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1308 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (644 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (657 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (550 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (730 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1321 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (917 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (971 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (669 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1012 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (724 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1641 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (734 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (523 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1154 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1708 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1390 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1170 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (540 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (947 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (519 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1121 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (907 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (2058 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (707 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (647 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1230 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (735 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (728 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (753 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (664 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (540 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (644 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (881 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (723 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (706 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (919 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (521 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (550 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (621 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1577 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (911 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (658 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (754 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (696 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (776 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (794 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (567 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1005 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (768 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (627 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (782 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1148 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (538 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1634 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (952 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (866 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (666 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (728 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (582 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1652 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (751 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (543 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1859 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1187 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (524 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (578 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1392 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (539 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (771 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (747 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1362 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (777 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (599 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (906 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (736 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (647 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (725 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (857 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (513 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1279 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (592 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (740 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (515 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (597 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (956 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (519 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (546 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (681 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1312 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1511 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (991 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (632 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (632 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (774 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (583 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (577 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (712 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1594 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (828 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (993 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (562 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1209 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1052 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (982 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (619 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (987 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (816 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (927 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (758 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (552 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (624 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (636 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (565 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (550 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1177 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1085 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1131 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (549 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1204 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (622 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (830 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (592 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (995 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (2046 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (650 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (590 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (737 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (514 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (748 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (599 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (687 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (889 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1279 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (782 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (562 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (606 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (523 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (847 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (584 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (548 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1034 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (525 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (571 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (935 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (523 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (525 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (694 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (918 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (762 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1177 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (617 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (639 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (516 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (512 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (626 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (569 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (928 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (665 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (667 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (727 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (608 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (669 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (527 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (574 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (3630 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (647 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (917 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1222 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (890 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (522 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (523 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (743 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (560 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1291 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (664 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (984 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1076 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (614 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (551 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (581 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (569 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (716 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (805 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1039 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (870 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (611 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (819 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (567 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (903 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (700 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1250 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1133 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1552 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (970 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (717 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (683 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    }
   ],
   "source": [
    "# Report the number of sentences.\n",
    "print('Number of test sentences: {:,}\\n'.format(df.shape[0]))\n",
    "\n",
    "# Create sentence and label lists\n",
    "sentences = df.reviewText.values\n",
    "labels = df.label.values\n",
    "\n",
    "# Tokenize all of the sentences and map the tokens to thier word IDs.\n",
    "input_ids = []\n",
    "\n",
    "# For every sentence...\n",
    "for sent in sentences:\n",
    "    # `encode` will:\n",
    "    #   (1) Tokenize the sentence.\n",
    "    #   (2) Prepend the `[CLS]` token to the start.\n",
    "    #   (3) Append the `[SEP]` token to the end.\n",
    "    #   (4) Map tokens to their IDs.\n",
    "    encoded_sent = tokenizer.encode(\n",
    "                        sent,                      # Sentence to encode.\n",
    "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
    "                   )\n",
    "    \n",
    "    input_ids.append(encoded_sent)\n",
    "\n",
    "# Pad our input tokens\n",
    "input_ids = pad_sequences(input_ids, maxlen=MAX_LEN, \n",
    "                          dtype=\"long\", truncating=\"post\", padding=\"post\")\n",
    "\n",
    "# Create attention masks\n",
    "attention_masks = []\n",
    "\n",
    "# Create a mask of 1s for each token followed by 0s for padding\n",
    "for seq in input_ids:\n",
    "    seq_mask = [float(i>0) for i in seq]\n",
    "    attention_masks.append(seq_mask) \n",
    "\n",
    "# Convert to tensors.\n",
    "prediction_inputs = torch.tensor(input_ids)\n",
    "prediction_masks = torch.tensor(attention_masks)\n",
    "prediction_labels = torch.tensor(labels)\n",
    "\n",
    "# Set the batch size.  \n",
    "batch_size = 32  \n",
    "\n",
    "# Create the DataLoader.\n",
    "prediction_data = TensorDataset(prediction_inputs, prediction_masks, prediction_labels)\n",
    "prediction_sampler = SequentialSampler(prediction_data)\n",
    "prediction_dataloader = DataLoader(prediction_data, sampler=prediction_sampler, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "mJYFPbneD_8N",
    "outputId": "88c22183-2115-468d-a595-209c4bd28267"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting labels for 5,000 test sentences...\n",
      "    DONE.\n"
     ]
    }
   ],
   "source": [
    "# Prediction on test set\n",
    "\n",
    "print('Predicting labels for {:,} test sentences...'.format(len(prediction_inputs)))\n",
    "\n",
    "# Put model in evaluation mode\n",
    "model.eval()\n",
    "\n",
    "# Tracking variables \n",
    "predictions , true_labels = [], []\n",
    "\n",
    "# Predict \n",
    "for batch in prediction_dataloader:\n",
    "    # Add batch to GPU\n",
    "    batch = tuple(t.to(device) for t in batch)\n",
    "\n",
    "    # Unpack the inputs from our dataloader\n",
    "    b_input_ids, b_input_mask, b_labels = batch\n",
    "\n",
    "    # Telling the model not to compute or store gradients, saving memory and \n",
    "    # speeding up prediction\n",
    "    with torch.no_grad():\n",
    "      # Forward pass, calculate logit predictions\n",
    "      outputs = model(b_input_ids, token_type_ids=None, \n",
    "                      attention_mask=b_input_mask)\n",
    "\n",
    "    logits = outputs[0]\n",
    "\n",
    "    # Move logits and labels to CPU\n",
    "    logits = logits.detach().cpu().numpy()\n",
    "    label_ids = b_labels.to('cpu').numpy()\n",
    "\n",
    "    # Store predictions and true labels\n",
    "    predictions.append(logits)\n",
    "    true_labels.append(label_ids)\n",
    "\n",
    "print('    DONE.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "f_SRoxdqEyjF",
    "outputId": "0aefc4ec-90f9-4927-c374-edc52908d9e4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive samples: 3388 of 5000 (67.76%)\n"
     ]
    }
   ],
   "source": [
    "print('Positive samples: %d of %d (%.2f%%)' % (df.label.sum(), len(df.label), (df.label.sum() / len(df.label) * 100.0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "o0loDbF-E5nz",
    "outputId": "911b1cdc-2e0a-4811-9f1a-4caae8e5e573"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating Matthews Corr. Coef. for each batch...\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import matthews_corrcoef\n",
    "\n",
    "matthews_set = []\n",
    "\n",
    "# Evaluate each test batch using Matthew's correlation coefficient\n",
    "print('Calculating Matthews Corr. Coef. for each batch...')\n",
    "\n",
    "# For each input batch...\n",
    "for i in range(len(true_labels)):\n",
    "\n",
    "    # The predictions for this batch are a 2-column ndarray (one column for \"0\" \n",
    "    # and one column for \"1\"). Pick the label with the highest value and turn this\n",
    "    # in to a list of 0s and 1s.\n",
    "    pred_labels_i = np.argmax(predictions[i], axis=1).flatten()\n",
    "\n",
    "    # Calculate and store the coef for this batch.  \n",
    "    matthews = matthews_corrcoef(true_labels[i], pred_labels_i)                \n",
    "    matthews_set.append(matthews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "uU1xjQ_1E7Sf",
    "outputId": "dd4a94df-dd27-4288-e5fb-541cfac337ff"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MCC: 0.845\n"
     ]
    }
   ],
   "source": [
    "# Combine the predictions for each batch into a single list of 0s and 1s.\n",
    "flat_predictions = [item for sublist in predictions for item in sublist]\n",
    "flat_predictions = np.argmax(flat_predictions, axis=1).flatten()\n",
    "\n",
    "# Combine the correct labels for each batch into a single list.\n",
    "flat_true_labels = [item for sublist in true_labels for item in sublist]\n",
    "\n",
    "# Calculate the MCC\n",
    "mcc = matthews_corrcoef(flat_true_labels, flat_predictions)\n",
    "\n",
    "print('MCC: %.3f' % mcc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 90
    },
    "colab_type": "code",
    "id": "JPtkvC0TE-Jc",
    "outputId": "fc6b8324-d709-4653-f202-721db6b42903"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model to ./model_save/\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('./model_save/vocab.txt',\n",
       " './model_save/special_tokens_map.json',\n",
       " './model_save/added_tokens.json')"
      ]
     },
     "execution_count": 54,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Saving best-practices: if you use defaults names for the model, you can reload it using from_pretrained()\n",
    "\n",
    "output_dir = './model_save/'\n",
    "\n",
    "# Create output directory if needed\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "\n",
    "print(\"Saving model to %s\" % output_dir)\n",
    "\n",
    "# Save a trained model, configuration and tokenizer using `save_pretrained()`.\n",
    "# They can then be reloaded using `from_pretrained()`\n",
    "model_to_save = model.module if hasattr(model, 'module') else model  # Take care of distributed/parallel training\n",
    "model_to_save.save_pretrained(output_dir)\n",
    "tokenizer.save_pretrained(output_dir)\n",
    "\n",
    "# Good practice: save your training arguments together with the trained model\n",
    "# torch.save(args, os.path.join(output_dir, 'training_args.bin'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pg2MGCpAF1QX"
   },
   "source": [
    "As we can see, this model has MCC of 0.845, meaning excellent prediction in whether a model is a five-star comment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YfxS_bVKVMe_"
   },
   "source": [
    "The huggingface/transformers repository lists the other pipeline functions, such as ner extraction, sequence classification, and masking. You are encouraged to explore them. \n",
    "https://github.com/huggingface/transformers#quick-tour-of-pipelines\n",
    "\n",
    "## <span style=\"color:red\">*Exercise 2*</span>\n",
    "\n",
    "<span style=\"color:red\">In the cells immediately following, use the pipeline functions or the word or sentence vector functions (e.g., similarity) to explore the social game underlying the production and meaning of texts associated with your final project. You have used similar, but often weaker versions in previous weeks. How does BERT help you gain insight regarding your research question that is similar and different from prior methods?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mmyhofa6WHJa"
   },
   "source": [
    "## Embeddings, Context Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FR73_xxoVF-a"
   },
   "outputs": [],
   "source": [
    "from transformers import BertModel\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WCnpDa7-3HqP"
   },
   "outputs": [],
   "source": [
    "# Map the token strings to their vocabulary indeces.\n",
    "indexed_tokens = [tokenizer.convert_tokens_to_ids(text) for text in tokenized_texts]\n",
    "indexed_tokens = pad_sequences(indexed_tokens, maxlen=128, dtype=\"long\", truncating=\"post\", padding=\"post\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2PRU4GvK6MCN"
   },
   "source": [
    "## Segement ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qpu7-XdM6KoZ"
   },
   "outputs": [],
   "source": [
    "segment_ids = [100 * [1] for index in tokenized_texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AP_e9jjF6qef"
   },
   "outputs": [],
   "source": [
    "# Convert inputs to PyTorch tensors\n",
    "tokens_tensor = torch.tensor(indexed_tokens[:50])\n",
    "segments_tensors = torch.tensor(segment_ids[:50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "PQpZayPX6bIV",
    "outputId": "043d1a26-a472-4a9c-9d77-98bf1967b347"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertModel(\n",
       "  (embeddings): BertEmbeddings(\n",
       "    (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "    (position_embeddings): Embedding(512, 768)\n",
       "    (token_type_embeddings): Embedding(2, 768)\n",
       "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (encoder): BertEncoder(\n",
       "    (layer): ModuleList(\n",
       "      (0): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (1): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (2): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (3): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (4): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (5): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (6): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (7): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (8): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (9): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (10): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (11): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pooler): BertPooler(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (activation): Tanh()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load pre-trained model (weights)\n",
    "model_embedding = BertModel.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Put the model in \"evaluation\" mode, meaning feed-forward operation.\n",
    "model_embedding.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "P7TBhTqI7UvR"
   },
   "outputs": [],
   "source": [
    "output = model_embedding(tokens_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qLdf3jSL7gfl"
   },
   "source": [
    "## Understanding the Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "azgGZIeJ7dgx"
   },
   "outputs": [],
   "source": [
    "word_embeddings, sentence_embedding = output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 164
    },
    "colab_type": "code",
    "id": "rGs3orYH7orB",
    "outputId": "bf14b349-06d6-46e8-f02f-c5733224b4a5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.5190,  0.2969,  0.4654,  ..., -0.4119,  0.4396, -0.8465],\n",
       "        [-0.4679,  0.1030, -0.3807,  ..., -0.3009,  0.9709,  0.4252],\n",
       "        [ 0.0908, -0.7265,  0.5576,  ..., -0.3146,  0.1447,  0.1999],\n",
       "        ...,\n",
       "        [ 0.3638, -0.3650,  0.8420,  ..., -0.8527, -0.1828, -1.0350],\n",
       "        [ 0.3207, -0.1622,  0.8025,  ..., -0.8076, -0.3259, -1.0507],\n",
       "        [ 0.3537, -0.0855,  0.7437,  ..., -0.8039, -0.3248, -1.2958]],\n",
       "       grad_fn=<SelectBackward>)"
      ]
     },
     "execution_count": 18,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_embeddings[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 592
    },
    "colab_type": "code",
    "id": "VQgAcBrI7sNo",
    "outputId": "150bfba2-541b-4fbf-9e71-98a6f145901b"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "vec = word_embeddings[0][0]\n",
    "vec = vec.detach().numpy()\n",
    "# Plot the values as a histogram to show their distribution.\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.hist(vec, bins=200)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HnI0kvR970Tc"
   },
   "source": [
    "As is shown in the graph, the majority of values fall between [-1, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "l8cxXdhg8JEH"
   },
   "source": [
    "## Sentence Vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PaAbgR5_85BI"
   },
   "outputs": [],
   "source": [
    "token_vecs = []\n",
    "# For each token in the sentence...\n",
    "for embedding in word_embeddings[0]:\n",
    "    cat_vec = embedding.detach().numpy()\n",
    "    # Use `cat_vec` to represent `token`.\n",
    "    token_vecs.append(cat_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 439
    },
    "colab_type": "code",
    "id": "SqCDEpY_-ErS",
    "outputId": "6c58349f-afd5-4ffc-b568-2dbe217f1030"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 [CLS]\n",
      "1 this\n",
      "2 game\n",
      "3 is\n",
      "4 a\n",
      "5 bit\n",
      "6 hard\n",
      "7 to\n",
      "8 get\n",
      "9 the\n",
      "10 hang\n",
      "11 of\n",
      "12 ,\n",
      "13 but\n",
      "14 when\n",
      "15 you\n",
      "16 do\n",
      "17 it\n",
      "18 '\n",
      "19 s\n",
      "20 great\n",
      "21 .\n",
      "22 [SEP]\n"
     ]
    }
   ],
   "source": [
    "for i, token_str in enumerate(tokenized_texts[0]):\n",
    "    print(i, token_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 72
    },
    "colab_type": "code",
    "id": "LFHl7k-B9eHe",
    "outputId": "f46f8705-0eaf-4374-9888-8456434f89d5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "this game    [ 0.09082028 -0.7264875   0.5576084   0.03801588  0.17322066]\n",
      "bit hard   [-0.83949304 -0.10810888  0.43305808 -0.06664655 -0.7684753 ]\n"
     ]
    }
   ],
   "source": [
    "print('')\n",
    "print(\"this game   \", str(token_vecs[2][:5]))\n",
    "print(\"bit hard  \", str(token_vecs[6][:5]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0MolJAYX_E4o"
   },
   "source": [
    "## Transformers Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 67,
     "referenced_widgets": [
      "d95cfe0845c9467eb472a72fbdd1d007",
      "8855e8337a244f2d9a01b1c13fb6eb81",
      "4bac22afbde74b0396ac78cf1f1f977b",
      "73ddf68494f441ffaca15939d18c0b27",
      "840f0266b9894fac92754e194c9cd9c8",
      "02cf8709b60d4e78a5aaf02632c8bddf",
      "79749471cb584160908296eedbd0d8e9",
      "eaa71d7c8a8b4cceb6388ecd675eac92"
     ]
    },
    "colab_type": "code",
    "id": "uvJSKElJ90go",
    "outputId": "b5867e64-b53b-445e-c41a-851804dab8c0"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d95cfe0845c9467eb472a72fbdd1d007",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=230.0, style=ProgressStyle(description_…"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "# Allocate a pipeline for sentiment-analysis\n",
    "nlp_sentiment = pipeline('sentiment-analysis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "sF8Ie4P5_KDm",
    "outputId": "8565c203-dc65-4699-8180-59a395201012"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index 18 : Senetence is too long\n",
      "index 19 : Senetence is too long\n",
      "index 37 : Senetence is too long\n",
      "index 42 : Senetence is too long\n",
      "index 45 : Senetence is too long\n",
      "index 92 : Senetence is too long\n",
      "index 93 : Senetence is too long\n",
      "index 160 : Senetence is too long\n",
      "index 167 : Senetence is too long\n",
      "index 283 : Senetence is too long\n",
      "index 411 : Senetence is too long\n",
      "index 422 : Senetence is too long\n",
      "index 431 : Senetence is too long\n",
      "index 435 : Senetence is too long\n",
      "index 436 : Senetence is too long\n",
      "index 440 : Senetence is too long\n",
      "index 454 : Senetence is too long\n",
      "index 463 : Senetence is too long\n",
      "index 498 : Senetence is too long\n",
      "index 506 : Senetence is too long\n",
      "index 521 : Senetence is too long\n",
      "index 525 : Senetence is too long\n",
      "index 530 : Senetence is too long\n",
      "index 532 : Senetence is too long\n",
      "index 533 : Senetence is too long\n",
      "index 541 : Senetence is too long\n",
      "index 574 : Senetence is too long\n",
      "index 585 : Senetence is too long\n",
      "index 587 : Senetence is too long\n",
      "index 588 : Senetence is too long\n",
      "index 608 : Senetence is too long\n",
      "index 621 : Senetence is too long\n",
      "index 638 : Senetence is too long\n",
      "index 642 : Senetence is too long\n",
      "index 655 : Senetence is too long\n",
      "index 659 : Senetence is too long\n",
      "index 662 : Senetence is too long\n",
      "index 681 : Senetence is too long\n",
      "index 691 : Senetence is too long\n",
      "index 695 : Senetence is too long\n",
      "index 722 : Senetence is too long\n",
      "index 741 : Senetence is too long\n",
      "index 743 : Senetence is too long\n",
      "index 818 : Senetence is too long\n",
      "index 833 : Senetence is too long\n",
      "index 880 : Senetence is too long\n",
      "index 890 : Senetence is too long\n",
      "index 926 : Senetence is too long\n",
      "index 936 : Senetence is too long\n",
      "index 937 : Senetence is too long\n",
      "index 964 : Senetence is too long\n",
      "index 967 : Senetence is too long\n",
      "index 974 : Senetence is too long\n",
      "index 984 : Senetence is too long\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[{'label': 'POSITIVE', 'score': 0.9998044967651367}],\n",
       " [{'label': 'POSITIVE', 'score': 0.9994499683380127}],\n",
       " [{'label': 'POSITIVE', 'score': 0.9998160600662231}],\n",
       " [{'label': 'NEGATIVE', 'score': 0.9997512102127075}],\n",
       " [{'label': 'POSITIVE', 'score': 0.9998770356178284}]]"
      ]
     },
     "execution_count": 26,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sen_sentiment = [nlp_sentiment(sen2) for sen2 in sentences[:19]]\n",
    "\n",
    "sen_sentiment = []\n",
    "for i in range(1000):\n",
    "  try:\n",
    "    sen_sentiment.append(nlp_sentiment(sentences[i]))\n",
    "  except:\n",
    "    print(\"index {} : Senetence is too long\".format(i))\n",
    "sen_sentiment[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 283
    },
    "colab_type": "code",
    "id": "fN9hqBsr_xB8",
    "outputId": "2b01f369-97eb-411e-d151-d6ac2d6dd0aa"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fe59fb0d518>]"
      ]
     },
     "execution_count": 36,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "com_pos = []\n",
    "com_neg = []\n",
    "for i in range(len(sen_sentiment)):\n",
    "  if sen_sentiment[i][0]['label'] == 'POSITIVE':\n",
    "    com_pos.append(sen_sentiment[i][0]['score'])\n",
    "  else:\n",
    "    com_neg.append(-sen_sentiment[i][0]['score'])\n",
    "plt.plot(com_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 283
    },
    "colab_type": "code",
    "id": "SoYtFtA1_x24",
    "outputId": "02febede-4f0b-41b2-9d16-7e25a19d441f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fe59faeb278>]"
      ]
     },
     "execution_count": 37,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(com_neg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "t1YvhuLQCgVS"
   },
   "source": [
    "From the EDA Analysis above, we can see that around 750 sentences are positive while the remianing 250 is negative comments. We can also infer that those positive comments have much stronger sentimental score than the negative comments."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LS3ZjtE9HN5z"
   },
   "source": [
    "## <span style=\"color:red\">*Exercise 3*</span>\n",
    "\n",
    "<span style=\"color:red\">Construct cells immediately below this that generate a BERT-powered chatbot tuned on text related to your final project. What is interesting about this model, and how to does it compare to an untrained model? What does it reveal about the social game involved with your dataset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 218,
     "referenced_widgets": [
      "70bf5c6d20a7403c8e6d6bcf396cfa08",
      "0a483e7e6f9d49a78912b8b7b328f7c5",
      "44d4881aca074b5c92322887f716b6dc",
      "9f961d16dd3d428d8ab7213a44ca9a19",
      "808972de3dea43d0a42f3e84df3504f2",
      "3235bcdf3c004022ac25e5f396c7fbdf",
      "6cefd8a091254039a0f85bf7b16d5acc",
      "7ab8aaa2ad464f7eb8219e7368cd534e",
      "63ee95f98ea74604847d70e16caeaa1b",
      "3969ea90aed840d38c07c9c33b034908",
      "b4edeb281cc34d1ebdbf17915abd9a04",
      "c8e2d662c05042349743a4da60f43244",
      "e81d79ad57464ffa8d18e9f7aa683378",
      "d9c53452b7394f86ae5b0a3e43ccd7a5",
      "003c583e777045fe8d33b53388e385b2",
      "e65eb70f47fc4ec5b1c7fde7b3322c6a",
      "33e36b40eae74a3e9a045543a2c9a85b",
      "34cac1b3c51f46eb8a8ed854db59ecaf",
      "a32069ec91074400b67ff7ccdb4e2215",
      "ee56701c9b124abcbc1d3d60392276b0",
      "868b0da4ab814f7790691602dead75b2",
      "f2056f8965f34d10b17609bc40382ac8",
      "2c06611729e94f4f9fbeb66b0cd8fcbd",
      "22b7213535774d479039ee46ea322f08",
      "106ab26ceaab47d187a048fff0f942a6",
      "b764d725d93f412eb42a1899b7913487",
      "c06dec3f52f64b29919ec556f31cb820",
      "ffc7f9dfdb6d4bb5a3cc2ce368d9fcfe",
      "2a21231f5026438d949f5d3f00bae86d",
      "3e9653db57f144449df5f991a8d19e13",
      "ecb79234c3804aaea46daeae18df86a4",
      "3d2b64d475aa489eb57cb7ac602c7357"
     ]
    },
    "colab_type": "code",
    "id": "GFF2CUocFzTl",
    "outputId": "ae199fcc-9ba0-4fba-b84c-d0a6bdb3b967"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "70bf5c6d20a7403c8e6d6bcf396cfa08",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=665.0, style=ProgressStyle(description_…"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63ee95f98ea74604847d70e16caeaa1b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=1042301.0, style=ProgressStyle(descript…"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33e36b40eae74a3e9a045543a2c9a85b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=456318.0, style=ProgressStyle(descripti…"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "106ab26ceaab47d187a048fff0f942a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=548118077.0, style=ProgressStyle(descri…"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelWithLMHead, AutoTokenizer\n",
    "\n",
    "tokenizer_gpt = AutoTokenizer.from_pretrained(\"gpt2\")\n",
    "model_gpt = AutoModelWithLMHead.from_pretrained(\"gpt2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-1yx3sO9RpSG"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_text, test_text = train_test_split(df['reviewText'], test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Yos5HI7QU4Mu"
   },
   "outputs": [],
   "source": [
    "train_text.to_frame().to_csv(r'train_text', header=None, index=None, sep=' ', mode='a')\n",
    "test_text.to_frame().to_csv(r'test_text', header=None, index=None, sep=' ', mode='a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 127
    },
    "colab_type": "code",
    "id": "Qw8xiPRWRpZQ",
    "outputId": "c0a6a125-b4d3-4805-9344-be72ead590c6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1501    This game is great!!!!!!! I played a friends, ...\n",
       "2272                                           great game\n",
       "1777    I am a latecomer to Tenchu. Since it is a PS1 ...\n",
       "649     I have got to be honest even if it means sacki...\n",
       "3810    after the fantastic Saturn,  sega took a break...\n",
       "Name: reviewText, dtype: object"
      ]
     },
     "execution_count": 20,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_text.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7vSPvzefRpck"
   },
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "e-iii8X8RpgU",
    "outputId": "6c767379-15a1-475f-9ed2-e07c0ed3a921"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-05-22 03:01:23.188713: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
      "05/22/2020 03:01:24 - WARNING - __main__ -   Process rank: -1, device: cuda, n_gpu: 1, distributed training: False, 16-bits training: False\n",
      "05/22/2020 03:01:25 - INFO - transformers.configuration_utils -   loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-config.json from cache at /root/.cache/torch/transformers/4be02c5697d91738003fb1685c9872f284166aa32e061576bbe6aaeb95649fcf.db13c9bc9c7bdd738ec89e069621d88e05dc670366092d809a9cbcac6798e24e\n",
      "05/22/2020 03:01:25 - INFO - transformers.configuration_utils -   Model config GPT2Config {\n",
      "  \"activation_function\": \"gelu_new\",\n",
      "  \"architectures\": [\n",
      "    \"GPT2LMHeadModel\"\n",
      "  ],\n",
      "  \"attn_pdrop\": 0.1,\n",
      "  \"bos_token_id\": 50256,\n",
      "  \"embd_pdrop\": 0.1,\n",
      "  \"eos_token_id\": 50256,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"gpt2\",\n",
      "  \"n_ctx\": 1024,\n",
      "  \"n_embd\": 768,\n",
      "  \"n_head\": 12,\n",
      "  \"n_layer\": 12,\n",
      "  \"n_positions\": 1024,\n",
      "  \"resid_pdrop\": 0.1,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"cls_index\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"task_specific_params\": {\n",
      "    \"text-generation\": {\n",
      "      \"do_sample\": true,\n",
      "      \"max_length\": 50\n",
      "    }\n",
      "  },\n",
      "  \"vocab_size\": 50257\n",
      "}\n",
      "\n",
      "05/22/2020 03:01:27 - INFO - transformers.tokenization_utils -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-vocab.json from cache at /root/.cache/torch/transformers/f2808208f9bec2320371a9f5f891c184ae0b674ef866b79c58177067d15732dd.1512018be4ba4e8726e41b9145129dc30651ea4fec86aa61f4b9f40bf94eac71\n",
      "05/22/2020 03:01:27 - INFO - transformers.tokenization_utils -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-merges.txt from cache at /root/.cache/torch/transformers/d629f792e430b3c76a1291bb2766b0a047e36fae0588f9dbc1ae51decdff691b.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda\n",
      "05/22/2020 03:01:28 - INFO - transformers.modeling_utils -   loading weights file https://cdn.huggingface.co/gpt2-pytorch_model.bin from cache at /root/.cache/torch/transformers/d71fd633e58263bd5e91dd3bde9f658bafd81e11ece622be6a3c2e4d42d8fd89.778cf36f5c4e5d94c8cd9cefcf2a580c8643570eb327f0d4a1f007fab2acbdf1\n",
      "05/22/2020 03:01:32 - INFO - transformers.modeling_utils -   Weights of GPT2LMHeadModel not initialized from pretrained model: ['h.0.attn.masked_bias', 'h.1.attn.masked_bias', 'h.2.attn.masked_bias', 'h.3.attn.masked_bias', 'h.4.attn.masked_bias', 'h.5.attn.masked_bias', 'h.6.attn.masked_bias', 'h.7.attn.masked_bias', 'h.8.attn.masked_bias', 'h.9.attn.masked_bias', 'h.10.attn.masked_bias', 'h.11.attn.masked_bias', 'lm_head.weight']\n",
      "05/22/2020 03:01:37 - INFO - __main__ -   Training/evaluation parameters Namespace(adam_epsilon=1e-08, block_size=1024, cache_dir=None, config_name=None, device=device(type='cuda'), do_eval=True, do_train=True, eval_all_checkpoints=False, eval_data_file='test_text', evaluate_during_training=False, fp16=False, fp16_opt_level='O1', gradient_accumulation_steps=1, learning_rate=5e-05, line_by_line=False, local_rank=-1, logging_steps=500, max_grad_norm=1.0, max_steps=-1, mlm=False, mlm_probability=0.15, model_name_or_path='gpt2', model_type='gpt2', n_gpu=1, no_cuda=False, num_train_epochs=1.0, output_dir='output_gpt_text', overwrite_cache=False, overwrite_output_dir=False, per_gpu_eval_batch_size=1, per_gpu_train_batch_size=1, save_steps=500, save_total_limit=None, seed=42, server_ip='', server_port='', should_continue=False, tokenizer_name=None, train_data_file='train_text', warmup_steps=0, weight_decay=0.0)\n",
      "05/22/2020 03:01:37 - INFO - __main__ -   Creating features from dataset file at \n",
      "05/22/2020 03:01:40 - INFO - __main__ -   Saving features into cached file gpt2_cached_lm_1024_train_text\n",
      "05/22/2020 03:01:40 - INFO - __main__ -   ***** Running training *****\n",
      "05/22/2020 03:01:40 - INFO - __main__ -     Num examples = 699\n",
      "05/22/2020 03:01:40 - INFO - __main__ -     Num Epochs = 1\n",
      "05/22/2020 03:01:40 - INFO - __main__ -     Instantaneous batch size per GPU = 1\n",
      "05/22/2020 03:01:40 - INFO - __main__ -     Total train batch size (w. parallel, distributed & accumulation) = 1\n",
      "05/22/2020 03:01:40 - INFO - __main__ -     Gradient Accumulation steps = 1\n",
      "05/22/2020 03:01:40 - INFO - __main__ -     Total optimization steps = 699\n",
      "Epoch:   0% 0/1 [00:00<?, ?it/s]\n",
      "Iteration:   0% 0/699 [00:00<?, ?it/s]\u001b[A/pytorch/torch/csrc/utils/python_arg_parser.cpp:756: UserWarning: This overload of add_ is deprecated:\n",
      "\tadd_(Number alpha, Tensor other)\n",
      "Consider using one of the following signatures instead:\n",
      "\tadd_(Tensor other, *, Number alpha)\n",
      "\n",
      "Iteration:   0% 1/699 [00:00<08:12,  1.42it/s]\u001b[A\n",
      "Iteration:   0% 2/699 [00:01<07:03,  1.64it/s]\u001b[A\n",
      "Iteration:   0% 3/699 [00:01<06:17,  1.84it/s]\u001b[A\n",
      "Iteration:   1% 4/699 [00:01<05:50,  1.98it/s]\u001b[A\n",
      "Iteration:   1% 5/699 [00:02<05:26,  2.13it/s]\u001b[A\n",
      "Iteration:   1% 6/699 [00:02<05:12,  2.22it/s]\u001b[A\n",
      "Iteration:   1% 7/699 [00:03<05:01,  2.30it/s]\u001b[A\n",
      "Iteration:   1% 8/699 [00:03<04:52,  2.37it/s]\u001b[A\n",
      "Iteration:   1% 9/699 [00:03<04:48,  2.39it/s]\u001b[A\n",
      "Iteration:   1% 10/699 [00:04<04:44,  2.43it/s]\u001b[A\n",
      "Iteration:   2% 11/699 [00:04<04:40,  2.45it/s]\u001b[A\n",
      "Iteration:   2% 12/699 [00:05<04:39,  2.46it/s]\u001b[A\n",
      "Iteration:   2% 13/699 [00:05<04:37,  2.47it/s]\u001b[A\n",
      "Iteration:   2% 14/699 [00:05<04:37,  2.47it/s]\u001b[A\n",
      "Iteration:   2% 15/699 [00:06<04:36,  2.47it/s]\u001b[A\n",
      "Iteration:   2% 16/699 [00:06<04:35,  2.48it/s]\u001b[A\n",
      "Iteration:   2% 17/699 [00:07<04:35,  2.47it/s]\u001b[A\n",
      "Iteration:   3% 18/699 [00:07<04:35,  2.47it/s]\u001b[A\n",
      "Iteration:   3% 19/699 [00:07<04:35,  2.47it/s]\u001b[A\n",
      "Iteration:   3% 20/699 [00:08<04:35,  2.47it/s]\u001b[A\n",
      "Iteration:   3% 21/699 [00:08<04:34,  2.47it/s]\u001b[A\n",
      "Iteration:   3% 22/699 [00:09<04:34,  2.47it/s]\u001b[A\n",
      "Iteration:   3% 23/699 [00:09<04:33,  2.47it/s]\u001b[A\n",
      "Iteration:   3% 24/699 [00:09<04:33,  2.47it/s]\u001b[A\n",
      "Iteration:   4% 25/699 [00:10<04:33,  2.47it/s]\u001b[A\n",
      "Iteration:   4% 26/699 [00:10<04:33,  2.46it/s]\u001b[A\n",
      "Iteration:   4% 27/699 [00:11<04:32,  2.47it/s]\u001b[A\n",
      "Iteration:   4% 28/699 [00:11<04:31,  2.47it/s]\u001b[A\n",
      "Iteration:   4% 29/699 [00:11<04:30,  2.48it/s]\u001b[A\n",
      "Iteration:   4% 30/699 [00:12<04:30,  2.48it/s]\u001b[A\n",
      "Iteration:   4% 31/699 [00:12<04:30,  2.47it/s]\u001b[A\n",
      "Iteration:   5% 32/699 [00:13<04:28,  2.48it/s]\u001b[A\n",
      "Iteration:   5% 33/699 [00:13<04:29,  2.48it/s]\u001b[A\n",
      "Iteration:   5% 34/699 [00:13<04:28,  2.48it/s]\u001b[A\n",
      "Iteration:   5% 35/699 [00:14<04:28,  2.47it/s]\u001b[A\n",
      "Iteration:   5% 36/699 [00:14<04:27,  2.48it/s]\u001b[A\n",
      "Iteration:   5% 37/699 [00:15<04:27,  2.48it/s]\u001b[A\n",
      "Iteration:   5% 38/699 [00:15<04:27,  2.47it/s]\u001b[A\n",
      "Iteration:   6% 39/699 [00:16<04:27,  2.47it/s]\u001b[A\n",
      "Iteration:   6% 40/699 [00:16<04:26,  2.47it/s]\u001b[A\n",
      "Iteration:   6% 41/699 [00:16<04:27,  2.46it/s]\u001b[A\n",
      "Iteration:   6% 42/699 [00:17<04:26,  2.47it/s]\u001b[A\n",
      "Iteration:   6% 43/699 [00:17<04:26,  2.46it/s]\u001b[A\n",
      "Iteration:   6% 44/699 [00:18<04:26,  2.46it/s]\u001b[A\n",
      "Iteration:   6% 45/699 [00:18<04:26,  2.45it/s]\u001b[A\n",
      "Iteration:   7% 46/699 [00:18<04:27,  2.44it/s]\u001b[A\n",
      "Iteration:   7% 47/699 [00:19<04:26,  2.45it/s]\u001b[A\n",
      "Iteration:   7% 48/699 [00:19<04:26,  2.44it/s]\u001b[A\n",
      "Iteration:   7% 49/699 [00:20<04:26,  2.44it/s]\u001b[A\n",
      "Iteration:   7% 50/699 [00:20<04:25,  2.44it/s]\u001b[A\n",
      "Iteration:   7% 51/699 [00:20<04:26,  2.43it/s]\u001b[A\n",
      "Iteration:   7% 52/699 [00:21<04:25,  2.44it/s]\u001b[A\n",
      "Iteration:   8% 53/699 [00:21<04:26,  2.43it/s]\u001b[A\n",
      "Iteration:   8% 54/699 [00:22<04:25,  2.43it/s]\u001b[A\n",
      "Iteration:   8% 55/699 [00:22<04:25,  2.43it/s]\u001b[A\n",
      "Iteration:   8% 56/699 [00:22<04:25,  2.42it/s]\u001b[A\n",
      "Iteration:   8% 57/699 [00:23<04:24,  2.43it/s]\u001b[A\n",
      "Iteration:   8% 58/699 [00:23<04:24,  2.42it/s]\u001b[A\n",
      "Iteration:   8% 59/699 [00:24<04:24,  2.42it/s]\u001b[A\n",
      "Iteration:   9% 60/699 [00:24<04:24,  2.42it/s]\u001b[A\n",
      "Iteration:   9% 61/699 [00:25<04:24,  2.41it/s]\u001b[A\n",
      "Iteration:   9% 62/699 [00:25<04:23,  2.42it/s]\u001b[A\n",
      "Iteration:   9% 63/699 [00:25<04:23,  2.41it/s]\u001b[A\n",
      "Iteration:   9% 64/699 [00:26<04:23,  2.41it/s]\u001b[A\n",
      "Iteration:   9% 65/699 [00:26<04:23,  2.41it/s]\u001b[A\n",
      "Iteration:   9% 66/699 [00:27<04:22,  2.41it/s]\u001b[A\n",
      "Iteration:  10% 67/699 [00:27<04:22,  2.41it/s]\u001b[A\n",
      "Iteration:  10% 68/699 [00:27<04:22,  2.40it/s]\u001b[A\n",
      "Iteration:  10% 69/699 [00:28<04:22,  2.40it/s]\u001b[A\n",
      "Iteration:  10% 70/699 [00:28<04:22,  2.39it/s]\u001b[A\n",
      "Iteration:  10% 71/699 [00:29<04:22,  2.40it/s]\u001b[A\n",
      "Iteration:  10% 72/699 [00:29<04:21,  2.40it/s]\u001b[A\n",
      "Iteration:  10% 73/699 [00:30<04:21,  2.39it/s]\u001b[A\n",
      "Iteration:  11% 74/699 [00:30<04:21,  2.39it/s]\u001b[A\n",
      "Iteration:  11% 75/699 [00:30<04:22,  2.38it/s]\u001b[A\n",
      "Iteration:  11% 76/699 [00:31<04:21,  2.38it/s]\u001b[A\n",
      "Iteration:  11% 77/699 [00:31<04:21,  2.38it/s]\u001b[A\n",
      "Iteration:  11% 78/699 [00:32<04:20,  2.38it/s]\u001b[A\n",
      "Iteration:  11% 79/699 [00:32<04:21,  2.38it/s]\u001b[A\n",
      "Iteration:  11% 80/699 [00:32<04:20,  2.37it/s]\u001b[A\n",
      "Iteration:  12% 81/699 [00:33<04:21,  2.37it/s]\u001b[A\n",
      "Iteration:  12% 82/699 [00:33<04:20,  2.37it/s]\u001b[A\n",
      "Iteration:  12% 83/699 [00:34<04:19,  2.37it/s]\u001b[A\n",
      "Iteration:  12% 84/699 [00:34<04:19,  2.37it/s]\u001b[A\n",
      "Iteration:  12% 85/699 [00:35<04:19,  2.37it/s]\u001b[A\n",
      "Iteration:  12% 86/699 [00:35<04:19,  2.36it/s]\u001b[A\n",
      "Iteration:  12% 87/699 [00:35<04:19,  2.36it/s]\u001b[A\n",
      "Iteration:  13% 88/699 [00:36<04:19,  2.35it/s]\u001b[A\n",
      "Iteration:  13% 89/699 [00:36<04:18,  2.36it/s]\u001b[A\n",
      "Iteration:  13% 90/699 [00:37<04:18,  2.36it/s]\u001b[A\n",
      "Iteration:  13% 91/699 [00:37<04:18,  2.35it/s]\u001b[A\n",
      "Iteration:  13% 92/699 [00:38<04:18,  2.35it/s]\u001b[A\n",
      "Iteration:  13% 93/699 [00:38<04:16,  2.36it/s]\u001b[A\n",
      "Iteration:  13% 94/699 [00:38<04:16,  2.36it/s]\u001b[A\n",
      "Iteration:  14% 95/699 [00:39<04:16,  2.36it/s]\u001b[A\n",
      "Iteration:  14% 96/699 [00:39<04:15,  2.36it/s]\u001b[A\n",
      "Iteration:  14% 97/699 [00:40<04:16,  2.35it/s]\u001b[A\n",
      "Iteration:  14% 98/699 [00:40<04:15,  2.35it/s]\u001b[A\n",
      "Iteration:  14% 99/699 [00:41<04:15,  2.35it/s]\u001b[A\n",
      "Iteration:  14% 100/699 [00:41<04:14,  2.35it/s]\u001b[A\n",
      "Iteration:  14% 101/699 [00:41<04:13,  2.36it/s]\u001b[A\n",
      "Iteration:  15% 102/699 [00:42<04:13,  2.35it/s]\u001b[A\n",
      "Iteration:  15% 103/699 [00:42<04:13,  2.35it/s]\u001b[A\n",
      "Iteration:  15% 104/699 [00:43<04:13,  2.35it/s]\u001b[A\n",
      "Iteration:  15% 105/699 [00:43<04:12,  2.35it/s]\u001b[A\n",
      "Iteration:  15% 106/699 [00:44<04:11,  2.36it/s]\u001b[A\n",
      "Iteration:  15% 107/699 [00:44<04:11,  2.35it/s]\u001b[A\n",
      "Iteration:  15% 108/699 [00:44<04:11,  2.35it/s]\u001b[A\n",
      "Iteration:  16% 109/699 [00:45<04:10,  2.35it/s]\u001b[A\n",
      "Iteration:  16% 110/699 [00:45<04:09,  2.36it/s]\u001b[A\n",
      "Iteration:  16% 111/699 [00:46<04:09,  2.36it/s]\u001b[A\n",
      "Iteration:  16% 112/699 [00:46<04:08,  2.36it/s]\u001b[A\n",
      "Iteration:  16% 113/699 [00:47<04:08,  2.36it/s]\u001b[A\n",
      "Iteration:  16% 114/699 [00:47<04:08,  2.35it/s]\u001b[A\n",
      "Iteration:  16% 115/699 [00:47<04:08,  2.35it/s]\u001b[A\n",
      "Iteration:  17% 116/699 [00:48<04:07,  2.35it/s]\u001b[A\n",
      "Iteration:  17% 117/699 [00:48<04:07,  2.35it/s]\u001b[A\n",
      "Iteration:  17% 118/699 [00:49<04:07,  2.35it/s]\u001b[A\n",
      "Iteration:  17% 119/699 [00:49<04:06,  2.36it/s]\u001b[A\n",
      "Iteration:  17% 120/699 [00:49<04:05,  2.35it/s]\u001b[A\n",
      "Iteration:  17% 121/699 [00:50<04:05,  2.35it/s]\u001b[A\n",
      "Iteration:  17% 122/699 [00:50<04:04,  2.36it/s]\u001b[A\n",
      "Iteration:  18% 123/699 [00:51<04:04,  2.35it/s]\u001b[A\n",
      "Iteration:  18% 124/699 [00:51<04:03,  2.36it/s]\u001b[A\n",
      "Iteration:  18% 125/699 [00:52<04:02,  2.36it/s]\u001b[A\n",
      "Iteration:  18% 126/699 [00:52<04:02,  2.36it/s]\u001b[A\n",
      "Iteration:  18% 127/699 [00:52<04:01,  2.36it/s]\u001b[A\n",
      "Iteration:  18% 128/699 [00:53<04:01,  2.36it/s]\u001b[A\n",
      "Iteration:  18% 129/699 [00:53<04:01,  2.36it/s]\u001b[A\n",
      "Iteration:  19% 130/699 [00:54<04:01,  2.36it/s]\u001b[A\n",
      "Iteration:  19% 131/699 [00:54<04:00,  2.36it/s]\u001b[A\n",
      "Iteration:  19% 132/699 [00:55<04:00,  2.36it/s]\u001b[A\n",
      "Iteration:  19% 133/699 [00:55<03:59,  2.36it/s]\u001b[A\n",
      "Iteration:  19% 134/699 [00:55<03:59,  2.36it/s]\u001b[A\n",
      "Iteration:  19% 135/699 [00:56<03:59,  2.35it/s]\u001b[A\n",
      "Iteration:  19% 136/699 [00:56<03:59,  2.35it/s]\u001b[A\n",
      "Iteration:  20% 137/699 [00:57<03:58,  2.36it/s]\u001b[A\n",
      "Iteration:  20% 138/699 [00:57<03:57,  2.36it/s]\u001b[A\n",
      "Iteration:  20% 139/699 [00:58<03:56,  2.36it/s]\u001b[A\n",
      "Iteration:  20% 140/699 [00:58<03:56,  2.36it/s]\u001b[A\n",
      "Iteration:  20% 141/699 [00:58<03:55,  2.37it/s]\u001b[A\n",
      "Iteration:  20% 142/699 [00:59<03:54,  2.37it/s]\u001b[A\n",
      "Iteration:  20% 143/699 [00:59<03:54,  2.37it/s]\u001b[A\n",
      "Iteration:  21% 144/699 [01:00<03:54,  2.37it/s]\u001b[A\n",
      "Iteration:  21% 145/699 [01:00<03:53,  2.37it/s]\u001b[A\n",
      "Iteration:  21% 146/699 [01:00<03:53,  2.37it/s]\u001b[A\n",
      "Iteration:  21% 147/699 [01:01<03:53,  2.36it/s]\u001b[A\n",
      "Iteration:  21% 148/699 [01:01<03:52,  2.37it/s]\u001b[A\n",
      "Iteration:  21% 149/699 [01:02<03:52,  2.37it/s]\u001b[A\n",
      "Iteration:  21% 150/699 [01:02<03:51,  2.37it/s]\u001b[A\n",
      "Iteration:  22% 151/699 [01:03<03:51,  2.37it/s]\u001b[A\n",
      "Iteration:  22% 152/699 [01:03<03:50,  2.37it/s]\u001b[A\n",
      "Iteration:  22% 153/699 [01:03<03:49,  2.37it/s]\u001b[A\n",
      "Iteration:  22% 154/699 [01:04<03:49,  2.37it/s]\u001b[A\n",
      "Iteration:  22% 155/699 [01:04<03:49,  2.38it/s]\u001b[A\n",
      "Iteration:  22% 156/699 [01:05<03:48,  2.38it/s]\u001b[A\n",
      "Iteration:  22% 157/699 [01:05<03:47,  2.38it/s]\u001b[A\n",
      "Iteration:  23% 158/699 [01:06<03:47,  2.38it/s]\u001b[A\n",
      "Iteration:  23% 159/699 [01:06<03:47,  2.38it/s]\u001b[A\n",
      "Iteration:  23% 160/699 [01:06<03:46,  2.38it/s]\u001b[A\n",
      "Iteration:  23% 161/699 [01:07<03:46,  2.37it/s]\u001b[A\n",
      "Iteration:  23% 162/699 [01:07<03:45,  2.38it/s]\u001b[A\n",
      "Iteration:  23% 163/699 [01:08<03:45,  2.38it/s]\u001b[A\n",
      "Iteration:  23% 164/699 [01:08<03:44,  2.38it/s]\u001b[A\n",
      "Iteration:  24% 165/699 [01:08<03:43,  2.39it/s]\u001b[A\n",
      "Iteration:  24% 166/699 [01:09<03:43,  2.39it/s]\u001b[A\n",
      "Iteration:  24% 167/699 [01:09<03:42,  2.39it/s]\u001b[A\n",
      "Iteration:  24% 168/699 [01:10<03:42,  2.39it/s]\u001b[A\n",
      "Iteration:  24% 169/699 [01:10<03:42,  2.39it/s]\u001b[A\n",
      "Iteration:  24% 170/699 [01:11<03:41,  2.39it/s]\u001b[A\n",
      "Iteration:  24% 171/699 [01:11<03:41,  2.39it/s]\u001b[A\n",
      "Iteration:  25% 172/699 [01:11<03:40,  2.39it/s]\u001b[A\n",
      "Iteration:  25% 173/699 [01:12<03:40,  2.39it/s]\u001b[A\n",
      "Iteration:  25% 174/699 [01:12<03:39,  2.39it/s]\u001b[A\n",
      "Iteration:  25% 175/699 [01:13<03:39,  2.39it/s]\u001b[A\n",
      "Iteration:  25% 176/699 [01:13<03:38,  2.39it/s]\u001b[A\n",
      "Iteration:  25% 177/699 [01:13<03:38,  2.39it/s]\u001b[A\n",
      "Iteration:  25% 178/699 [01:14<03:37,  2.40it/s]\u001b[A\n",
      "Iteration:  26% 179/699 [01:14<03:36,  2.40it/s]\u001b[A\n",
      "Iteration:  26% 180/699 [01:15<03:36,  2.40it/s]\u001b[A\n",
      "Iteration:  26% 181/699 [01:15<03:36,  2.40it/s]\u001b[A\n",
      "Iteration:  26% 182/699 [01:16<03:35,  2.40it/s]\u001b[A\n",
      "Iteration:  26% 183/699 [01:16<03:35,  2.40it/s]\u001b[A\n",
      "Iteration:  26% 184/699 [01:16<03:35,  2.39it/s]\u001b[A\n",
      "Iteration:  26% 185/699 [01:17<03:34,  2.40it/s]\u001b[A\n",
      "Iteration:  27% 186/699 [01:17<03:33,  2.40it/s]\u001b[A\n",
      "Iteration:  27% 187/699 [01:18<03:33,  2.40it/s]\u001b[A\n",
      "Iteration:  27% 188/699 [01:18<03:32,  2.40it/s]\u001b[A\n",
      "Iteration:  27% 189/699 [01:18<03:32,  2.40it/s]\u001b[A\n",
      "Iteration:  27% 190/699 [01:19<03:31,  2.40it/s]\u001b[A\n",
      "Iteration:  27% 191/699 [01:19<03:31,  2.40it/s]\u001b[A\n",
      "Iteration:  27% 192/699 [01:20<03:31,  2.40it/s]\u001b[A\n",
      "Iteration:  28% 193/699 [01:20<03:30,  2.40it/s]\u001b[A\n",
      "Iteration:  28% 194/699 [01:21<03:30,  2.40it/s]\u001b[A\n",
      "Iteration:  28% 195/699 [01:21<03:29,  2.41it/s]\u001b[A\n",
      "Iteration:  28% 196/699 [01:21<03:29,  2.40it/s]\u001b[A\n",
      "Iteration:  28% 197/699 [01:22<03:28,  2.41it/s]\u001b[A\n",
      "Iteration:  28% 198/699 [01:22<03:27,  2.41it/s]\u001b[A\n",
      "Iteration:  28% 199/699 [01:23<03:27,  2.41it/s]\u001b[A\n",
      "Iteration:  29% 200/699 [01:23<03:26,  2.41it/s]\u001b[A\n",
      "Iteration:  29% 201/699 [01:23<03:26,  2.41it/s]\u001b[A\n",
      "Iteration:  29% 202/699 [01:24<03:25,  2.41it/s]\u001b[A\n",
      "Iteration:  29% 203/699 [01:24<03:25,  2.41it/s]\u001b[A\n",
      "Iteration:  29% 204/699 [01:25<03:25,  2.41it/s]\u001b[A\n",
      "Iteration:  29% 205/699 [01:25<03:24,  2.41it/s]\u001b[A\n",
      "Iteration:  29% 206/699 [01:26<03:24,  2.41it/s]\u001b[A\n",
      "Iteration:  30% 207/699 [01:26<03:24,  2.41it/s]\u001b[A\n",
      "Iteration:  30% 208/699 [01:26<03:23,  2.41it/s]\u001b[A\n",
      "Iteration:  30% 209/699 [01:27<03:24,  2.40it/s]\u001b[A\n",
      "Iteration:  30% 210/699 [01:27<03:22,  2.41it/s]\u001b[A\n",
      "Iteration:  30% 211/699 [01:28<03:23,  2.40it/s]\u001b[A\n",
      "Iteration:  30% 212/699 [01:28<03:22,  2.41it/s]\u001b[A\n",
      "Iteration:  30% 213/699 [01:28<03:22,  2.40it/s]\u001b[A\n",
      "Iteration:  31% 214/699 [01:29<03:22,  2.40it/s]\u001b[A\n",
      "Iteration:  31% 215/699 [01:29<03:21,  2.41it/s]\u001b[A\n",
      "Iteration:  31% 216/699 [01:30<03:21,  2.40it/s]\u001b[A\n",
      "Iteration:  31% 217/699 [01:30<03:20,  2.41it/s]\u001b[A\n",
      "Iteration:  31% 218/699 [01:31<03:19,  2.41it/s]\u001b[A\n",
      "Iteration:  31% 219/699 [01:31<03:19,  2.41it/s]\u001b[A\n",
      "Iteration:  31% 220/699 [01:31<03:18,  2.41it/s]\u001b[A\n",
      "Iteration:  32% 221/699 [01:32<03:18,  2.41it/s]\u001b[A\n",
      "Iteration:  32% 222/699 [01:32<03:17,  2.42it/s]\u001b[A\n",
      "Iteration:  32% 223/699 [01:33<03:17,  2.41it/s]\u001b[A\n",
      "Iteration:  32% 224/699 [01:33<03:16,  2.41it/s]\u001b[A\n",
      "Iteration:  32% 225/699 [01:33<03:16,  2.41it/s]\u001b[A\n",
      "Iteration:  32% 226/699 [01:34<03:16,  2.40it/s]\u001b[A\n",
      "Iteration:  32% 227/699 [01:34<03:15,  2.41it/s]\u001b[A\n",
      "Iteration:  33% 228/699 [01:35<03:15,  2.41it/s]\u001b[A\n",
      "Iteration:  33% 229/699 [01:35<03:15,  2.41it/s]\u001b[A\n",
      "Iteration:  33% 230/699 [01:36<03:14,  2.41it/s]\u001b[A\n",
      "Iteration:  33% 231/699 [01:36<03:14,  2.41it/s]\u001b[A\n",
      "Iteration:  33% 232/699 [01:36<03:13,  2.41it/s]\u001b[A\n",
      "Iteration:  33% 233/699 [01:37<03:13,  2.41it/s]\u001b[A\n",
      "Iteration:  33% 234/699 [01:37<03:12,  2.41it/s]\u001b[A\n",
      "Iteration:  34% 235/699 [01:38<03:12,  2.41it/s]\u001b[A\n",
      "Iteration:  34% 236/699 [01:38<03:11,  2.41it/s]\u001b[A\n",
      "Iteration:  34% 237/699 [01:38<03:11,  2.41it/s]\u001b[A\n",
      "Iteration:  34% 238/699 [01:39<03:11,  2.41it/s]\u001b[A\n",
      "Iteration:  34% 239/699 [01:39<03:10,  2.41it/s]\u001b[A\n",
      "Iteration:  34% 240/699 [01:40<03:10,  2.42it/s]\u001b[A\n",
      "Iteration:  34% 241/699 [01:40<03:10,  2.41it/s]\u001b[A\n",
      "Iteration:  35% 242/699 [01:40<03:09,  2.41it/s]\u001b[A\n",
      "Iteration:  35% 243/699 [01:41<03:09,  2.41it/s]\u001b[A\n",
      "Iteration:  35% 244/699 [01:41<03:08,  2.41it/s]\u001b[A\n",
      "Iteration:  35% 245/699 [01:42<03:08,  2.41it/s]\u001b[A\n",
      "Iteration:  35% 246/699 [01:42<03:07,  2.41it/s]\u001b[A\n",
      "Iteration:  35% 247/699 [01:43<03:07,  2.41it/s]\u001b[A\n",
      "Iteration:  35% 248/699 [01:43<03:07,  2.41it/s]\u001b[A\n",
      "Iteration:  36% 249/699 [01:43<03:07,  2.40it/s]\u001b[A\n",
      "Iteration:  36% 250/699 [01:44<03:06,  2.41it/s]\u001b[A\n",
      "Iteration:  36% 251/699 [01:44<03:06,  2.40it/s]\u001b[A\n",
      "Iteration:  36% 252/699 [01:45<03:05,  2.41it/s]\u001b[A\n",
      "Iteration:  36% 253/699 [01:45<03:05,  2.40it/s]\u001b[A\n",
      "Iteration:  36% 254/699 [01:45<03:05,  2.40it/s]\u001b[A\n",
      "Iteration:  36% 255/699 [01:46<03:04,  2.40it/s]\u001b[A\n",
      "Iteration:  37% 256/699 [01:46<03:04,  2.41it/s]\u001b[A\n",
      "Iteration:  37% 257/699 [01:47<03:03,  2.41it/s]\u001b[A\n",
      "Iteration:  37% 258/699 [01:47<03:03,  2.40it/s]\u001b[A\n",
      "Iteration:  37% 259/699 [01:48<03:02,  2.40it/s]\u001b[A\n",
      "Iteration:  37% 260/699 [01:48<03:02,  2.41it/s]\u001b[A\n",
      "Iteration:  37% 261/699 [01:48<03:01,  2.41it/s]\u001b[A\n",
      "Iteration:  37% 262/699 [01:49<03:01,  2.41it/s]\u001b[A\n",
      "Iteration:  38% 263/699 [01:49<03:01,  2.41it/s]\u001b[A\n",
      "Iteration:  38% 264/699 [01:50<03:01,  2.40it/s]\u001b[A\n",
      "Iteration:  38% 265/699 [01:50<03:00,  2.40it/s]\u001b[A\n",
      "Iteration:  38% 266/699 [01:50<03:00,  2.40it/s]\u001b[A\n",
      "Iteration:  38% 267/699 [01:51<02:59,  2.40it/s]\u001b[A\n",
      "Iteration:  38% 268/699 [01:51<02:59,  2.40it/s]\u001b[A\n",
      "Iteration:  38% 269/699 [01:52<02:58,  2.40it/s]\u001b[A\n",
      "Iteration:  39% 270/699 [01:52<02:58,  2.40it/s]\u001b[A\n",
      "Iteration:  39% 271/699 [01:53<02:58,  2.39it/s]\u001b[A\n",
      "Iteration:  39% 272/699 [01:53<02:57,  2.40it/s]\u001b[A\n",
      "Iteration:  39% 273/699 [01:53<02:57,  2.39it/s]\u001b[A\n",
      "Iteration:  39% 274/699 [01:54<02:57,  2.40it/s]\u001b[A\n",
      "Iteration:  39% 275/699 [01:54<02:56,  2.40it/s]\u001b[A\n",
      "Iteration:  39% 276/699 [01:55<02:56,  2.40it/s]\u001b[A\n",
      "Iteration:  40% 277/699 [01:55<02:55,  2.40it/s]\u001b[A\n",
      "Iteration:  40% 278/699 [01:55<02:56,  2.39it/s]\u001b[A\n",
      "Iteration:  40% 279/699 [01:56<02:55,  2.40it/s]\u001b[A\n",
      "Iteration:  40% 280/699 [01:56<02:55,  2.39it/s]\u001b[A\n",
      "Iteration:  40% 281/699 [01:57<02:54,  2.40it/s]\u001b[A\n",
      "Iteration:  40% 282/699 [01:57<02:53,  2.40it/s]\u001b[A\n",
      "Iteration:  40% 283/699 [01:58<02:53,  2.40it/s]\u001b[A\n",
      "Iteration:  41% 284/699 [01:58<02:52,  2.40it/s]\u001b[A\n",
      "Iteration:  41% 285/699 [01:58<02:53,  2.39it/s]\u001b[A\n",
      "Iteration:  41% 286/699 [01:59<02:52,  2.40it/s]\u001b[A\n",
      "Iteration:  41% 287/699 [01:59<02:52,  2.39it/s]\u001b[A\n",
      "Iteration:  41% 288/699 [02:00<02:51,  2.40it/s]\u001b[A\n",
      "Iteration:  41% 289/699 [02:00<02:51,  2.40it/s]\u001b[A\n",
      "Iteration:  41% 290/699 [02:00<02:51,  2.39it/s]\u001b[A\n",
      "Iteration:  42% 291/699 [02:01<02:50,  2.40it/s]\u001b[A\n",
      "Iteration:  42% 292/699 [02:01<02:50,  2.39it/s]\u001b[A\n",
      "Iteration:  42% 293/699 [02:02<02:49,  2.40it/s]\u001b[A\n",
      "Iteration:  42% 294/699 [02:02<02:49,  2.39it/s]\u001b[A\n",
      "Iteration:  42% 295/699 [02:03<02:48,  2.39it/s]\u001b[A\n",
      "Iteration:  42% 296/699 [02:03<02:48,  2.40it/s]\u001b[A\n",
      "Iteration:  42% 297/699 [02:03<02:48,  2.39it/s]\u001b[A\n",
      "Iteration:  43% 298/699 [02:04<02:47,  2.40it/s]\u001b[A\n",
      "Iteration:  43% 299/699 [02:04<02:46,  2.40it/s]\u001b[A\n",
      "Iteration:  43% 300/699 [02:05<02:46,  2.39it/s]\u001b[A\n",
      "Iteration:  43% 301/699 [02:05<02:46,  2.39it/s]\u001b[A\n",
      "Iteration:  43% 302/699 [02:06<02:46,  2.38it/s]\u001b[A\n",
      "Iteration:  43% 303/699 [02:06<02:45,  2.39it/s]\u001b[A\n",
      "Iteration:  43% 304/699 [02:06<02:45,  2.39it/s]\u001b[A\n",
      "Iteration:  44% 305/699 [02:07<02:44,  2.39it/s]\u001b[A\n",
      "Iteration:  44% 306/699 [02:07<02:44,  2.39it/s]\u001b[A\n",
      "Iteration:  44% 307/699 [02:08<02:44,  2.39it/s]\u001b[A\n",
      "Iteration:  44% 308/699 [02:08<02:43,  2.40it/s]\u001b[A\n",
      "Iteration:  44% 309/699 [02:08<02:43,  2.39it/s]\u001b[A\n",
      "Iteration:  44% 310/699 [02:09<02:42,  2.40it/s]\u001b[A\n",
      "Iteration:  44% 311/699 [02:09<02:42,  2.39it/s]\u001b[A\n",
      "Iteration:  45% 312/699 [02:10<02:41,  2.39it/s]\u001b[A\n",
      "Iteration:  45% 313/699 [02:10<02:41,  2.40it/s]\u001b[A\n",
      "Iteration:  45% 314/699 [02:11<02:41,  2.38it/s]\u001b[A\n",
      "Iteration:  45% 315/699 [02:11<02:40,  2.39it/s]\u001b[A\n",
      "Iteration:  45% 316/699 [02:11<02:40,  2.38it/s]\u001b[A\n",
      "Iteration:  45% 317/699 [02:12<02:39,  2.39it/s]\u001b[A\n",
      "Iteration:  45% 318/699 [02:12<02:39,  2.39it/s]\u001b[A\n",
      "Iteration:  46% 319/699 [02:13<02:38,  2.39it/s]\u001b[A\n",
      "Iteration:  46% 320/699 [02:13<02:38,  2.39it/s]\u001b[A\n",
      "Iteration:  46% 321/699 [02:13<02:38,  2.39it/s]\u001b[A\n",
      "Iteration:  46% 322/699 [02:14<02:37,  2.39it/s]\u001b[A\n",
      "Iteration:  46% 323/699 [02:14<02:37,  2.39it/s]\u001b[A\n",
      "Iteration:  46% 324/699 [02:15<02:37,  2.39it/s]\u001b[A\n",
      "Iteration:  46% 325/699 [02:15<02:36,  2.39it/s]\u001b[A\n",
      "Iteration:  47% 326/699 [02:16<02:36,  2.39it/s]\u001b[A\n",
      "Iteration:  47% 327/699 [02:16<02:35,  2.39it/s]\u001b[A\n",
      "Iteration:  47% 328/699 [02:16<02:35,  2.39it/s]\u001b[A\n",
      "Iteration:  47% 329/699 [02:17<02:35,  2.38it/s]\u001b[A\n",
      "Iteration:  47% 330/699 [02:17<02:34,  2.38it/s]\u001b[A\n",
      "Iteration:  47% 331/699 [02:18<02:34,  2.38it/s]\u001b[A\n",
      "Iteration:  47% 332/699 [02:18<02:33,  2.39it/s]\u001b[A\n",
      "Iteration:  48% 333/699 [02:18<02:33,  2.39it/s]\u001b[A\n",
      "Iteration:  48% 334/699 [02:19<02:32,  2.39it/s]\u001b[A\n",
      "Iteration:  48% 335/699 [02:19<02:32,  2.39it/s]\u001b[A\n",
      "Iteration:  48% 336/699 [02:20<02:32,  2.39it/s]\u001b[A\n",
      "Iteration:  48% 337/699 [02:20<02:31,  2.39it/s]\u001b[A\n",
      "Iteration:  48% 338/699 [02:21<02:31,  2.38it/s]\u001b[A\n",
      "Iteration:  48% 339/699 [02:21<02:30,  2.39it/s]\u001b[A\n",
      "Iteration:  49% 340/699 [02:21<02:30,  2.39it/s]\u001b[A\n",
      "Iteration:  49% 341/699 [02:22<02:30,  2.38it/s]\u001b[A\n",
      "Iteration:  49% 342/699 [02:22<02:29,  2.39it/s]\u001b[A\n",
      "Iteration:  49% 343/699 [02:23<02:29,  2.38it/s]\u001b[A\n",
      "Iteration:  49% 344/699 [02:23<02:28,  2.39it/s]\u001b[A\n",
      "Iteration:  49% 345/699 [02:24<02:28,  2.39it/s]\u001b[A\n",
      "Iteration:  49% 346/699 [02:24<02:28,  2.38it/s]\u001b[A\n",
      "Iteration:  50% 347/699 [02:24<02:27,  2.38it/s]\u001b[A\n",
      "Iteration:  50% 348/699 [02:25<02:27,  2.38it/s]\u001b[A\n",
      "Iteration:  50% 349/699 [02:25<02:26,  2.38it/s]\u001b[A\n",
      "Iteration:  50% 350/699 [02:26<02:26,  2.38it/s]\u001b[A\n",
      "Iteration:  50% 351/699 [02:26<02:25,  2.38it/s]\u001b[A\n",
      "Iteration:  50% 352/699 [02:26<02:25,  2.38it/s]\u001b[A\n",
      "Iteration:  51% 353/699 [02:27<02:25,  2.38it/s]\u001b[A\n",
      "Iteration:  51% 354/699 [02:27<02:24,  2.39it/s]\u001b[A\n",
      "Iteration:  51% 355/699 [02:28<02:24,  2.38it/s]\u001b[A\n",
      "Iteration:  51% 356/699 [02:28<02:24,  2.38it/s]\u001b[A\n",
      "Iteration:  51% 357/699 [02:29<02:23,  2.38it/s]\u001b[A\n",
      "Iteration:  51% 358/699 [02:29<02:23,  2.38it/s]\u001b[A\n",
      "Iteration:  51% 359/699 [02:29<02:22,  2.38it/s]\u001b[A\n",
      "Iteration:  52% 360/699 [02:30<02:22,  2.38it/s]\u001b[A\n",
      "Iteration:  52% 361/699 [02:30<02:21,  2.38it/s]\u001b[A\n",
      "Iteration:  52% 362/699 [02:31<02:21,  2.38it/s]\u001b[A\n",
      "Iteration:  52% 363/699 [02:31<02:20,  2.38it/s]\u001b[A\n",
      "Iteration:  52% 364/699 [02:31<02:20,  2.39it/s]\u001b[A\n",
      "Iteration:  52% 365/699 [02:32<02:19,  2.39it/s]\u001b[A\n",
      "Iteration:  52% 366/699 [02:32<02:19,  2.39it/s]\u001b[A\n",
      "Iteration:  53% 367/699 [02:33<02:19,  2.38it/s]\u001b[A\n",
      "Iteration:  53% 368/699 [02:33<02:18,  2.38it/s]\u001b[A\n",
      "Iteration:  53% 369/699 [02:34<02:18,  2.38it/s]\u001b[A\n",
      "Iteration:  53% 370/699 [02:34<02:17,  2.39it/s]\u001b[A\n",
      "Iteration:  53% 371/699 [02:34<02:17,  2.39it/s]\u001b[A\n",
      "Iteration:  53% 372/699 [02:35<02:17,  2.38it/s]\u001b[A\n",
      "Iteration:  53% 373/699 [02:35<02:16,  2.39it/s]\u001b[A\n",
      "Iteration:  54% 374/699 [02:36<02:16,  2.38it/s]\u001b[A\n",
      "Iteration:  54% 375/699 [02:36<02:16,  2.38it/s]\u001b[A\n",
      "Iteration:  54% 376/699 [02:37<02:15,  2.38it/s]\u001b[A\n",
      "Iteration:  54% 377/699 [02:37<02:15,  2.38it/s]\u001b[A\n",
      "Iteration:  54% 378/699 [02:37<02:14,  2.39it/s]\u001b[A\n",
      "Iteration:  54% 379/699 [02:38<02:14,  2.38it/s]\u001b[A\n",
      "Iteration:  54% 380/699 [02:38<02:13,  2.39it/s]\u001b[A\n",
      "Iteration:  55% 381/699 [02:39<02:13,  2.38it/s]\u001b[A\n",
      "Iteration:  55% 382/699 [02:39<02:13,  2.38it/s]\u001b[A\n",
      "Iteration:  55% 383/699 [02:39<02:12,  2.38it/s]\u001b[A\n",
      "Iteration:  55% 384/699 [02:40<02:12,  2.38it/s]\u001b[A\n",
      "Iteration:  55% 385/699 [02:40<02:11,  2.38it/s]\u001b[A\n",
      "Iteration:  55% 386/699 [02:41<02:11,  2.38it/s]\u001b[A\n",
      "Iteration:  55% 387/699 [02:41<02:10,  2.39it/s]\u001b[A\n",
      "Iteration:  56% 388/699 [02:42<02:09,  2.39it/s]\u001b[A\n",
      "Iteration:  56% 389/699 [02:42<02:09,  2.39it/s]\u001b[A\n",
      "Iteration:  56% 390/699 [02:42<02:09,  2.39it/s]\u001b[A\n",
      "Iteration:  56% 391/699 [02:43<02:09,  2.38it/s]\u001b[A\n",
      "Iteration:  56% 392/699 [02:43<02:08,  2.39it/s]\u001b[A\n",
      "Iteration:  56% 393/699 [02:44<02:08,  2.39it/s]\u001b[A\n",
      "Iteration:  56% 394/699 [02:44<02:07,  2.39it/s]\u001b[A\n",
      "Iteration:  57% 395/699 [02:44<02:07,  2.39it/s]\u001b[A\n",
      "Iteration:  57% 396/699 [02:45<02:06,  2.39it/s]\u001b[A\n",
      "Iteration:  57% 397/699 [02:45<02:06,  2.39it/s]\u001b[A\n",
      "Iteration:  57% 398/699 [02:46<02:05,  2.39it/s]\u001b[A\n",
      "Iteration:  57% 399/699 [02:46<02:05,  2.39it/s]\u001b[A\n",
      "Iteration:  57% 400/699 [02:47<02:04,  2.39it/s]\u001b[A\n",
      "Iteration:  57% 401/699 [02:47<02:04,  2.40it/s]\u001b[A\n",
      "Iteration:  58% 402/699 [02:47<02:04,  2.38it/s]\u001b[A\n",
      "Iteration:  58% 403/699 [02:48<02:04,  2.39it/s]\u001b[A\n",
      "Iteration:  58% 404/699 [02:48<02:03,  2.39it/s]\u001b[A\n",
      "Iteration:  58% 405/699 [02:49<02:02,  2.39it/s]\u001b[A\n",
      "Iteration:  58% 406/699 [02:49<02:02,  2.39it/s]\u001b[A\n",
      "Iteration:  58% 407/699 [02:49<02:02,  2.39it/s]\u001b[A\n",
      "Iteration:  58% 408/699 [02:50<02:01,  2.39it/s]\u001b[A\n",
      "Iteration:  59% 409/699 [02:50<02:01,  2.39it/s]\u001b[A\n",
      "Iteration:  59% 410/699 [02:51<02:00,  2.39it/s]\u001b[A\n",
      "Iteration:  59% 411/699 [02:51<02:00,  2.39it/s]\u001b[A\n",
      "Iteration:  59% 412/699 [02:52<02:00,  2.39it/s]\u001b[A\n",
      "Iteration:  59% 413/699 [02:52<01:59,  2.39it/s]\u001b[A\n",
      "Iteration:  59% 414/699 [02:52<01:59,  2.39it/s]\u001b[A\n",
      "Iteration:  59% 415/699 [02:53<01:58,  2.40it/s]\u001b[A\n",
      "Iteration:  60% 416/699 [02:53<01:58,  2.40it/s]\u001b[A\n",
      "Iteration:  60% 417/699 [02:54<01:57,  2.39it/s]\u001b[A\n",
      "Iteration:  60% 418/699 [02:54<01:57,  2.39it/s]\u001b[A\n",
      "Iteration:  60% 419/699 [02:55<01:57,  2.39it/s]\u001b[A\n",
      "Iteration:  60% 420/699 [02:55<01:56,  2.39it/s]\u001b[A\n",
      "Iteration:  60% 421/699 [02:55<01:56,  2.39it/s]\u001b[A\n",
      "Iteration:  60% 422/699 [02:56<01:55,  2.39it/s]\u001b[A\n",
      "Iteration:  61% 423/699 [02:56<01:55,  2.39it/s]\u001b[A\n",
      "Iteration:  61% 424/699 [02:57<01:54,  2.40it/s]\u001b[A\n",
      "Iteration:  61% 425/699 [02:57<01:54,  2.39it/s]\u001b[A\n",
      "Iteration:  61% 426/699 [02:57<01:54,  2.39it/s]\u001b[A\n",
      "Iteration:  61% 427/699 [02:58<01:53,  2.39it/s]\u001b[A\n",
      "Iteration:  61% 428/699 [02:58<01:53,  2.40it/s]\u001b[A\n",
      "Iteration:  61% 429/699 [02:59<01:52,  2.39it/s]\u001b[A\n",
      "Iteration:  62% 430/699 [02:59<01:52,  2.39it/s]\u001b[A\n",
      "Iteration:  62% 431/699 [03:00<01:52,  2.39it/s]\u001b[A\n",
      "Iteration:  62% 432/699 [03:00<01:51,  2.39it/s]\u001b[A\n",
      "Iteration:  62% 433/699 [03:00<01:51,  2.40it/s]\u001b[A\n",
      "Iteration:  62% 434/699 [03:01<01:50,  2.40it/s]\u001b[A\n",
      "Iteration:  62% 435/699 [03:01<01:50,  2.39it/s]\u001b[A\n",
      "Iteration:  62% 436/699 [03:02<01:49,  2.40it/s]\u001b[A\n",
      "Iteration:  63% 437/699 [03:02<01:49,  2.39it/s]\u001b[A\n",
      "Iteration:  63% 438/699 [03:02<01:48,  2.40it/s]\u001b[A\n",
      "Iteration:  63% 439/699 [03:03<01:48,  2.39it/s]\u001b[A\n",
      "Iteration:  63% 440/699 [03:03<01:48,  2.39it/s]\u001b[A\n",
      "Iteration:  63% 441/699 [03:04<01:47,  2.40it/s]\u001b[A\n",
      "Iteration:  63% 442/699 [03:04<01:47,  2.39it/s]\u001b[A\n",
      "Iteration:  63% 443/699 [03:05<01:47,  2.39it/s]\u001b[A\n",
      "Iteration:  64% 444/699 [03:05<01:47,  2.38it/s]\u001b[A\n",
      "Iteration:  64% 445/699 [03:05<01:46,  2.39it/s]\u001b[A\n",
      "Iteration:  64% 446/699 [03:06<01:45,  2.39it/s]\u001b[A\n",
      "Iteration:  64% 447/699 [03:06<01:45,  2.39it/s]\u001b[A\n",
      "Iteration:  64% 448/699 [03:07<01:44,  2.39it/s]\u001b[A\n",
      "Iteration:  64% 449/699 [03:07<01:44,  2.39it/s]\u001b[A\n",
      "Iteration:  64% 450/699 [03:07<01:44,  2.39it/s]\u001b[A\n",
      "Iteration:  65% 451/699 [03:08<01:43,  2.39it/s]\u001b[A\n",
      "Iteration:  65% 452/699 [03:08<01:43,  2.39it/s]\u001b[A\n",
      "Iteration:  65% 453/699 [03:09<01:42,  2.39it/s]\u001b[A\n",
      "Iteration:  65% 454/699 [03:09<01:42,  2.40it/s]\u001b[A\n",
      "Iteration:  65% 455/699 [03:10<01:42,  2.39it/s]\u001b[A\n",
      "Iteration:  65% 456/699 [03:10<01:41,  2.39it/s]\u001b[A\n",
      "Iteration:  65% 457/699 [03:10<01:41,  2.39it/s]\u001b[A\n",
      "Iteration:  66% 458/699 [03:11<01:40,  2.39it/s]\u001b[A\n",
      "Iteration:  66% 459/699 [03:11<01:40,  2.39it/s]\u001b[A\n",
      "Iteration:  66% 460/699 [03:12<01:39,  2.39it/s]\u001b[A\n",
      "Iteration:  66% 461/699 [03:12<01:39,  2.40it/s]\u001b[A\n",
      "Iteration:  66% 462/699 [03:12<01:38,  2.39it/s]\u001b[A\n",
      "Iteration:  66% 463/699 [03:13<01:38,  2.39it/s]\u001b[A\n",
      "Iteration:  66% 464/699 [03:13<01:37,  2.40it/s]\u001b[A\n",
      "Iteration:  67% 465/699 [03:14<01:37,  2.40it/s]\u001b[A\n",
      "Iteration:  67% 466/699 [03:14<01:36,  2.40it/s]\u001b[A\n",
      "Iteration:  67% 467/699 [03:15<01:36,  2.40it/s]\u001b[A\n",
      "Iteration:  67% 468/699 [03:15<01:36,  2.40it/s]\u001b[A\n",
      "Iteration:  67% 469/699 [03:15<01:35,  2.40it/s]\u001b[A\n",
      "Iteration:  67% 470/699 [03:16<01:35,  2.39it/s]\u001b[A\n",
      "Iteration:  67% 471/699 [03:16<01:35,  2.40it/s]\u001b[A\n",
      "Iteration:  68% 472/699 [03:17<01:34,  2.39it/s]\u001b[A\n",
      "Iteration:  68% 473/699 [03:17<01:34,  2.40it/s]\u001b[A\n",
      "Iteration:  68% 474/699 [03:17<01:33,  2.40it/s]\u001b[A\n",
      "Iteration:  68% 475/699 [03:18<01:33,  2.39it/s]\u001b[A\n",
      "Iteration:  68% 476/699 [03:18<01:32,  2.40it/s]\u001b[A\n",
      "Iteration:  68% 477/699 [03:19<01:32,  2.40it/s]\u001b[A\n",
      "Iteration:  68% 478/699 [03:19<01:32,  2.39it/s]\u001b[A\n",
      "Iteration:  69% 479/699 [03:20<01:31,  2.40it/s]\u001b[A\n",
      "Iteration:  69% 480/699 [03:20<01:31,  2.40it/s]\u001b[A\n",
      "Iteration:  69% 481/699 [03:20<01:30,  2.40it/s]\u001b[A\n",
      "Iteration:  69% 482/699 [03:21<01:30,  2.39it/s]\u001b[A\n",
      "Iteration:  69% 483/699 [03:21<01:30,  2.39it/s]\u001b[A\n",
      "Iteration:  69% 484/699 [03:22<01:29,  2.39it/s]\u001b[A\n",
      "Iteration:  69% 485/699 [03:22<01:29,  2.40it/s]\u001b[A\n",
      "Iteration:  70% 486/699 [03:22<01:28,  2.40it/s]\u001b[A\n",
      "Iteration:  70% 487/699 [03:23<01:28,  2.40it/s]\u001b[A\n",
      "Iteration:  70% 488/699 [03:23<01:28,  2.39it/s]\u001b[A\n",
      "Iteration:  70% 489/699 [03:24<01:27,  2.39it/s]\u001b[A\n",
      "Iteration:  70% 490/699 [03:24<01:27,  2.39it/s]\u001b[A\n",
      "Iteration:  70% 491/699 [03:25<01:26,  2.39it/s]\u001b[A\n",
      "Iteration:  70% 492/699 [03:25<01:26,  2.39it/s]\u001b[A\n",
      "Iteration:  71% 493/699 [03:25<01:25,  2.40it/s]\u001b[A\n",
      "Iteration:  71% 494/699 [03:26<01:25,  2.40it/s]\u001b[A\n",
      "Iteration:  71% 495/699 [03:26<01:25,  2.39it/s]\u001b[A\n",
      "Iteration:  71% 496/699 [03:27<01:24,  2.40it/s]\u001b[A\n",
      "Iteration:  71% 497/699 [03:27<01:24,  2.40it/s]\u001b[A\n",
      "Iteration:  71% 498/699 [03:28<01:23,  2.40it/s]\u001b[A\n",
      "Iteration:  71% 499/699 [03:28<01:23,  2.40it/s]\u001b[A/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:231: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n",
      "05/22/2020 03:05:09 - INFO - transformers.configuration_utils -   Configuration saved in output_gpt_text/checkpoint-500/config.json\n",
      "05/22/2020 03:05:10 - INFO - transformers.modeling_utils -   Model weights saved in output_gpt_text/checkpoint-500/pytorch_model.bin\n",
      "05/22/2020 03:05:10 - INFO - __main__ -   Saving model checkpoint to output_gpt_text/checkpoint-500\n",
      "/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:200: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.\n",
      "  warnings.warn(SAVE_STATE_WARNING, UserWarning)\n",
      "05/22/2020 03:05:14 - INFO - __main__ -   Saving optimizer and scheduler states to output_gpt_text/checkpoint-500\n",
      "\n",
      "Iteration:  72% 500/699 [03:34<07:11,  2.17s/it]\u001b[A\n",
      "Iteration:  72% 501/699 [03:35<05:25,  1.64s/it]\u001b[A\n",
      "Iteration:  72% 502/699 [03:35<04:10,  1.27s/it]\u001b[A\n",
      "Iteration:  72% 503/699 [03:35<03:19,  1.02s/it]\u001b[A\n",
      "Iteration:  72% 504/699 [03:36<02:42,  1.20it/s]\u001b[A\n",
      "Iteration:  72% 505/699 [03:36<02:16,  1.42it/s]\u001b[A\n",
      "Iteration:  72% 506/699 [03:37<01:59,  1.62it/s]\u001b[A\n",
      "Iteration:  73% 507/699 [03:37<01:46,  1.80it/s]\u001b[A\n",
      "Iteration:  73% 508/699 [03:37<01:37,  1.95it/s]\u001b[A\n",
      "Iteration:  73% 509/699 [03:38<01:31,  2.08it/s]\u001b[A\n",
      "Iteration:  73% 510/699 [03:38<01:26,  2.17it/s]\u001b[A\n",
      "Iteration:  73% 511/699 [03:39<01:23,  2.24it/s]\u001b[A\n",
      "Iteration:  73% 512/699 [03:39<01:21,  2.30it/s]\u001b[A\n",
      "Iteration:  73% 513/699 [03:40<01:19,  2.33it/s]\u001b[A\n",
      "Iteration:  74% 514/699 [03:40<01:18,  2.36it/s]\u001b[A\n",
      "Iteration:  74% 515/699 [03:40<01:17,  2.38it/s]\u001b[A\n",
      "Iteration:  74% 516/699 [03:41<01:16,  2.39it/s]\u001b[A\n",
      "Iteration:  74% 517/699 [03:41<01:15,  2.41it/s]\u001b[A\n",
      "Iteration:  74% 518/699 [03:42<01:15,  2.41it/s]\u001b[A\n",
      "Iteration:  74% 519/699 [03:42<01:14,  2.41it/s]\u001b[A\n",
      "Iteration:  74% 520/699 [03:42<01:14,  2.41it/s]\u001b[A\n",
      "Iteration:  75% 521/699 [03:43<01:13,  2.41it/s]\u001b[A\n",
      "Iteration:  75% 522/699 [03:43<01:13,  2.42it/s]\u001b[A\n",
      "Iteration:  75% 523/699 [03:44<01:12,  2.41it/s]\u001b[A\n",
      "Iteration:  75% 524/699 [03:44<01:12,  2.41it/s]\u001b[A\n",
      "Iteration:  75% 525/699 [03:44<01:12,  2.41it/s]\u001b[A\n",
      "Iteration:  75% 526/699 [03:45<01:11,  2.41it/s]\u001b[A\n",
      "Iteration:  75% 527/699 [03:45<01:11,  2.41it/s]\u001b[A\n",
      "Iteration:  76% 528/699 [03:46<01:11,  2.41it/s]\u001b[A\n",
      "Iteration:  76% 529/699 [03:46<01:10,  2.41it/s]\u001b[A\n",
      "Iteration:  76% 530/699 [03:47<01:10,  2.40it/s]\u001b[A\n",
      "Iteration:  76% 531/699 [03:47<01:09,  2.40it/s]\u001b[A\n",
      "Iteration:  76% 532/699 [03:47<01:09,  2.40it/s]\u001b[A\n",
      "Iteration:  76% 533/699 [03:48<01:09,  2.40it/s]\u001b[A\n",
      "Iteration:  76% 534/699 [03:48<01:08,  2.39it/s]\u001b[A\n",
      "Iteration:  77% 535/699 [03:49<01:08,  2.40it/s]\u001b[A\n",
      "Iteration:  77% 536/699 [03:49<01:08,  2.39it/s]\u001b[A\n",
      "Iteration:  77% 537/699 [03:49<01:07,  2.40it/s]\u001b[A\n",
      "Iteration:  77% 538/699 [03:50<01:07,  2.39it/s]\u001b[A\n",
      "Iteration:  77% 539/699 [03:50<01:06,  2.39it/s]\u001b[A\n",
      "Iteration:  77% 540/699 [03:51<01:06,  2.39it/s]\u001b[A\n",
      "Iteration:  77% 541/699 [03:51<01:06,  2.38it/s]\u001b[A\n",
      "Iteration:  78% 542/699 [03:52<01:05,  2.38it/s]\u001b[A\n",
      "Iteration:  78% 543/699 [03:52<01:05,  2.37it/s]\u001b[A\n",
      "Iteration:  78% 544/699 [03:52<01:05,  2.37it/s]\u001b[A\n",
      "Iteration:  78% 545/699 [03:53<01:05,  2.37it/s]\u001b[A\n",
      "Iteration:  78% 546/699 [03:53<01:04,  2.36it/s]\u001b[A\n",
      "Iteration:  78% 547/699 [03:54<01:04,  2.36it/s]\u001b[A\n",
      "Iteration:  78% 548/699 [03:54<01:04,  2.35it/s]\u001b[A\n",
      "Iteration:  79% 549/699 [03:55<01:03,  2.36it/s]\u001b[A\n",
      "Iteration:  79% 550/699 [03:55<01:03,  2.36it/s]\u001b[A\n",
      "Iteration:  79% 551/699 [03:55<01:02,  2.36it/s]\u001b[A\n",
      "Iteration:  79% 552/699 [03:56<01:02,  2.36it/s]\u001b[A\n",
      "Iteration:  79% 553/699 [03:56<01:01,  2.36it/s]\u001b[A\n",
      "Iteration:  79% 554/699 [03:57<01:01,  2.36it/s]\u001b[A\n",
      "Iteration:  79% 555/699 [03:57<01:01,  2.36it/s]\u001b[A\n",
      "Iteration:  80% 556/699 [03:58<01:00,  2.35it/s]\u001b[A\n",
      "Iteration:  80% 557/699 [03:58<01:00,  2.35it/s]\u001b[A\n",
      "Iteration:  80% 558/699 [03:58<01:00,  2.35it/s]\u001b[A\n",
      "Iteration:  80% 559/699 [03:59<00:59,  2.35it/s]\u001b[A\n",
      "Iteration:  80% 560/699 [03:59<00:59,  2.35it/s]\u001b[A\n",
      "Iteration:  80% 561/699 [04:00<00:58,  2.35it/s]\u001b[A\n",
      "Iteration:  80% 562/699 [04:00<00:58,  2.35it/s]\u001b[A\n",
      "Iteration:  81% 563/699 [04:01<00:57,  2.35it/s]\u001b[A\n",
      "Iteration:  81% 564/699 [04:01<00:57,  2.34it/s]\u001b[A\n",
      "Iteration:  81% 565/699 [04:01<00:57,  2.34it/s]\u001b[A\n",
      "Iteration:  81% 566/699 [04:02<00:56,  2.34it/s]\u001b[A\n",
      "Iteration:  81% 567/699 [04:02<00:56,  2.34it/s]\u001b[A\n",
      "Iteration:  81% 568/699 [04:03<00:55,  2.34it/s]\u001b[A\n",
      "Iteration:  81% 569/699 [04:03<00:55,  2.34it/s]\u001b[A\n",
      "Iteration:  82% 570/699 [04:04<00:54,  2.35it/s]\u001b[A\n",
      "Iteration:  82% 571/699 [04:04<00:54,  2.35it/s]\u001b[A\n",
      "Iteration:  82% 572/699 [04:04<00:54,  2.34it/s]\u001b[A\n",
      "Iteration:  82% 573/699 [04:05<00:53,  2.34it/s]\u001b[A\n",
      "Iteration:  82% 574/699 [04:05<00:53,  2.35it/s]\u001b[A\n",
      "Iteration:  82% 575/699 [04:06<00:52,  2.34it/s]\u001b[A\n",
      "Iteration:  82% 576/699 [04:06<00:52,  2.35it/s]\u001b[A\n",
      "Iteration:  83% 577/699 [04:06<00:51,  2.35it/s]\u001b[A\n",
      "Iteration:  83% 578/699 [04:07<00:51,  2.35it/s]\u001b[A\n",
      "Iteration:  83% 579/699 [04:07<00:51,  2.35it/s]\u001b[A\n",
      "Iteration:  83% 580/699 [04:08<00:50,  2.35it/s]\u001b[A\n",
      "Iteration:  83% 581/699 [04:08<00:50,  2.35it/s]\u001b[A\n",
      "Iteration:  83% 582/699 [04:09<00:49,  2.35it/s]\u001b[A\n",
      "Iteration:  83% 583/699 [04:09<00:49,  2.36it/s]\u001b[A\n",
      "Iteration:  84% 584/699 [04:09<00:48,  2.37it/s]\u001b[A\n",
      "Iteration:  84% 585/699 [04:10<00:48,  2.37it/s]\u001b[A\n",
      "Iteration:  84% 586/699 [04:10<00:47,  2.37it/s]\u001b[A\n",
      "Iteration:  84% 587/699 [04:11<00:47,  2.37it/s]\u001b[A\n",
      "Iteration:  84% 588/699 [04:11<00:46,  2.37it/s]\u001b[A\n",
      "Iteration:  84% 589/699 [04:12<00:46,  2.37it/s]\u001b[A\n",
      "Iteration:  84% 590/699 [04:12<00:45,  2.37it/s]\u001b[A\n",
      "Iteration:  85% 591/699 [04:12<00:45,  2.37it/s]\u001b[A\n",
      "Iteration:  85% 592/699 [04:13<00:45,  2.37it/s]\u001b[A\n",
      "Iteration:  85% 593/699 [04:13<00:44,  2.37it/s]\u001b[A\n",
      "Iteration:  85% 594/699 [04:14<00:44,  2.37it/s]\u001b[A\n",
      "Iteration:  85% 595/699 [04:14<00:43,  2.37it/s]\u001b[A\n",
      "Iteration:  85% 596/699 [04:15<00:43,  2.38it/s]\u001b[A\n",
      "Iteration:  85% 597/699 [04:15<00:43,  2.37it/s]\u001b[A\n",
      "Iteration:  86% 598/699 [04:15<00:42,  2.38it/s]\u001b[A\n",
      "Iteration:  86% 599/699 [04:16<00:42,  2.37it/s]\u001b[A\n",
      "Iteration:  86% 600/699 [04:16<00:41,  2.37it/s]\u001b[A\n",
      "Iteration:  86% 601/699 [04:17<00:41,  2.38it/s]\u001b[A\n",
      "Iteration:  86% 602/699 [04:17<00:40,  2.38it/s]\u001b[A\n",
      "Iteration:  86% 603/699 [04:17<00:40,  2.38it/s]\u001b[A\n",
      "Iteration:  86% 604/699 [04:18<00:39,  2.38it/s]\u001b[A\n",
      "Iteration:  87% 605/699 [04:18<00:39,  2.37it/s]\u001b[A\n",
      "Iteration:  87% 606/699 [04:19<00:39,  2.38it/s]\u001b[A\n",
      "Iteration:  87% 607/699 [04:19<00:38,  2.38it/s]\u001b[A\n",
      "Iteration:  87% 608/699 [04:20<00:38,  2.38it/s]\u001b[A\n",
      "Iteration:  87% 609/699 [04:20<00:37,  2.38it/s]\u001b[A\n",
      "Iteration:  87% 610/699 [04:20<00:37,  2.39it/s]\u001b[A\n",
      "Iteration:  87% 611/699 [04:21<00:36,  2.39it/s]\u001b[A\n",
      "Iteration:  88% 612/699 [04:21<00:36,  2.39it/s]\u001b[A\n",
      "Iteration:  88% 613/699 [04:22<00:36,  2.39it/s]\u001b[A\n",
      "Iteration:  88% 614/699 [04:22<00:35,  2.38it/s]\u001b[A\n",
      "Iteration:  88% 615/699 [04:23<00:35,  2.38it/s]\u001b[A\n",
      "Iteration:  88% 616/699 [04:23<00:34,  2.39it/s]\u001b[A\n",
      "Iteration:  88% 617/699 [04:23<00:34,  2.39it/s]\u001b[A\n",
      "Iteration:  88% 618/699 [04:24<00:33,  2.39it/s]\u001b[A\n",
      "Iteration:  89% 619/699 [04:24<00:33,  2.39it/s]\u001b[A\n",
      "Iteration:  89% 620/699 [04:25<00:33,  2.39it/s]\u001b[A\n",
      "Iteration:  89% 621/699 [04:25<00:32,  2.39it/s]\u001b[A\n",
      "Iteration:  89% 622/699 [04:25<00:32,  2.39it/s]\u001b[A\n",
      "Iteration:  89% 623/699 [04:26<00:31,  2.40it/s]\u001b[A\n",
      "Iteration:  89% 624/699 [04:26<00:31,  2.39it/s]\u001b[A\n",
      "Iteration:  89% 625/699 [04:27<00:30,  2.40it/s]\u001b[A\n",
      "Iteration:  90% 626/699 [04:27<00:30,  2.40it/s]\u001b[A\n",
      "Iteration:  90% 627/699 [04:28<00:30,  2.40it/s]\u001b[A\n",
      "Iteration:  90% 628/699 [04:28<00:29,  2.40it/s]\u001b[A\n",
      "Iteration:  90% 629/699 [04:28<00:29,  2.40it/s]\u001b[A\n",
      "Iteration:  90% 630/699 [04:29<00:28,  2.40it/s]\u001b[A\n",
      "Iteration:  90% 631/699 [04:29<00:28,  2.40it/s]\u001b[A\n",
      "Iteration:  90% 632/699 [04:30<00:27,  2.40it/s]\u001b[A\n",
      "Iteration:  91% 633/699 [04:30<00:27,  2.40it/s]\u001b[A\n",
      "Iteration:  91% 634/699 [04:30<00:27,  2.40it/s]\u001b[A\n",
      "Iteration:  91% 635/699 [04:31<00:26,  2.41it/s]\u001b[A\n",
      "Iteration:  91% 636/699 [04:31<00:26,  2.40it/s]\u001b[A\n",
      "Iteration:  91% 637/699 [04:32<00:25,  2.40it/s]\u001b[A\n",
      "Iteration:  91% 638/699 [04:32<00:25,  2.40it/s]\u001b[A\n",
      "Iteration:  91% 639/699 [04:33<00:24,  2.40it/s]\u001b[A\n",
      "Iteration:  92% 640/699 [04:33<00:24,  2.41it/s]\u001b[A\n",
      "Iteration:  92% 641/699 [04:33<00:24,  2.40it/s]\u001b[A\n",
      "Iteration:  92% 642/699 [04:34<00:23,  2.41it/s]\u001b[A\n",
      "Iteration:  92% 643/699 [04:34<00:23,  2.40it/s]\u001b[A\n",
      "Iteration:  92% 644/699 [04:35<00:22,  2.40it/s]\u001b[A\n",
      "Iteration:  92% 645/699 [04:35<00:22,  2.41it/s]\u001b[A\n",
      "Iteration:  92% 646/699 [04:35<00:22,  2.40it/s]\u001b[A\n",
      "Iteration:  93% 647/699 [04:36<00:21,  2.41it/s]\u001b[A\n",
      "Iteration:  93% 648/699 [04:36<00:21,  2.40it/s]\u001b[A\n",
      "Iteration:  93% 649/699 [04:37<00:20,  2.40it/s]\u001b[A\n",
      "Iteration:  93% 650/699 [04:37<00:20,  2.40it/s]\u001b[A\n",
      "Iteration:  93% 651/699 [04:37<00:19,  2.41it/s]\u001b[A\n",
      "Iteration:  93% 652/699 [04:38<00:19,  2.41it/s]\u001b[A\n",
      "Iteration:  93% 653/699 [04:38<00:19,  2.41it/s]\u001b[A\n",
      "Iteration:  94% 654/699 [04:39<00:18,  2.41it/s]\u001b[A\n",
      "Iteration:  94% 655/699 [04:39<00:18,  2.41it/s]\u001b[A\n",
      "Iteration:  94% 656/699 [04:40<00:17,  2.41it/s]\u001b[A\n",
      "Iteration:  94% 657/699 [04:40<00:17,  2.42it/s]\u001b[A\n",
      "Iteration:  94% 658/699 [04:40<00:16,  2.41it/s]\u001b[A\n",
      "Iteration:  94% 659/699 [04:41<00:16,  2.41it/s]\u001b[A\n",
      "Iteration:  94% 660/699 [04:41<00:16,  2.41it/s]\u001b[A\n",
      "Iteration:  95% 661/699 [04:42<00:15,  2.41it/s]\u001b[A\n",
      "Iteration:  95% 662/699 [04:42<00:15,  2.42it/s]\u001b[A\n",
      "Iteration:  95% 663/699 [04:42<00:14,  2.41it/s]\u001b[A\n",
      "Iteration:  95% 664/699 [04:43<00:14,  2.42it/s]\u001b[A\n",
      "Iteration:  95% 665/699 [04:43<00:14,  2.42it/s]\u001b[A\n",
      "Iteration:  95% 666/699 [04:44<00:13,  2.41it/s]\u001b[A\n",
      "Iteration:  95% 667/699 [04:44<00:13,  2.41it/s]\u001b[A\n",
      "Iteration:  96% 668/699 [04:45<00:12,  2.41it/s]\u001b[A\n",
      "Iteration:  96% 669/699 [04:45<00:12,  2.41it/s]\u001b[A\n",
      "Iteration:  96% 670/699 [04:45<00:12,  2.41it/s]\u001b[A\n",
      "Iteration:  96% 671/699 [04:46<00:11,  2.41it/s]\u001b[A\n",
      "Iteration:  96% 672/699 [04:46<00:11,  2.41it/s]\u001b[A\n",
      "Iteration:  96% 673/699 [04:47<00:10,  2.41it/s]\u001b[A\n",
      "Iteration:  96% 674/699 [04:47<00:10,  2.41it/s]\u001b[A\n",
      "Iteration:  97% 675/699 [04:47<00:09,  2.42it/s]\u001b[A\n",
      "Iteration:  97% 676/699 [04:48<00:09,  2.42it/s]\u001b[A\n",
      "Iteration:  97% 677/699 [04:48<00:09,  2.42it/s]\u001b[A\n",
      "Iteration:  97% 678/699 [04:49<00:08,  2.41it/s]\u001b[A\n",
      "Iteration:  97% 679/699 [04:49<00:08,  2.41it/s]\u001b[A\n",
      "Iteration:  97% 680/699 [04:50<00:07,  2.41it/s]\u001b[A\n",
      "Iteration:  97% 681/699 [04:50<00:07,  2.41it/s]\u001b[A\n",
      "Iteration:  98% 682/699 [04:50<00:07,  2.41it/s]\u001b[A\n",
      "Iteration:  98% 683/699 [04:51<00:06,  2.41it/s]\u001b[A\n",
      "Iteration:  98% 684/699 [04:51<00:06,  2.41it/s]\u001b[A\n",
      "Iteration:  98% 685/699 [04:52<00:05,  2.41it/s]\u001b[A\n",
      "Iteration:  98% 686/699 [04:52<00:05,  2.41it/s]\u001b[A\n",
      "Iteration:  98% 687/699 [04:52<00:04,  2.41it/s]\u001b[A\n",
      "Iteration:  98% 688/699 [04:53<00:04,  2.41it/s]\u001b[A\n",
      "Iteration:  99% 689/699 [04:53<00:04,  2.41it/s]\u001b[A\n",
      "Iteration:  99% 690/699 [04:54<00:03,  2.40it/s]\u001b[A\n",
      "Iteration:  99% 691/699 [04:54<00:03,  2.41it/s]\u001b[A\n",
      "Iteration:  99% 692/699 [04:54<00:02,  2.42it/s]\u001b[A\n",
      "Iteration:  99% 693/699 [04:55<00:02,  2.41it/s]\u001b[A\n",
      "Iteration:  99% 694/699 [04:55<00:02,  2.41it/s]\u001b[A\n",
      "Iteration:  99% 695/699 [04:56<00:01,  2.41it/s]\u001b[A\n",
      "Iteration: 100% 696/699 [04:56<00:01,  2.41it/s]\u001b[A\n",
      "Iteration: 100% 697/699 [04:57<00:00,  2.40it/s]\u001b[A\n",
      "Iteration: 100% 698/699 [04:57<00:00,  2.41it/s]\u001b[A\n",
      "Iteration: 100% 699/699 [04:57<00:00,  2.35it/s]\n",
      "Epoch: 100% 1/1 [04:57<00:00, 297.90s/it]\n",
      "05/22/2020 03:06:38 - INFO - __main__ -    global_step = 699, average loss = 3.5057688397228803\n",
      "05/22/2020 03:06:38 - INFO - __main__ -   Saving model checkpoint to output_gpt_text\n",
      "05/22/2020 03:06:38 - INFO - transformers.configuration_utils -   Configuration saved in output_gpt_text/config.json\n",
      "05/22/2020 03:06:39 - INFO - transformers.modeling_utils -   Model weights saved in output_gpt_text/pytorch_model.bin\n",
      "05/22/2020 03:06:39 - INFO - transformers.configuration_utils -   loading configuration file output_gpt_text/config.json\n",
      "05/22/2020 03:06:39 - INFO - transformers.configuration_utils -   Model config GPT2Config {\n",
      "  \"activation_function\": \"gelu_new\",\n",
      "  \"architectures\": [\n",
      "    \"GPT2LMHeadModel\"\n",
      "  ],\n",
      "  \"attn_pdrop\": 0.1,\n",
      "  \"bos_token_id\": 50256,\n",
      "  \"embd_pdrop\": 0.1,\n",
      "  \"eos_token_id\": 50256,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"gpt2\",\n",
      "  \"n_ctx\": 1024,\n",
      "  \"n_embd\": 768,\n",
      "  \"n_head\": 12,\n",
      "  \"n_layer\": 12,\n",
      "  \"n_positions\": 1024,\n",
      "  \"resid_pdrop\": 0.1,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"cls_index\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"task_specific_params\": {\n",
      "    \"text-generation\": {\n",
      "      \"do_sample\": true,\n",
      "      \"max_length\": 50\n",
      "    }\n",
      "  },\n",
      "  \"vocab_size\": 50257\n",
      "}\n",
      "\n",
      "05/22/2020 03:06:39 - INFO - transformers.modeling_utils -   loading weights file output_gpt_text/pytorch_model.bin\n",
      "05/22/2020 03:06:44 - INFO - transformers.tokenization_utils -   Model name 'output_gpt_text' not found in model shortcut name list (gpt2, gpt2-medium, gpt2-large, gpt2-xl, distilgpt2). Assuming 'output_gpt_text' is a path, a model identifier, or url to a directory containing tokenizer files.\n",
      "05/22/2020 03:06:44 - INFO - transformers.tokenization_utils -   Didn't find file output_gpt_text/added_tokens.json. We won't load it.\n",
      "05/22/2020 03:06:44 - INFO - transformers.tokenization_utils -   loading file output_gpt_text/vocab.json\n",
      "05/22/2020 03:06:44 - INFO - transformers.tokenization_utils -   loading file output_gpt_text/merges.txt\n",
      "05/22/2020 03:06:44 - INFO - transformers.tokenization_utils -   loading file None\n",
      "05/22/2020 03:06:44 - INFO - transformers.tokenization_utils -   loading file output_gpt_text/special_tokens_map.json\n",
      "05/22/2020 03:06:44 - INFO - transformers.tokenization_utils -   loading file output_gpt_text/tokenizer_config.json\n",
      "05/22/2020 03:06:44 - INFO - __main__ -   Evaluate the following checkpoints: ['output_gpt_text']\n",
      "05/22/2020 03:06:44 - INFO - transformers.configuration_utils -   loading configuration file output_gpt_text/config.json\n",
      "05/22/2020 03:06:44 - INFO - transformers.configuration_utils -   Model config GPT2Config {\n",
      "  \"activation_function\": \"gelu_new\",\n",
      "  \"architectures\": [\n",
      "    \"GPT2LMHeadModel\"\n",
      "  ],\n",
      "  \"attn_pdrop\": 0.1,\n",
      "  \"bos_token_id\": 50256,\n",
      "  \"embd_pdrop\": 0.1,\n",
      "  \"eos_token_id\": 50256,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"gpt2\",\n",
      "  \"n_ctx\": 1024,\n",
      "  \"n_embd\": 768,\n",
      "  \"n_head\": 12,\n",
      "  \"n_layer\": 12,\n",
      "  \"n_positions\": 1024,\n",
      "  \"resid_pdrop\": 0.1,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"cls_index\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"task_specific_params\": {\n",
      "    \"text-generation\": {\n",
      "      \"do_sample\": true,\n",
      "      \"max_length\": 50\n",
      "    }\n",
      "  },\n",
      "  \"vocab_size\": 50257\n",
      "}\n",
      "\n",
      "05/22/2020 03:06:44 - INFO - transformers.modeling_utils -   loading weights file output_gpt_text/pytorch_model.bin\n",
      "05/22/2020 03:06:49 - INFO - __main__ -   Creating features from dataset file at \n",
      "05/22/2020 03:06:50 - INFO - __main__ -   Saving features into cached file gpt2_cached_lm_1024_test_text\n",
      "05/22/2020 03:06:50 - INFO - __main__ -   ***** Running evaluation  *****\n",
      "05/22/2020 03:06:50 - INFO - __main__ -     Num examples = 175\n",
      "05/22/2020 03:06:50 - INFO - __main__ -     Batch size = 1\n",
      "Evaluating: 100% 175/175 [00:22<00:00,  7.84it/s]\n",
      "05/22/2020 03:07:13 - INFO - __main__ -   ***** Eval results  *****\n",
      "05/22/2020 03:07:13 - INFO - __main__ -     perplexity = tensor(28.0279)\n"
     ]
    }
   ],
   "source": [
    "!python run_language_modelling.py --output_dir=output_gpt_text --model_type=gpt2 --model_name_or_path=gpt2 --do_train --train_data_file=train_text --do_eval --eval_data_file=test_text --per_gpu_train_batch_size=1 --per_gpu_eval_batch_size=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 900
    },
    "colab_type": "code",
    "id": "F4wVKwS0TDQj",
    "outputId": "f171ebff-6ec9-4512-94de-1ff6e00eb0ae"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-05-22 03:10:01.223360: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
      "05/22/2020 03:10:02 - INFO - transformers.tokenization_utils -   Model name 'output_gpt_text' not found in model shortcut name list (gpt2, gpt2-medium, gpt2-large, gpt2-xl, distilgpt2). Assuming 'output_gpt_text' is a path, a model identifier, or url to a directory containing tokenizer files.\n",
      "05/22/2020 03:10:02 - INFO - transformers.tokenization_utils -   Didn't find file output_gpt_text/added_tokens.json. We won't load it.\n",
      "05/22/2020 03:10:02 - INFO - transformers.tokenization_utils -   loading file output_gpt_text/vocab.json\n",
      "05/22/2020 03:10:02 - INFO - transformers.tokenization_utils -   loading file output_gpt_text/merges.txt\n",
      "05/22/2020 03:10:02 - INFO - transformers.tokenization_utils -   loading file None\n",
      "05/22/2020 03:10:02 - INFO - transformers.tokenization_utils -   loading file output_gpt_text/special_tokens_map.json\n",
      "05/22/2020 03:10:02 - INFO - transformers.tokenization_utils -   loading file output_gpt_text/tokenizer_config.json\n",
      "05/22/2020 03:10:03 - INFO - transformers.configuration_utils -   loading configuration file output_gpt_text/config.json\n",
      "05/22/2020 03:10:03 - INFO - transformers.configuration_utils -   Model config GPT2Config {\n",
      "  \"activation_function\": \"gelu_new\",\n",
      "  \"architectures\": [\n",
      "    \"GPT2LMHeadModel\"\n",
      "  ],\n",
      "  \"attn_pdrop\": 0.1,\n",
      "  \"bos_token_id\": 50256,\n",
      "  \"embd_pdrop\": 0.1,\n",
      "  \"eos_token_id\": 50256,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"gpt2\",\n",
      "  \"n_ctx\": 1024,\n",
      "  \"n_embd\": 768,\n",
      "  \"n_head\": 12,\n",
      "  \"n_layer\": 12,\n",
      "  \"n_positions\": 1024,\n",
      "  \"resid_pdrop\": 0.1,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"cls_index\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"task_specific_params\": {\n",
      "    \"text-generation\": {\n",
      "      \"do_sample\": true,\n",
      "      \"max_length\": 50\n",
      "    }\n",
      "  },\n",
      "  \"vocab_size\": 50257\n",
      "}\n",
      "\n",
      "05/22/2020 03:10:03 - INFO - transformers.modeling_utils -   loading weights file output_gpt_text/pytorch_model.bin\n",
      "05/22/2020 03:10:12 - INFO - __main__ -   Namespace(device=device(type='cuda'), k=0, length=20, model_name_or_path='output_gpt_text', model_type='gpt2', n_gpu=1, no_cuda=False, num_return_sequences=1, p=0.9, padding_text='', prompt='', repetition_penalty=1.0, seed=42, stop_token=None, temperature=1.0, xlm_language='')\n",
      "Model prompt >>> This game\n",
      "05/22/2020 03:10:37 - WARNING - transformers.modeling_utils -   Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n",
      "=== GENERATED SEQUENCE 1 ===\n",
      "This game was remarkably innovative and fun.  It has a complete line of games to choose from, such as\n"
     ]
    }
   ],
   "source": [
    "!python run_generation.py --model_type=gpt2 --model_name_or_path=output_gpt_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "v5ihjAtmYOqU"
   },
   "source": [
    "This was so interesting that it shows the high-level pattern of text generation that highlighting this video is innovative and fun, which is quite positive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Q_pMwXqfTDYj"
   },
   "outputs": [],
   "source": [
    "tokenizer_gpt = AutoTokenizer.from_pretrained(\"output_gpt_text\")\n",
    "model_gpt = AutoModelWithLMHead.from_pretrained(\"output_gpt_text\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 55
    },
    "colab_type": "code",
    "id": "DwCKAm5FPILp",
    "outputId": "d1e69a71-574d-4db9-ee6b-2c79e7f15d19"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I like this video game because it's fun and it's fun to play. I also like the fact that you can play as a character and have a lot of fun. I also like the fact that you can play as a character and have a\n"
     ]
    }
   ],
   "source": [
    "sequence = \"I like this video game because\"\n",
    "\n",
    "input = tokenizer_gpt.encode(sequence, return_tensors=\"pt\")\n",
    "generated = model_gpt.generate(input, max_length=50, bos_token_id=1, pad_token_id=1, eos_token_ids=1)\n",
    "\n",
    "resulting_string = tokenizer_gpt.decode(generated.tolist()[0])\n",
    "print(resulting_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 55
    },
    "colab_type": "code",
    "id": "GM5M7CHaP2ob",
    "outputId": "ea68f819-e7f8-4ee5-aab0-b8f7c31293da"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I don't like this video game because it's so boring.  I don't like the graphics, but I like the gameplay.  I like the story, but I don't like the characters.  I like the music, but I don\n"
     ]
    }
   ],
   "source": [
    "sequence = \"I don't like this video game because\"\n",
    "\n",
    "input = tokenizer_gpt.encode(sequence, return_tensors=\"pt\")\n",
    "generated = model_gpt.generate(input, max_length=50, bos_token_id=1, pad_token_id=1, eos_token_ids=1)\n",
    "\n",
    "resulting_string = tokenizer_gpt.decode(generated.tolist()[0])\n",
    "print(resulting_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kKQMzljEZTz2"
   },
   "source": [
    "It is so interesting that we can see the two text generations from positive and negative perspective."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3d4MmjnDcj5A"
   },
   "source": [
    "After that, We construct two new datasets each with labelled as 1 and 0 respectively with 1000 inputs.Then, we try to see different text generations from them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "colab_type": "code",
    "id": "sGEX6zX4bSwb",
    "outputId": "76ad3e0d-935b-412e-fe89-b54aa56fbacc"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>reviewText</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>This game is a bit hard to get the hang of, bu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>I played it a while but it was alright. The st...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>ok game.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>found the game a bit too complicated, not what...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>great game, I love it and have played it since...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                         reviewText\n",
       "0      1  This game is a bit hard to get the hang of, bu...\n",
       "1      0  I played it a while but it was alright. The st...\n",
       "2      0                                           ok game.\n",
       "3      0  found the game a bit too complicated, not what...\n",
       "4      1  great game, I love it and have played it since..."
      ]
     },
     "execution_count": 55,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "csv_url = \"https://raw.githubusercontent.com/minminfly68/Content-Analysis-2020/master/week-7/first5000.csv\"\n",
    "df_all = pd.read_csv(csv_url)\n",
    "df_all = df_all[['overall', 'reviewText']]\n",
    "df_all['label'] = df_all.apply(lambda x: int(x['overall'] == 5), axis=1)\n",
    "df_all = df_all[['label','reviewText']]\n",
    "df_all.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 237
    },
    "colab_type": "code",
    "id": "yzNesdfGbS4A",
    "outputId": "31c6cada-66ab-452d-9af1-0f909743b719"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    label                                         reviewText\n",
      "0       1  This game is a bit hard to get the hang of, bu...\n",
      "4       1  great game, I love it and have played it since...\n",
      "7       1  I bought this game thinking it would be pretty...\n",
      "8       1  I have played the old anno 1701 AND 1503.  thi...\n",
      "12      1  Loved playing Dirt 2 and I thought the graphic...\n",
      "   label                                         reviewText\n",
      "1      0  I played it a while but it was alright. The st...\n",
      "2      0                                           ok game.\n",
      "3      0  found the game a bit too complicated, not what...\n",
      "5      0  i liked a lot some time that i haven't play a ...\n",
      "6      0  I'm an avid gamer, but Anno 2070 is an INSULT ...\n"
     ]
    }
   ],
   "source": [
    "df_1 = df_all[df_all['label'] == 1]\n",
    "df_1 = df_1[:500]\n",
    "print(df_1.head())\n",
    "df_0 = df_all[df_all['label'] == 0]\n",
    "df_0 = df_0[:500]\n",
    "print(df_0.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rdxAacD1bS_B"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_text, test_text = train_test_split(df_1['reviewText'], test_size=0.2)\n",
    "train_text.to_frame().to_csv(r'train_text', header=None, index=None, sep=' ', mode='a')\n",
    "test_text.to_frame().to_csv(r'test_text', header=None, index=None, sep=' ', mode='a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RCHMwqxadC5-"
   },
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "bdeJ4KtYdDA-",
    "outputId": "9305028b-8087-4846-f5f4-4be1dbe9d2d0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-05-22 03:37:45.902575: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
      "05/22/2020 03:37:47 - WARNING - __main__ -   Process rank: -1, device: cuda, n_gpu: 1, distributed training: False, 16-bits training: False\n",
      "05/22/2020 03:37:48 - INFO - transformers.configuration_utils -   loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-config.json from cache at /root/.cache/torch/transformers/4be02c5697d91738003fb1685c9872f284166aa32e061576bbe6aaeb95649fcf.db13c9bc9c7bdd738ec89e069621d88e05dc670366092d809a9cbcac6798e24e\n",
      "05/22/2020 03:37:48 - INFO - transformers.configuration_utils -   Model config GPT2Config {\n",
      "  \"activation_function\": \"gelu_new\",\n",
      "  \"architectures\": [\n",
      "    \"GPT2LMHeadModel\"\n",
      "  ],\n",
      "  \"attn_pdrop\": 0.1,\n",
      "  \"bos_token_id\": 50256,\n",
      "  \"embd_pdrop\": 0.1,\n",
      "  \"eos_token_id\": 50256,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"gpt2\",\n",
      "  \"n_ctx\": 1024,\n",
      "  \"n_embd\": 768,\n",
      "  \"n_head\": 12,\n",
      "  \"n_layer\": 12,\n",
      "  \"n_positions\": 1024,\n",
      "  \"resid_pdrop\": 0.1,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"cls_index\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"task_specific_params\": {\n",
      "    \"text-generation\": {\n",
      "      \"do_sample\": true,\n",
      "      \"max_length\": 50\n",
      "    }\n",
      "  },\n",
      "  \"vocab_size\": 50257\n",
      "}\n",
      "\n",
      "05/22/2020 03:37:50 - INFO - transformers.tokenization_utils -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-vocab.json from cache at /root/.cache/torch/transformers/f2808208f9bec2320371a9f5f891c184ae0b674ef866b79c58177067d15732dd.1512018be4ba4e8726e41b9145129dc30651ea4fec86aa61f4b9f40bf94eac71\n",
      "05/22/2020 03:37:50 - INFO - transformers.tokenization_utils -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-merges.txt from cache at /root/.cache/torch/transformers/d629f792e430b3c76a1291bb2766b0a047e36fae0588f9dbc1ae51decdff691b.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda\n",
      "05/22/2020 03:37:50 - INFO - transformers.modeling_utils -   loading weights file https://cdn.huggingface.co/gpt2-pytorch_model.bin from cache at /root/.cache/torch/transformers/d71fd633e58263bd5e91dd3bde9f658bafd81e11ece622be6a3c2e4d42d8fd89.778cf36f5c4e5d94c8cd9cefcf2a580c8643570eb327f0d4a1f007fab2acbdf1\n",
      "05/22/2020 03:37:55 - INFO - transformers.modeling_utils -   Weights of GPT2LMHeadModel not initialized from pretrained model: ['h.0.attn.masked_bias', 'h.1.attn.masked_bias', 'h.2.attn.masked_bias', 'h.3.attn.masked_bias', 'h.4.attn.masked_bias', 'h.5.attn.masked_bias', 'h.6.attn.masked_bias', 'h.7.attn.masked_bias', 'h.8.attn.masked_bias', 'h.9.attn.masked_bias', 'h.10.attn.masked_bias', 'h.11.attn.masked_bias', 'lm_head.weight']\n",
      "05/22/2020 03:37:59 - INFO - __main__ -   Training/evaluation parameters Namespace(adam_epsilon=1e-08, block_size=1024, cache_dir=None, config_name=None, device=device(type='cuda'), do_eval=True, do_train=True, eval_all_checkpoints=False, eval_data_file='test_text', evaluate_during_training=False, fp16=False, fp16_opt_level='O1', gradient_accumulation_steps=1, learning_rate=5e-05, line_by_line=False, local_rank=-1, logging_steps=500, max_grad_norm=1.0, max_steps=-1, mlm=False, mlm_probability=0.15, model_name_or_path='gpt2', model_type='gpt2', n_gpu=1, no_cuda=False, num_train_epochs=1.0, output_dir='output_gpt_text_1', overwrite_cache=False, overwrite_output_dir=False, per_gpu_eval_batch_size=1, per_gpu_train_batch_size=1, save_steps=500, save_total_limit=None, seed=42, server_ip='', server_port='', should_continue=False, tokenizer_name=None, train_data_file='train_text', warmup_steps=0, weight_decay=0.0)\n",
      "05/22/2020 03:37:59 - INFO - __main__ -   Loading features from cached file gpt2_cached_lm_1024_train_text\n",
      "05/22/2020 03:37:59 - INFO - __main__ -   ***** Running training *****\n",
      "05/22/2020 03:37:59 - INFO - __main__ -     Num examples = 699\n",
      "05/22/2020 03:37:59 - INFO - __main__ -     Num Epochs = 1\n",
      "05/22/2020 03:37:59 - INFO - __main__ -     Instantaneous batch size per GPU = 1\n",
      "05/22/2020 03:37:59 - INFO - __main__ -     Total train batch size (w. parallel, distributed & accumulation) = 1\n",
      "05/22/2020 03:37:59 - INFO - __main__ -     Gradient Accumulation steps = 1\n",
      "05/22/2020 03:37:59 - INFO - __main__ -     Total optimization steps = 699\n",
      "Epoch:   0% 0/1 [00:00<?, ?it/s]\n",
      "Iteration:   0% 0/699 [00:00<?, ?it/s]\u001b[A/pytorch/torch/csrc/utils/python_arg_parser.cpp:756: UserWarning: This overload of add_ is deprecated:\n",
      "\tadd_(Number alpha, Tensor other)\n",
      "Consider using one of the following signatures instead:\n",
      "\tadd_(Tensor other, *, Number alpha)\n",
      "\n",
      "Iteration:   0% 1/699 [00:00<05:14,  2.22it/s]\u001b[A\n",
      "Iteration:   0% 2/699 [00:00<04:57,  2.34it/s]\u001b[A\n",
      "Iteration:   0% 3/699 [00:01<04:49,  2.40it/s]\u001b[A\n",
      "Iteration:   1% 4/699 [00:01<04:42,  2.46it/s]\u001b[A\n",
      "Iteration:   1% 5/699 [00:01<04:37,  2.50it/s]\u001b[A\n",
      "Iteration:   1% 6/699 [00:02<04:34,  2.52it/s]\u001b[A\n",
      "Iteration:   1% 7/699 [00:02<04:33,  2.53it/s]\u001b[A\n",
      "Iteration:   1% 8/699 [00:03<04:31,  2.55it/s]\u001b[A\n",
      "Iteration:   1% 9/699 [00:03<04:30,  2.55it/s]\u001b[A\n",
      "Iteration:   1% 10/699 [00:03<04:29,  2.56it/s]\u001b[A\n",
      "Iteration:   2% 11/699 [00:04<04:28,  2.56it/s]\u001b[A\n",
      "Iteration:   2% 12/699 [00:04<04:28,  2.56it/s]\u001b[A\n",
      "Iteration:   2% 13/699 [00:05<04:27,  2.57it/s]\u001b[A\n",
      "Iteration:   2% 14/699 [00:05<04:26,  2.57it/s]\u001b[A\n",
      "Iteration:   2% 15/699 [00:05<04:25,  2.57it/s]\u001b[A\n",
      "Iteration:   2% 16/699 [00:06<04:25,  2.57it/s]\u001b[A\n",
      "Iteration:   2% 17/699 [00:06<04:25,  2.57it/s]\u001b[A\n",
      "Iteration:   3% 18/699 [00:07<04:24,  2.57it/s]\u001b[A\n",
      "Iteration:   3% 19/699 [00:07<04:23,  2.58it/s]\u001b[A\n",
      "Iteration:   3% 20/699 [00:07<04:24,  2.57it/s]\u001b[A\n",
      "Iteration:   3% 21/699 [00:08<04:23,  2.57it/s]\u001b[A\n",
      "Iteration:   3% 22/699 [00:08<04:23,  2.57it/s]\u001b[A\n",
      "Iteration:   3% 23/699 [00:08<04:23,  2.57it/s]\u001b[A\n",
      "Iteration:   3% 24/699 [00:09<04:22,  2.57it/s]\u001b[A\n",
      "Iteration:   4% 25/699 [00:09<04:22,  2.57it/s]\u001b[A\n",
      "Iteration:   4% 26/699 [00:10<04:22,  2.56it/s]\u001b[A\n",
      "Iteration:   4% 27/699 [00:10<04:21,  2.57it/s]\u001b[A\n",
      "Iteration:   4% 28/699 [00:10<04:21,  2.57it/s]\u001b[A\n",
      "Iteration:   4% 29/699 [00:11<04:21,  2.56it/s]\u001b[A\n",
      "Iteration:   4% 30/699 [00:11<04:20,  2.56it/s]\u001b[A\n",
      "Iteration:   4% 31/699 [00:12<04:21,  2.56it/s]\u001b[A\n",
      "Iteration:   5% 32/699 [00:12<04:20,  2.56it/s]\u001b[A\n",
      "Iteration:   5% 33/699 [00:12<04:20,  2.56it/s]\u001b[A\n",
      "Iteration:   5% 34/699 [00:13<04:19,  2.56it/s]\u001b[A\n",
      "Iteration:   5% 35/699 [00:13<04:19,  2.56it/s]\u001b[A\n",
      "Iteration:   5% 36/699 [00:14<04:19,  2.55it/s]\u001b[A\n",
      "Iteration:   5% 37/699 [00:14<04:19,  2.55it/s]\u001b[A\n",
      "Iteration:   5% 38/699 [00:14<04:18,  2.55it/s]\u001b[A\n",
      "Iteration:   6% 39/699 [00:15<04:19,  2.55it/s]\u001b[A\n",
      "Iteration:   6% 40/699 [00:15<04:18,  2.55it/s]\u001b[A\n",
      "Iteration:   6% 41/699 [00:16<04:17,  2.55it/s]\u001b[A\n",
      "Iteration:   6% 42/699 [00:16<04:18,  2.54it/s]\u001b[A\n",
      "Iteration:   6% 43/699 [00:16<04:17,  2.55it/s]\u001b[A\n",
      "Iteration:   6% 44/699 [00:17<04:17,  2.54it/s]\u001b[A\n",
      "Iteration:   6% 45/699 [00:17<04:17,  2.54it/s]\u001b[A\n",
      "Iteration:   7% 46/699 [00:17<04:16,  2.55it/s]\u001b[A\n",
      "Iteration:   7% 47/699 [00:18<04:16,  2.54it/s]\u001b[A\n",
      "Iteration:   7% 48/699 [00:18<04:16,  2.54it/s]\u001b[A\n",
      "Iteration:   7% 49/699 [00:19<04:16,  2.54it/s]\u001b[A\n",
      "Iteration:   7% 50/699 [00:19<04:15,  2.54it/s]\u001b[A\n",
      "Iteration:   7% 51/699 [00:19<04:15,  2.54it/s]\u001b[A\n",
      "Iteration:   7% 52/699 [00:20<04:16,  2.52it/s]\u001b[A\n",
      "Iteration:   8% 53/699 [00:20<04:16,  2.52it/s]\u001b[A\n",
      "Iteration:   8% 54/699 [00:21<04:15,  2.52it/s]\u001b[A\n",
      "Iteration:   8% 55/699 [00:21<04:14,  2.53it/s]\u001b[A\n",
      "Iteration:   8% 56/699 [00:21<04:14,  2.53it/s]\u001b[A\n",
      "Iteration:   8% 57/699 [00:22<04:14,  2.52it/s]\u001b[A\n",
      "Iteration:   8% 58/699 [00:22<04:14,  2.52it/s]\u001b[A\n",
      "Iteration:   8% 59/699 [00:23<04:13,  2.52it/s]\u001b[A\n",
      "Iteration:   9% 60/699 [00:23<04:13,  2.52it/s]\u001b[A\n",
      "Iteration:   9% 61/699 [00:23<04:12,  2.52it/s]\u001b[A\n",
      "Iteration:   9% 62/699 [00:24<04:12,  2.52it/s]\u001b[A\n",
      "Iteration:   9% 63/699 [00:24<04:12,  2.52it/s]\u001b[A\n",
      "Iteration:   9% 64/699 [00:25<04:12,  2.52it/s]\u001b[A\n",
      "Iteration:   9% 65/699 [00:25<04:12,  2.51it/s]\u001b[A\n",
      "Iteration:   9% 66/699 [00:25<04:11,  2.52it/s]\u001b[A\n",
      "Iteration:  10% 67/699 [00:26<04:11,  2.51it/s]\u001b[A\n",
      "Iteration:  10% 68/699 [00:26<04:11,  2.51it/s]\u001b[A\n",
      "Iteration:  10% 69/699 [00:27<04:11,  2.50it/s]\u001b[A\n",
      "Iteration:  10% 70/699 [00:27<04:10,  2.51it/s]\u001b[A\n",
      "Iteration:  10% 71/699 [00:27<04:10,  2.50it/s]\u001b[A\n",
      "Iteration:  10% 72/699 [00:28<04:10,  2.50it/s]\u001b[A\n",
      "Iteration:  10% 73/699 [00:28<04:10,  2.50it/s]\u001b[A\n",
      "Iteration:  11% 74/699 [00:29<04:10,  2.50it/s]\u001b[A\n",
      "Iteration:  11% 75/699 [00:29<04:09,  2.50it/s]\u001b[A\n",
      "Iteration:  11% 76/699 [00:29<04:09,  2.50it/s]\u001b[A\n",
      "Iteration:  11% 77/699 [00:30<04:09,  2.49it/s]\u001b[A\n",
      "Iteration:  11% 78/699 [00:30<04:08,  2.50it/s]\u001b[A\n",
      "Iteration:  11% 79/699 [00:31<04:08,  2.49it/s]\u001b[A\n",
      "Iteration:  11% 80/699 [00:31<04:07,  2.50it/s]\u001b[A\n",
      "Iteration:  12% 81/699 [00:31<04:08,  2.49it/s]\u001b[A\n",
      "Iteration:  12% 82/699 [00:32<04:08,  2.48it/s]\u001b[A\n",
      "Iteration:  12% 83/699 [00:32<04:08,  2.48it/s]\u001b[A\n",
      "Iteration:  12% 84/699 [00:33<04:07,  2.48it/s]\u001b[A\n",
      "Iteration:  12% 85/699 [00:33<04:07,  2.48it/s]\u001b[A\n",
      "Iteration:  12% 86/699 [00:33<04:06,  2.48it/s]\u001b[A\n",
      "Iteration:  12% 87/699 [00:34<04:06,  2.48it/s]\u001b[A\n",
      "Iteration:  13% 88/699 [00:34<04:06,  2.48it/s]\u001b[A\n",
      "Iteration:  13% 89/699 [00:35<04:06,  2.48it/s]\u001b[A\n",
      "Iteration:  13% 90/699 [00:35<04:06,  2.48it/s]\u001b[A\n",
      "Iteration:  13% 91/699 [00:35<04:06,  2.47it/s]\u001b[A\n",
      "Iteration:  13% 92/699 [00:36<04:05,  2.47it/s]\u001b[A\n",
      "Iteration:  13% 93/699 [00:36<04:05,  2.47it/s]\u001b[A\n",
      "Iteration:  13% 94/699 [00:37<04:04,  2.47it/s]\u001b[A\n",
      "Iteration:  14% 95/699 [00:37<04:04,  2.47it/s]\u001b[A\n",
      "Iteration:  14% 96/699 [00:37<04:04,  2.46it/s]\u001b[A\n",
      "Iteration:  14% 97/699 [00:38<04:03,  2.47it/s]\u001b[A\n",
      "Iteration:  14% 98/699 [00:38<04:03,  2.46it/s]\u001b[A\n",
      "Iteration:  14% 99/699 [00:39<04:03,  2.46it/s]\u001b[A\n",
      "Iteration:  14% 100/699 [00:39<04:02,  2.47it/s]\u001b[A\n",
      "Iteration:  14% 101/699 [00:40<04:02,  2.47it/s]\u001b[A\n",
      "Iteration:  15% 102/699 [00:40<04:00,  2.48it/s]\u001b[A\n",
      "Iteration:  15% 103/699 [00:40<04:01,  2.47it/s]\u001b[A\n",
      "Iteration:  15% 104/699 [00:41<04:00,  2.48it/s]\u001b[A\n",
      "Iteration:  15% 105/699 [00:41<03:59,  2.48it/s]\u001b[A\n",
      "Iteration:  15% 106/699 [00:42<04:00,  2.47it/s]\u001b[A\n",
      "Iteration:  15% 107/699 [00:42<03:58,  2.48it/s]\u001b[A\n",
      "Iteration:  15% 108/699 [00:42<03:58,  2.48it/s]\u001b[A\n",
      "Iteration:  16% 109/699 [00:43<03:57,  2.48it/s]\u001b[A\n",
      "Iteration:  16% 110/699 [00:43<03:57,  2.48it/s]\u001b[A\n",
      "Iteration:  16% 111/699 [00:44<03:57,  2.47it/s]\u001b[A\n",
      "Iteration:  16% 112/699 [00:44<03:57,  2.47it/s]\u001b[A\n",
      "Iteration:  16% 113/699 [00:44<03:56,  2.48it/s]\u001b[A\n",
      "Iteration:  16% 114/699 [00:45<03:56,  2.48it/s]\u001b[A\n",
      "Iteration:  16% 115/699 [00:45<03:55,  2.48it/s]\u001b[A\n",
      "Iteration:  17% 116/699 [00:46<03:56,  2.47it/s]\u001b[A\n",
      "Iteration:  17% 117/699 [00:46<03:55,  2.47it/s]\u001b[A\n",
      "Iteration:  17% 118/699 [00:46<03:55,  2.47it/s]\u001b[A\n",
      "Iteration:  17% 119/699 [00:47<03:54,  2.47it/s]\u001b[A\n",
      "Iteration:  17% 120/699 [00:47<03:54,  2.47it/s]\u001b[A\n",
      "Iteration:  17% 121/699 [00:48<03:54,  2.46it/s]\u001b[A\n",
      "Iteration:  17% 122/699 [00:48<03:54,  2.47it/s]\u001b[A\n",
      "Iteration:  18% 123/699 [00:48<03:53,  2.47it/s]\u001b[A\n",
      "Iteration:  18% 124/699 [00:49<03:53,  2.47it/s]\u001b[A\n",
      "Iteration:  18% 125/699 [00:49<03:52,  2.47it/s]\u001b[A\n",
      "Iteration:  18% 126/699 [00:50<03:52,  2.47it/s]\u001b[A\n",
      "Iteration:  18% 127/699 [00:50<03:52,  2.46it/s]\u001b[A\n",
      "Iteration:  18% 128/699 [00:50<03:51,  2.47it/s]\u001b[A\n",
      "Iteration:  18% 129/699 [00:51<03:51,  2.46it/s]\u001b[A\n",
      "Iteration:  19% 130/699 [00:51<03:51,  2.46it/s]\u001b[A\n",
      "Iteration:  19% 131/699 [00:52<03:50,  2.46it/s]\u001b[A\n",
      "Iteration:  19% 132/699 [00:52<03:50,  2.46it/s]\u001b[A\n",
      "Iteration:  19% 133/699 [00:52<03:49,  2.46it/s]\u001b[A\n",
      "Iteration:  19% 134/699 [00:53<03:49,  2.46it/s]\u001b[A\n",
      "Iteration:  19% 135/699 [00:53<03:50,  2.45it/s]\u001b[A\n",
      "Iteration:  19% 136/699 [00:54<03:49,  2.45it/s]\u001b[A\n",
      "Iteration:  20% 137/699 [00:54<03:49,  2.45it/s]\u001b[A\n",
      "Iteration:  20% 138/699 [00:55<03:49,  2.45it/s]\u001b[A\n",
      "Iteration:  20% 139/699 [00:55<03:48,  2.45it/s]\u001b[A\n",
      "Iteration:  20% 140/699 [00:55<03:48,  2.45it/s]\u001b[A\n",
      "Iteration:  20% 141/699 [00:56<03:48,  2.44it/s]\u001b[A\n",
      "Iteration:  20% 142/699 [00:56<03:48,  2.44it/s]\u001b[A\n",
      "Iteration:  20% 143/699 [00:57<03:48,  2.43it/s]\u001b[A\n",
      "Iteration:  21% 144/699 [00:57<03:47,  2.43it/s]\u001b[A\n",
      "Iteration:  21% 145/699 [00:57<03:47,  2.43it/s]\u001b[A\n",
      "Iteration:  21% 146/699 [00:58<03:47,  2.43it/s]\u001b[A\n",
      "Iteration:  21% 147/699 [00:58<03:46,  2.43it/s]\u001b[A\n",
      "Iteration:  21% 148/699 [00:59<03:47,  2.43it/s]\u001b[A\n",
      "Iteration:  21% 149/699 [00:59<03:46,  2.43it/s]\u001b[A\n",
      "Iteration:  21% 150/699 [00:59<03:45,  2.43it/s]\u001b[A\n",
      "Iteration:  22% 151/699 [01:00<03:45,  2.43it/s]\u001b[A\n",
      "Iteration:  22% 152/699 [01:00<03:45,  2.43it/s]\u001b[A\n",
      "Iteration:  22% 153/699 [01:01<03:45,  2.42it/s]\u001b[A\n",
      "Iteration:  22% 154/699 [01:01<03:45,  2.42it/s]\u001b[A\n",
      "Iteration:  22% 155/699 [01:02<03:44,  2.42it/s]\u001b[A\n",
      "Iteration:  22% 156/699 [01:02<03:44,  2.42it/s]\u001b[A\n",
      "Iteration:  22% 157/699 [01:02<03:44,  2.42it/s]\u001b[A\n",
      "Iteration:  23% 158/699 [01:03<03:44,  2.41it/s]\u001b[A\n",
      "Iteration:  23% 159/699 [01:03<03:44,  2.41it/s]\u001b[A\n",
      "Iteration:  23% 160/699 [01:04<03:43,  2.41it/s]\u001b[A\n",
      "Iteration:  23% 161/699 [01:04<03:43,  2.40it/s]\u001b[A\n",
      "Iteration:  23% 162/699 [01:04<03:43,  2.40it/s]\u001b[A\n",
      "Iteration:  23% 163/699 [01:05<03:43,  2.40it/s]\u001b[A\n",
      "Iteration:  23% 164/699 [01:05<03:43,  2.39it/s]\u001b[A\n",
      "Iteration:  24% 165/699 [01:06<03:42,  2.40it/s]\u001b[A\n",
      "Iteration:  24% 166/699 [01:06<03:42,  2.39it/s]\u001b[A\n",
      "Iteration:  24% 167/699 [01:07<03:41,  2.40it/s]\u001b[A\n",
      "Iteration:  24% 168/699 [01:07<03:41,  2.39it/s]\u001b[A\n",
      "Iteration:  24% 169/699 [01:07<03:42,  2.39it/s]\u001b[A\n",
      "Iteration:  24% 170/699 [01:08<03:41,  2.39it/s]\u001b[A\n",
      "Iteration:  24% 171/699 [01:08<03:42,  2.37it/s]\u001b[A\n",
      "Iteration:  25% 172/699 [01:09<03:41,  2.38it/s]\u001b[A\n",
      "Iteration:  25% 173/699 [01:09<03:41,  2.38it/s]\u001b[A\n",
      "Iteration:  25% 174/699 [01:09<03:40,  2.38it/s]\u001b[A\n",
      "Iteration:  25% 175/699 [01:10<03:40,  2.38it/s]\u001b[A\n",
      "Iteration:  25% 176/699 [01:10<03:41,  2.36it/s]\u001b[A\n",
      "Iteration:  25% 177/699 [01:11<03:40,  2.36it/s]\u001b[A\n",
      "Iteration:  25% 178/699 [01:11<03:41,  2.36it/s]\u001b[A\n",
      "Iteration:  26% 179/699 [01:12<03:40,  2.36it/s]\u001b[A\n",
      "Iteration:  26% 180/699 [01:12<03:39,  2.36it/s]\u001b[A\n",
      "Iteration:  26% 181/699 [01:12<03:40,  2.35it/s]\u001b[A\n",
      "Iteration:  26% 182/699 [01:13<03:39,  2.35it/s]\u001b[A\n",
      "Iteration:  26% 183/699 [01:13<03:39,  2.35it/s]\u001b[A\n",
      "Iteration:  26% 184/699 [01:14<03:38,  2.35it/s]\u001b[A\n",
      "Iteration:  26% 185/699 [01:14<03:38,  2.36it/s]\u001b[A\n",
      "Iteration:  27% 186/699 [01:15<03:38,  2.35it/s]\u001b[A\n",
      "Iteration:  27% 187/699 [01:15<03:37,  2.35it/s]\u001b[A\n",
      "Iteration:  27% 188/699 [01:15<03:36,  2.36it/s]\u001b[A\n",
      "Iteration:  27% 189/699 [01:16<03:36,  2.35it/s]\u001b[A\n",
      "Iteration:  27% 190/699 [01:16<03:36,  2.35it/s]\u001b[A\n",
      "Iteration:  27% 191/699 [01:17<03:36,  2.35it/s]\u001b[A\n",
      "Iteration:  27% 192/699 [01:17<03:35,  2.35it/s]\u001b[A\n",
      "Iteration:  28% 193/699 [01:18<03:35,  2.35it/s]\u001b[A\n",
      "Iteration:  28% 194/699 [01:18<03:34,  2.35it/s]\u001b[A\n",
      "Iteration:  28% 195/699 [01:18<03:34,  2.35it/s]\u001b[A\n",
      "Iteration:  28% 196/699 [01:19<03:33,  2.35it/s]\u001b[A\n",
      "Iteration:  28% 197/699 [01:19<03:33,  2.35it/s]\u001b[A\n",
      "Iteration:  28% 198/699 [01:20<03:33,  2.35it/s]\u001b[A\n",
      "Iteration:  28% 199/699 [01:20<03:32,  2.35it/s]\u001b[A\n",
      "Iteration:  29% 200/699 [01:21<03:32,  2.35it/s]\u001b[A\n",
      "Iteration:  29% 201/699 [01:21<03:32,  2.35it/s]\u001b[A\n",
      "Iteration:  29% 202/699 [01:21<03:31,  2.35it/s]\u001b[A\n",
      "Iteration:  29% 203/699 [01:22<03:30,  2.35it/s]\u001b[A\n",
      "Iteration:  29% 204/699 [01:22<03:30,  2.35it/s]\u001b[A\n",
      "Iteration:  29% 205/699 [01:23<03:30,  2.35it/s]\u001b[A\n",
      "Iteration:  29% 206/699 [01:23<03:29,  2.35it/s]\u001b[A\n",
      "Iteration:  30% 207/699 [01:24<03:29,  2.35it/s]\u001b[A\n",
      "Iteration:  30% 208/699 [01:24<03:28,  2.35it/s]\u001b[A\n",
      "Iteration:  30% 209/699 [01:24<03:29,  2.34it/s]\u001b[A\n",
      "Iteration:  30% 210/699 [01:25<03:28,  2.35it/s]\u001b[A\n",
      "Iteration:  30% 211/699 [01:25<03:27,  2.35it/s]\u001b[A\n",
      "Iteration:  30% 212/699 [01:26<03:26,  2.35it/s]\u001b[A\n",
      "Iteration:  30% 213/699 [01:26<03:26,  2.35it/s]\u001b[A\n",
      "Iteration:  31% 214/699 [01:26<03:25,  2.36it/s]\u001b[A\n",
      "Iteration:  31% 215/699 [01:27<03:25,  2.36it/s]\u001b[A\n",
      "Iteration:  31% 216/699 [01:27<03:25,  2.35it/s]\u001b[A\n",
      "Iteration:  31% 217/699 [01:28<03:24,  2.35it/s]\u001b[A\n",
      "Iteration:  31% 218/699 [01:28<03:24,  2.35it/s]\u001b[A\n",
      "Iteration:  31% 219/699 [01:29<03:23,  2.35it/s]\u001b[A\n",
      "Iteration:  31% 220/699 [01:29<03:23,  2.36it/s]\u001b[A\n",
      "Iteration:  32% 221/699 [01:29<03:22,  2.36it/s]\u001b[A\n",
      "Iteration:  32% 222/699 [01:30<03:21,  2.36it/s]\u001b[A\n",
      "Iteration:  32% 223/699 [01:30<03:21,  2.36it/s]\u001b[A\n",
      "Iteration:  32% 224/699 [01:31<03:20,  2.37it/s]\u001b[A\n",
      "Iteration:  32% 225/699 [01:31<03:20,  2.36it/s]\u001b[A\n",
      "Iteration:  32% 226/699 [01:32<03:19,  2.37it/s]\u001b[A\n",
      "Iteration:  32% 227/699 [01:32<03:19,  2.36it/s]\u001b[A\n",
      "Iteration:  33% 228/699 [01:32<03:19,  2.36it/s]\u001b[A\n",
      "Iteration:  33% 229/699 [01:33<03:18,  2.36it/s]\u001b[A\n",
      "Iteration:  33% 230/699 [01:33<03:18,  2.37it/s]\u001b[A\n",
      "Iteration:  33% 231/699 [01:34<03:17,  2.37it/s]\u001b[A\n",
      "Iteration:  33% 232/699 [01:34<03:17,  2.37it/s]\u001b[A\n",
      "Iteration:  33% 233/699 [01:35<03:17,  2.37it/s]\u001b[A\n",
      "Iteration:  33% 234/699 [01:35<03:16,  2.37it/s]\u001b[A\n",
      "Iteration:  34% 235/699 [01:35<03:16,  2.37it/s]\u001b[A\n",
      "Iteration:  34% 236/699 [01:36<03:15,  2.37it/s]\u001b[A\n",
      "Iteration:  34% 237/699 [01:36<03:14,  2.37it/s]\u001b[A\n",
      "Iteration:  34% 238/699 [01:37<03:14,  2.37it/s]\u001b[A\n",
      "Iteration:  34% 239/699 [01:37<03:14,  2.37it/s]\u001b[A\n",
      "Iteration:  34% 240/699 [01:37<03:13,  2.37it/s]\u001b[A\n",
      "Iteration:  34% 241/699 [01:38<03:12,  2.37it/s]\u001b[A\n",
      "Iteration:  35% 242/699 [01:38<03:12,  2.37it/s]\u001b[A\n",
      "Iteration:  35% 243/699 [01:39<03:11,  2.38it/s]\u001b[A\n",
      "Iteration:  35% 244/699 [01:39<03:11,  2.38it/s]\u001b[A\n",
      "Iteration:  35% 245/699 [01:40<03:10,  2.38it/s]\u001b[A\n",
      "Iteration:  35% 246/699 [01:40<03:10,  2.38it/s]\u001b[A\n",
      "Iteration:  35% 247/699 [01:40<03:10,  2.37it/s]\u001b[A\n",
      "Iteration:  35% 248/699 [01:41<03:10,  2.37it/s]\u001b[A\n",
      "Iteration:  36% 249/699 [01:41<03:09,  2.37it/s]\u001b[A\n",
      "Iteration:  36% 250/699 [01:42<03:08,  2.38it/s]\u001b[A\n",
      "Iteration:  36% 251/699 [01:42<03:08,  2.38it/s]\u001b[A\n",
      "Iteration:  36% 252/699 [01:43<03:07,  2.38it/s]\u001b[A\n",
      "Iteration:  36% 253/699 [01:43<03:07,  2.38it/s]\u001b[A\n",
      "Iteration:  36% 254/699 [01:43<03:07,  2.38it/s]\u001b[A\n",
      "Iteration:  36% 255/699 [01:44<03:06,  2.38it/s]\u001b[A\n",
      "Iteration:  37% 256/699 [01:44<03:05,  2.38it/s]\u001b[A\n",
      "Iteration:  37% 257/699 [01:45<03:05,  2.39it/s]\u001b[A\n",
      "Iteration:  37% 258/699 [01:45<03:04,  2.39it/s]\u001b[A\n",
      "Iteration:  37% 259/699 [01:45<03:04,  2.39it/s]\u001b[A\n",
      "Iteration:  37% 260/699 [01:46<03:03,  2.39it/s]\u001b[A\n",
      "Iteration:  37% 261/699 [01:46<03:03,  2.39it/s]\u001b[A\n",
      "Iteration:  37% 262/699 [01:47<03:02,  2.40it/s]\u001b[A\n",
      "Iteration:  38% 263/699 [01:47<03:02,  2.39it/s]\u001b[A\n",
      "Iteration:  38% 264/699 [01:48<03:02,  2.39it/s]\u001b[A\n",
      "Iteration:  38% 265/699 [01:48<03:01,  2.40it/s]\u001b[A\n",
      "Iteration:  38% 266/699 [01:48<03:00,  2.39it/s]\u001b[A\n",
      "Iteration:  38% 267/699 [01:49<03:00,  2.40it/s]\u001b[A\n",
      "Iteration:  38% 268/699 [01:49<03:00,  2.39it/s]\u001b[A\n",
      "Iteration:  38% 269/699 [01:50<02:59,  2.40it/s]\u001b[A\n",
      "Iteration:  39% 270/699 [01:50<02:58,  2.40it/s]\u001b[A\n",
      "Iteration:  39% 271/699 [01:50<02:58,  2.40it/s]\u001b[A\n",
      "Iteration:  39% 272/699 [01:51<02:58,  2.40it/s]\u001b[A\n",
      "Iteration:  39% 273/699 [01:51<02:58,  2.39it/s]\u001b[A\n",
      "Iteration:  39% 274/699 [01:52<02:57,  2.40it/s]\u001b[A\n",
      "Iteration:  39% 275/699 [01:52<02:56,  2.40it/s]\u001b[A\n",
      "Iteration:  39% 276/699 [01:53<02:56,  2.40it/s]\u001b[A\n",
      "Iteration:  40% 277/699 [01:53<02:55,  2.41it/s]\u001b[A\n",
      "Iteration:  40% 278/699 [01:53<02:55,  2.40it/s]\u001b[A\n",
      "Iteration:  40% 279/699 [01:54<02:54,  2.40it/s]\u001b[A\n",
      "Iteration:  40% 280/699 [01:54<02:54,  2.40it/s]\u001b[A\n",
      "Iteration:  40% 281/699 [01:55<02:53,  2.40it/s]\u001b[A\n",
      "Iteration:  40% 282/699 [01:55<02:53,  2.40it/s]\u001b[A\n",
      "Iteration:  40% 283/699 [01:55<02:52,  2.41it/s]\u001b[A\n",
      "Iteration:  41% 284/699 [01:56<02:52,  2.41it/s]\u001b[A\n",
      "Iteration:  41% 285/699 [01:56<02:51,  2.41it/s]\u001b[A\n",
      "Iteration:  41% 286/699 [01:57<02:51,  2.41it/s]\u001b[A\n",
      "Iteration:  41% 287/699 [01:57<02:51,  2.41it/s]\u001b[A\n",
      "Iteration:  41% 288/699 [01:58<02:50,  2.41it/s]\u001b[A\n",
      "Iteration:  41% 289/699 [01:58<02:50,  2.41it/s]\u001b[A\n",
      "Iteration:  41% 290/699 [01:58<02:49,  2.41it/s]\u001b[A\n",
      "Iteration:  42% 291/699 [01:59<02:49,  2.41it/s]\u001b[A\n",
      "Iteration:  42% 292/699 [01:59<02:48,  2.41it/s]\u001b[A\n",
      "Iteration:  42% 293/699 [02:00<02:48,  2.42it/s]\u001b[A\n",
      "Iteration:  42% 294/699 [02:00<02:47,  2.42it/s]\u001b[A\n",
      "Iteration:  42% 295/699 [02:00<02:47,  2.41it/s]\u001b[A\n",
      "Iteration:  42% 296/699 [02:01<02:47,  2.41it/s]\u001b[A\n",
      "Iteration:  42% 297/699 [02:01<02:46,  2.41it/s]\u001b[A\n",
      "Iteration:  43% 298/699 [02:02<02:46,  2.41it/s]\u001b[A\n",
      "Iteration:  43% 299/699 [02:02<02:46,  2.40it/s]\u001b[A\n",
      "Iteration:  43% 300/699 [02:03<02:45,  2.41it/s]\u001b[A\n",
      "Iteration:  43% 301/699 [02:03<02:45,  2.40it/s]\u001b[A\n",
      "Iteration:  43% 302/699 [02:03<02:44,  2.41it/s]\u001b[A\n",
      "Iteration:  43% 303/699 [02:04<02:44,  2.41it/s]\u001b[A\n",
      "Iteration:  43% 304/699 [02:04<02:43,  2.41it/s]\u001b[A\n",
      "Iteration:  44% 305/699 [02:05<02:42,  2.42it/s]\u001b[A\n",
      "Iteration:  44% 306/699 [02:05<02:42,  2.41it/s]\u001b[A\n",
      "Iteration:  44% 307/699 [02:05<02:42,  2.41it/s]\u001b[A\n",
      "Iteration:  44% 308/699 [02:06<02:41,  2.41it/s]\u001b[A\n",
      "Iteration:  44% 309/699 [02:06<02:41,  2.41it/s]\u001b[A\n",
      "Iteration:  44% 310/699 [02:07<02:41,  2.41it/s]\u001b[A\n",
      "Iteration:  44% 311/699 [02:07<02:40,  2.41it/s]\u001b[A\n",
      "Iteration:  45% 312/699 [02:07<02:40,  2.42it/s]\u001b[A\n",
      "Iteration:  45% 313/699 [02:08<02:39,  2.42it/s]\u001b[A\n",
      "Iteration:  45% 314/699 [02:08<02:39,  2.42it/s]\u001b[A\n",
      "Iteration:  45% 315/699 [02:09<02:38,  2.42it/s]\u001b[A\n",
      "Iteration:  45% 316/699 [02:09<02:38,  2.41it/s]\u001b[A\n",
      "Iteration:  45% 317/699 [02:10<02:38,  2.41it/s]\u001b[A\n",
      "Iteration:  45% 318/699 [02:10<02:37,  2.41it/s]\u001b[A\n",
      "Iteration:  46% 319/699 [02:10<02:37,  2.42it/s]\u001b[A\n",
      "Iteration:  46% 320/699 [02:11<02:36,  2.42it/s]\u001b[A\n",
      "Iteration:  46% 321/699 [02:11<02:36,  2.42it/s]\u001b[A\n",
      "Iteration:  46% 322/699 [02:12<02:36,  2.41it/s]\u001b[A\n",
      "Iteration:  46% 323/699 [02:12<02:35,  2.42it/s]\u001b[A\n",
      "Iteration:  46% 324/699 [02:12<02:35,  2.41it/s]\u001b[A\n",
      "Iteration:  46% 325/699 [02:13<02:35,  2.41it/s]\u001b[A\n",
      "Iteration:  47% 326/699 [02:13<02:34,  2.41it/s]\u001b[A\n",
      "Iteration:  47% 327/699 [02:14<02:34,  2.41it/s]\u001b[A\n",
      "Iteration:  47% 328/699 [02:14<02:33,  2.42it/s]\u001b[A\n",
      "Iteration:  47% 329/699 [02:15<02:33,  2.41it/s]\u001b[A\n",
      "Iteration:  47% 330/699 [02:15<02:33,  2.41it/s]\u001b[A\n",
      "Iteration:  47% 331/699 [02:15<02:32,  2.42it/s]\u001b[A\n",
      "Iteration:  47% 332/699 [02:16<02:32,  2.41it/s]\u001b[A\n",
      "Iteration:  48% 333/699 [02:16<02:31,  2.41it/s]\u001b[A\n",
      "Iteration:  48% 334/699 [02:17<02:30,  2.42it/s]\u001b[A\n",
      "Iteration:  48% 335/699 [02:17<02:30,  2.42it/s]\u001b[A\n",
      "Iteration:  48% 336/699 [02:17<02:30,  2.42it/s]\u001b[A\n",
      "Iteration:  48% 337/699 [02:18<02:29,  2.42it/s]\u001b[A\n",
      "Iteration:  48% 338/699 [02:18<02:29,  2.41it/s]\u001b[A\n",
      "Iteration:  48% 339/699 [02:19<02:29,  2.41it/s]\u001b[A\n",
      "Iteration:  49% 340/699 [02:19<02:29,  2.40it/s]\u001b[A\n",
      "Iteration:  49% 341/699 [02:19<02:28,  2.41it/s]\u001b[A\n",
      "Iteration:  49% 342/699 [02:20<02:28,  2.41it/s]\u001b[A\n",
      "Iteration:  49% 343/699 [02:20<02:27,  2.41it/s]\u001b[A\n",
      "Iteration:  49% 344/699 [02:21<02:27,  2.41it/s]\u001b[A\n",
      "Iteration:  49% 345/699 [02:21<02:27,  2.41it/s]\u001b[A\n",
      "Iteration:  49% 346/699 [02:22<02:26,  2.41it/s]\u001b[A\n",
      "Iteration:  50% 347/699 [02:22<02:26,  2.41it/s]\u001b[A\n",
      "Iteration:  50% 348/699 [02:22<02:25,  2.41it/s]\u001b[A\n",
      "Iteration:  50% 349/699 [02:23<02:25,  2.41it/s]\u001b[A\n",
      "Iteration:  50% 350/699 [02:23<02:25,  2.40it/s]\u001b[A\n",
      "Iteration:  50% 351/699 [02:24<02:24,  2.40it/s]\u001b[A\n",
      "Iteration:  50% 352/699 [02:24<02:24,  2.40it/s]\u001b[A\n",
      "Iteration:  51% 353/699 [02:24<02:23,  2.40it/s]\u001b[A\n",
      "Iteration:  51% 354/699 [02:25<02:23,  2.40it/s]\u001b[A\n",
      "Iteration:  51% 355/699 [02:25<02:23,  2.40it/s]\u001b[A\n",
      "Iteration:  51% 356/699 [02:26<02:22,  2.40it/s]\u001b[A\n",
      "Iteration:  51% 357/699 [02:26<02:22,  2.40it/s]\u001b[A\n",
      "Iteration:  51% 358/699 [02:27<02:22,  2.40it/s]\u001b[A\n",
      "Iteration:  51% 359/699 [02:27<02:21,  2.40it/s]\u001b[A\n",
      "Iteration:  52% 360/699 [02:27<02:21,  2.40it/s]\u001b[A\n",
      "Iteration:  52% 361/699 [02:28<02:21,  2.40it/s]\u001b[A\n",
      "Iteration:  52% 362/699 [02:28<02:20,  2.41it/s]\u001b[A\n",
      "Iteration:  52% 363/699 [02:29<02:19,  2.40it/s]\u001b[A\n",
      "Iteration:  52% 364/699 [02:29<02:19,  2.40it/s]\u001b[A\n",
      "Iteration:  52% 365/699 [02:29<02:19,  2.40it/s]\u001b[A\n",
      "Iteration:  52% 366/699 [02:30<02:18,  2.40it/s]\u001b[A\n",
      "Iteration:  53% 367/699 [02:30<02:18,  2.40it/s]\u001b[A\n",
      "Iteration:  53% 368/699 [02:31<02:18,  2.40it/s]\u001b[A\n",
      "Iteration:  53% 369/699 [02:31<02:17,  2.40it/s]\u001b[A\n",
      "Iteration:  53% 370/699 [02:32<02:17,  2.40it/s]\u001b[A\n",
      "Iteration:  53% 371/699 [02:32<02:16,  2.40it/s]\u001b[A\n",
      "Iteration:  53% 372/699 [02:32<02:17,  2.38it/s]\u001b[A\n",
      "Iteration:  53% 373/699 [02:33<02:15,  2.41it/s]\u001b[A\n",
      "Iteration:  54% 374/699 [02:33<02:15,  2.40it/s]\u001b[A\n",
      "Iteration:  54% 375/699 [02:34<02:14,  2.41it/s]\u001b[A\n",
      "Iteration:  54% 376/699 [02:34<02:14,  2.40it/s]\u001b[A\n",
      "Iteration:  54% 377/699 [02:34<02:14,  2.40it/s]\u001b[A\n",
      "Iteration:  54% 378/699 [02:35<02:13,  2.40it/s]\u001b[A\n",
      "Iteration:  54% 379/699 [02:35<02:13,  2.40it/s]\u001b[A\n",
      "Iteration:  54% 380/699 [02:36<02:13,  2.40it/s]\u001b[A\n",
      "Iteration:  55% 381/699 [02:36<02:12,  2.40it/s]\u001b[A\n",
      "Iteration:  55% 382/699 [02:37<02:12,  2.40it/s]\u001b[A\n",
      "Iteration:  55% 383/699 [02:37<02:12,  2.38it/s]\u001b[A\n",
      "Iteration:  55% 384/699 [02:37<02:11,  2.40it/s]\u001b[A\n",
      "Iteration:  55% 385/699 [02:38<02:10,  2.40it/s]\u001b[A\n",
      "Iteration:  55% 386/699 [02:38<02:10,  2.40it/s]\u001b[A\n",
      "Iteration:  55% 387/699 [02:39<02:09,  2.40it/s]\u001b[A\n",
      "Iteration:  56% 388/699 [02:39<02:09,  2.39it/s]\u001b[A\n",
      "Iteration:  56% 389/699 [02:39<02:09,  2.40it/s]\u001b[A\n",
      "Iteration:  56% 390/699 [02:40<02:09,  2.39it/s]\u001b[A\n",
      "Iteration:  56% 391/699 [02:40<02:08,  2.39it/s]\u001b[A\n",
      "Iteration:  56% 392/699 [02:41<02:08,  2.39it/s]\u001b[A\n",
      "Iteration:  56% 393/699 [02:41<02:07,  2.39it/s]\u001b[A\n",
      "Iteration:  56% 394/699 [02:42<02:07,  2.40it/s]\u001b[A\n",
      "Iteration:  57% 395/699 [02:42<02:07,  2.39it/s]\u001b[A\n",
      "Iteration:  57% 396/699 [02:42<02:06,  2.39it/s]\u001b[A\n",
      "Iteration:  57% 397/699 [02:43<02:06,  2.39it/s]\u001b[A\n",
      "Iteration:  57% 398/699 [02:43<02:06,  2.38it/s]\u001b[A\n",
      "Iteration:  57% 399/699 [02:44<02:05,  2.39it/s]\u001b[A\n",
      "Iteration:  57% 400/699 [02:44<02:05,  2.38it/s]\u001b[A\n",
      "Iteration:  57% 401/699 [02:45<02:04,  2.39it/s]\u001b[A\n",
      "Iteration:  58% 402/699 [02:45<02:04,  2.38it/s]\u001b[A\n",
      "Iteration:  58% 403/699 [02:45<02:04,  2.38it/s]\u001b[A\n",
      "Iteration:  58% 404/699 [02:46<02:03,  2.38it/s]\u001b[A\n",
      "Iteration:  58% 405/699 [02:46<02:03,  2.38it/s]\u001b[A\n",
      "Iteration:  58% 406/699 [02:47<02:02,  2.38it/s]\u001b[A\n",
      "Iteration:  58% 407/699 [02:47<02:02,  2.38it/s]\u001b[A\n",
      "Iteration:  58% 408/699 [02:47<02:01,  2.39it/s]\u001b[A\n",
      "Iteration:  59% 409/699 [02:48<02:01,  2.39it/s]\u001b[A\n",
      "Iteration:  59% 410/699 [02:48<02:01,  2.38it/s]\u001b[A\n",
      "Iteration:  59% 411/699 [02:49<02:00,  2.39it/s]\u001b[A\n",
      "Iteration:  59% 412/699 [02:49<02:00,  2.39it/s]\u001b[A\n",
      "Iteration:  59% 413/699 [02:50<01:59,  2.39it/s]\u001b[A\n",
      "Iteration:  59% 414/699 [02:50<01:59,  2.38it/s]\u001b[A\n",
      "Iteration:  59% 415/699 [02:50<01:58,  2.39it/s]\u001b[A\n",
      "Iteration:  60% 416/699 [02:51<01:58,  2.39it/s]\u001b[A\n",
      "Iteration:  60% 417/699 [02:51<01:58,  2.38it/s]\u001b[A\n",
      "Iteration:  60% 418/699 [02:52<01:58,  2.38it/s]\u001b[A\n",
      "Iteration:  60% 419/699 [02:52<01:57,  2.38it/s]\u001b[A\n",
      "Iteration:  60% 420/699 [02:52<01:57,  2.38it/s]\u001b[A\n",
      "Iteration:  60% 421/699 [02:53<01:56,  2.38it/s]\u001b[A\n",
      "Iteration:  60% 422/699 [02:53<01:56,  2.39it/s]\u001b[A\n",
      "Iteration:  61% 423/699 [02:54<01:55,  2.38it/s]\u001b[A\n",
      "Iteration:  61% 424/699 [02:54<01:55,  2.39it/s]\u001b[A\n",
      "Iteration:  61% 425/699 [02:55<01:54,  2.38it/s]\u001b[A\n",
      "Iteration:  61% 426/699 [02:55<01:54,  2.38it/s]\u001b[A\n",
      "Iteration:  61% 427/699 [02:55<01:54,  2.38it/s]\u001b[A\n",
      "Iteration:  61% 428/699 [02:56<01:53,  2.39it/s]\u001b[A\n",
      "Iteration:  61% 429/699 [02:56<01:53,  2.39it/s]\u001b[A\n",
      "Iteration:  62% 430/699 [02:57<01:53,  2.38it/s]\u001b[A\n",
      "Iteration:  62% 431/699 [02:57<01:52,  2.38it/s]\u001b[A\n",
      "Iteration:  62% 432/699 [02:58<01:52,  2.38it/s]\u001b[A\n",
      "Iteration:  62% 433/699 [02:58<01:51,  2.38it/s]\u001b[A\n",
      "Iteration:  62% 434/699 [02:58<01:51,  2.38it/s]\u001b[A\n",
      "Iteration:  62% 435/699 [02:59<01:51,  2.38it/s]\u001b[A\n",
      "Iteration:  62% 436/699 [02:59<01:50,  2.38it/s]\u001b[A\n",
      "Iteration:  63% 437/699 [03:00<01:49,  2.38it/s]\u001b[A\n",
      "Iteration:  63% 438/699 [03:00<01:49,  2.38it/s]\u001b[A\n",
      "Iteration:  63% 439/699 [03:00<01:49,  2.38it/s]\u001b[A\n",
      "Iteration:  63% 440/699 [03:01<01:48,  2.39it/s]\u001b[A\n",
      "Iteration:  63% 441/699 [03:01<01:48,  2.38it/s]\u001b[A\n",
      "Iteration:  63% 442/699 [03:02<01:47,  2.39it/s]\u001b[A\n",
      "Iteration:  63% 443/699 [03:02<01:47,  2.39it/s]\u001b[A\n",
      "Iteration:  64% 444/699 [03:03<01:46,  2.39it/s]\u001b[A\n",
      "Iteration:  64% 445/699 [03:03<01:47,  2.37it/s]\u001b[A\n",
      "Iteration:  64% 446/699 [03:03<01:46,  2.37it/s]\u001b[A\n",
      "Iteration:  64% 447/699 [03:04<01:45,  2.38it/s]\u001b[A\n",
      "Iteration:  64% 448/699 [03:04<01:45,  2.38it/s]\u001b[A\n",
      "Iteration:  64% 449/699 [03:05<01:44,  2.38it/s]\u001b[A\n",
      "Iteration:  64% 450/699 [03:05<01:44,  2.38it/s]\u001b[A\n",
      "Iteration:  65% 451/699 [03:06<01:43,  2.39it/s]\u001b[A\n",
      "Iteration:  65% 452/699 [03:06<01:43,  2.38it/s]\u001b[A\n",
      "Iteration:  65% 453/699 [03:06<01:43,  2.38it/s]\u001b[A\n",
      "Iteration:  65% 454/699 [03:07<01:42,  2.39it/s]\u001b[A\n",
      "Iteration:  65% 455/699 [03:07<01:42,  2.39it/s]\u001b[A\n",
      "Iteration:  65% 456/699 [03:08<01:41,  2.39it/s]\u001b[A\n",
      "Iteration:  65% 457/699 [03:08<01:41,  2.39it/s]\u001b[A\n",
      "Iteration:  66% 458/699 [03:08<01:40,  2.39it/s]\u001b[A\n",
      "Iteration:  66% 459/699 [03:09<01:40,  2.39it/s]\u001b[A\n",
      "Iteration:  66% 460/699 [03:09<01:40,  2.39it/s]\u001b[A\n",
      "Iteration:  66% 461/699 [03:10<01:39,  2.39it/s]\u001b[A\n",
      "Iteration:  66% 462/699 [03:10<01:39,  2.38it/s]\u001b[A\n",
      "Iteration:  66% 463/699 [03:11<01:38,  2.39it/s]\u001b[A\n",
      "Iteration:  66% 464/699 [03:11<01:38,  2.39it/s]\u001b[A\n",
      "Iteration:  67% 465/699 [03:11<01:37,  2.40it/s]\u001b[A\n",
      "Iteration:  67% 466/699 [03:12<01:37,  2.39it/s]\u001b[A\n",
      "Iteration:  67% 467/699 [03:12<01:37,  2.39it/s]\u001b[A\n",
      "Iteration:  67% 468/699 [03:13<01:36,  2.39it/s]\u001b[A\n",
      "Iteration:  67% 469/699 [03:13<01:36,  2.39it/s]\u001b[A\n",
      "Iteration:  67% 470/699 [03:13<01:35,  2.39it/s]\u001b[A\n",
      "Iteration:  67% 471/699 [03:14<01:35,  2.38it/s]\u001b[A\n",
      "Iteration:  68% 472/699 [03:14<01:35,  2.39it/s]\u001b[A\n",
      "Iteration:  68% 473/699 [03:15<01:34,  2.38it/s]\u001b[A\n",
      "Iteration:  68% 474/699 [03:15<01:34,  2.39it/s]\u001b[A\n",
      "Iteration:  68% 475/699 [03:16<01:33,  2.39it/s]\u001b[A\n",
      "Iteration:  68% 476/699 [03:16<01:33,  2.39it/s]\u001b[A\n",
      "Iteration:  68% 477/699 [03:16<01:32,  2.39it/s]\u001b[A\n",
      "Iteration:  68% 478/699 [03:17<01:32,  2.39it/s]\u001b[A\n",
      "Iteration:  69% 479/699 [03:17<01:32,  2.39it/s]\u001b[A\n",
      "Iteration:  69% 480/699 [03:18<01:31,  2.39it/s]\u001b[A\n",
      "Iteration:  69% 481/699 [03:18<01:31,  2.39it/s]\u001b[A\n",
      "Iteration:  69% 482/699 [03:18<01:30,  2.39it/s]\u001b[A\n",
      "Iteration:  69% 483/699 [03:19<01:30,  2.39it/s]\u001b[A\n",
      "Iteration:  69% 484/699 [03:19<01:29,  2.39it/s]\u001b[A\n",
      "Iteration:  69% 485/699 [03:20<01:29,  2.40it/s]\u001b[A\n",
      "Iteration:  70% 486/699 [03:20<01:29,  2.39it/s]\u001b[A\n",
      "Iteration:  70% 487/699 [03:21<01:28,  2.39it/s]\u001b[A\n",
      "Iteration:  70% 488/699 [03:21<01:28,  2.39it/s]\u001b[A\n",
      "Iteration:  70% 489/699 [03:21<01:27,  2.39it/s]\u001b[A\n",
      "Iteration:  70% 490/699 [03:22<01:27,  2.40it/s]\u001b[A\n",
      "Iteration:  70% 491/699 [03:22<01:26,  2.39it/s]\u001b[A\n",
      "Iteration:  70% 492/699 [03:23<01:26,  2.40it/s]\u001b[A\n",
      "Iteration:  71% 493/699 [03:23<01:26,  2.39it/s]\u001b[A\n",
      "Iteration:  71% 494/699 [03:23<01:25,  2.39it/s]\u001b[A\n",
      "Iteration:  71% 495/699 [03:24<01:25,  2.40it/s]\u001b[A\n",
      "Iteration:  71% 496/699 [03:24<01:24,  2.39it/s]\u001b[A\n",
      "Iteration:  71% 497/699 [03:25<01:24,  2.40it/s]\u001b[A\n",
      "Iteration:  71% 498/699 [03:25<01:23,  2.40it/s]\u001b[A\n",
      "Iteration:  71% 499/699 [03:26<01:23,  2.39it/s]\u001b[A/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:231: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n",
      "05/22/2020 03:41:26 - INFO - transformers.configuration_utils -   Configuration saved in output_gpt_text_1/checkpoint-500/config.json\n",
      "05/22/2020 03:41:27 - INFO - transformers.modeling_utils -   Model weights saved in output_gpt_text_1/checkpoint-500/pytorch_model.bin\n",
      "05/22/2020 03:41:28 - INFO - __main__ -   Saving model checkpoint to output_gpt_text_1/checkpoint-500\n",
      "/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:200: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.\n",
      "  warnings.warn(SAVE_STATE_WARNING, UserWarning)\n",
      "05/22/2020 03:41:32 - INFO - __main__ -   Saving optimizer and scheduler states to output_gpt_text_1/checkpoint-500\n",
      "\n",
      "Iteration:  72% 500/699 [03:32<07:24,  2.23s/it]\u001b[A\n",
      "Iteration:  72% 501/699 [03:32<05:35,  1.69s/it]\u001b[A\n",
      "Iteration:  72% 502/699 [03:33<04:16,  1.30s/it]\u001b[A\n",
      "Iteration:  72% 503/699 [03:33<03:23,  1.04s/it]\u001b[A\n",
      "Iteration:  72% 504/699 [03:34<02:45,  1.18it/s]\u001b[A\n",
      "Iteration:  72% 505/699 [03:34<02:18,  1.40it/s]\u001b[A\n",
      "Iteration:  72% 506/699 [03:35<02:00,  1.60it/s]\u001b[A\n",
      "Iteration:  73% 507/699 [03:35<01:47,  1.78it/s]\u001b[A\n",
      "Iteration:  73% 508/699 [03:35<01:38,  1.93it/s]\u001b[A\n",
      "Iteration:  73% 509/699 [03:36<01:32,  2.06it/s]\u001b[A\n",
      "Iteration:  73% 510/699 [03:36<01:27,  2.17it/s]\u001b[A\n",
      "Iteration:  73% 511/699 [03:37<01:24,  2.24it/s]\u001b[A\n",
      "Iteration:  73% 512/699 [03:37<01:21,  2.29it/s]\u001b[A\n",
      "Iteration:  73% 513/699 [03:37<01:19,  2.33it/s]\u001b[A\n",
      "Iteration:  74% 514/699 [03:38<01:18,  2.36it/s]\u001b[A\n",
      "Iteration:  74% 515/699 [03:38<01:17,  2.37it/s]\u001b[A\n",
      "Iteration:  74% 516/699 [03:39<01:16,  2.38it/s]\u001b[A\n",
      "Iteration:  74% 517/699 [03:39<01:15,  2.40it/s]\u001b[A\n",
      "Iteration:  74% 518/699 [03:39<01:15,  2.40it/s]\u001b[A\n",
      "Iteration:  74% 519/699 [03:40<01:14,  2.40it/s]\u001b[A\n",
      "Iteration:  74% 520/699 [03:40<01:14,  2.40it/s]\u001b[A\n",
      "Iteration:  75% 521/699 [03:41<01:13,  2.41it/s]\u001b[A\n",
      "Iteration:  75% 522/699 [03:41<01:13,  2.41it/s]\u001b[A\n",
      "Iteration:  75% 523/699 [03:42<01:13,  2.41it/s]\u001b[A\n",
      "Iteration:  75% 524/699 [03:42<01:12,  2.41it/s]\u001b[A\n",
      "Iteration:  75% 525/699 [03:42<01:12,  2.41it/s]\u001b[A\n",
      "Iteration:  75% 526/699 [03:43<01:11,  2.41it/s]\u001b[A\n",
      "Iteration:  75% 527/699 [03:43<01:11,  2.41it/s]\u001b[A\n",
      "Iteration:  76% 528/699 [03:44<01:11,  2.40it/s]\u001b[A\n",
      "Iteration:  76% 529/699 [03:44<01:10,  2.40it/s]\u001b[A\n",
      "Iteration:  76% 530/699 [03:44<01:10,  2.40it/s]\u001b[A\n",
      "Iteration:  76% 531/699 [03:45<01:10,  2.40it/s]\u001b[A\n",
      "Iteration:  76% 532/699 [03:45<01:09,  2.40it/s]\u001b[A\n",
      "Iteration:  76% 533/699 [03:46<01:09,  2.40it/s]\u001b[A\n",
      "Iteration:  76% 534/699 [03:46<01:08,  2.40it/s]\u001b[A\n",
      "Iteration:  77% 535/699 [03:47<01:08,  2.40it/s]\u001b[A\n",
      "Iteration:  77% 536/699 [03:47<01:08,  2.39it/s]\u001b[A\n",
      "Iteration:  77% 537/699 [03:47<01:07,  2.39it/s]\u001b[A\n",
      "Iteration:  77% 538/699 [03:48<01:07,  2.39it/s]\u001b[A\n",
      "Iteration:  77% 539/699 [03:48<01:06,  2.39it/s]\u001b[A\n",
      "Iteration:  77% 540/699 [03:49<01:06,  2.39it/s]\u001b[A\n",
      "Iteration:  77% 541/699 [03:49<01:06,  2.39it/s]\u001b[A\n",
      "Iteration:  78% 542/699 [03:49<01:05,  2.38it/s]\u001b[A\n",
      "Iteration:  78% 543/699 [03:50<01:05,  2.38it/s]\u001b[A\n",
      "Iteration:  78% 544/699 [03:50<01:05,  2.38it/s]\u001b[A\n",
      "Iteration:  78% 545/699 [03:51<01:04,  2.38it/s]\u001b[A\n",
      "Iteration:  78% 546/699 [03:51<01:04,  2.38it/s]\u001b[A\n",
      "Iteration:  78% 547/699 [03:52<01:03,  2.38it/s]\u001b[A\n",
      "Iteration:  78% 548/699 [03:52<01:03,  2.37it/s]\u001b[A\n",
      "Iteration:  79% 549/699 [03:52<01:03,  2.38it/s]\u001b[A\n",
      "Iteration:  79% 550/699 [03:53<01:03,  2.36it/s]\u001b[A\n",
      "Iteration:  79% 551/699 [03:53<01:02,  2.37it/s]\u001b[A\n",
      "Iteration:  79% 552/699 [03:54<01:02,  2.36it/s]\u001b[A\n",
      "Iteration:  79% 553/699 [03:54<01:01,  2.36it/s]\u001b[A\n",
      "Iteration:  79% 554/699 [03:55<01:01,  2.36it/s]\u001b[A\n",
      "Iteration:  79% 555/699 [03:55<01:01,  2.36it/s]\u001b[A\n",
      "Iteration:  80% 556/699 [03:55<01:00,  2.36it/s]\u001b[A\n",
      "Iteration:  80% 557/699 [03:56<01:00,  2.36it/s]\u001b[A\n",
      "Iteration:  80% 558/699 [03:56<00:59,  2.36it/s]\u001b[A\n",
      "Iteration:  80% 559/699 [03:57<00:59,  2.36it/s]\u001b[A\n",
      "Iteration:  80% 560/699 [03:57<00:58,  2.36it/s]\u001b[A\n",
      "Iteration:  80% 561/699 [03:58<00:58,  2.36it/s]\u001b[A\n",
      "Iteration:  80% 562/699 [03:58<00:58,  2.36it/s]\u001b[A\n",
      "Iteration:  81% 563/699 [03:58<00:57,  2.35it/s]\u001b[A\n",
      "Iteration:  81% 564/699 [03:59<00:57,  2.35it/s]\u001b[A\n",
      "Iteration:  81% 565/699 [03:59<00:56,  2.36it/s]\u001b[A\n",
      "Iteration:  81% 566/699 [04:00<00:56,  2.35it/s]\u001b[A\n",
      "Iteration:  81% 567/699 [04:00<00:56,  2.35it/s]\u001b[A\n",
      "Iteration:  81% 568/699 [04:00<00:55,  2.35it/s]\u001b[A\n",
      "Iteration:  81% 569/699 [04:01<00:55,  2.35it/s]\u001b[A\n",
      "Iteration:  82% 570/699 [04:01<00:54,  2.35it/s]\u001b[A\n",
      "Iteration:  82% 571/699 [04:02<00:54,  2.35it/s]\u001b[A\n",
      "Iteration:  82% 572/699 [04:02<00:54,  2.35it/s]\u001b[A\n",
      "Iteration:  82% 573/699 [04:03<00:53,  2.35it/s]\u001b[A\n",
      "Iteration:  82% 574/699 [04:03<00:53,  2.35it/s]\u001b[A\n",
      "Iteration:  82% 575/699 [04:03<00:52,  2.36it/s]\u001b[A\n",
      "Iteration:  82% 576/699 [04:04<00:52,  2.36it/s]\u001b[A\n",
      "Iteration:  83% 577/699 [04:04<00:51,  2.36it/s]\u001b[A\n",
      "Iteration:  83% 578/699 [04:05<00:51,  2.35it/s]\u001b[A\n",
      "Iteration:  83% 579/699 [04:05<00:50,  2.35it/s]\u001b[A\n",
      "Iteration:  83% 580/699 [04:06<00:50,  2.36it/s]\u001b[A\n",
      "Iteration:  83% 581/699 [04:06<00:49,  2.36it/s]\u001b[A\n",
      "Iteration:  83% 582/699 [04:06<00:49,  2.36it/s]\u001b[A\n",
      "Iteration:  83% 583/699 [04:07<00:49,  2.37it/s]\u001b[A\n",
      "Iteration:  84% 584/699 [04:07<00:48,  2.37it/s]\u001b[A\n",
      "Iteration:  84% 585/699 [04:08<00:48,  2.36it/s]\u001b[A\n",
      "Iteration:  84% 586/699 [04:08<00:47,  2.36it/s]\u001b[A\n",
      "Iteration:  84% 587/699 [04:09<00:47,  2.37it/s]\u001b[A\n",
      "Iteration:  84% 588/699 [04:09<00:46,  2.37it/s]\u001b[A\n",
      "Iteration:  84% 589/699 [04:09<00:46,  2.37it/s]\u001b[A\n",
      "Iteration:  84% 590/699 [04:10<00:46,  2.37it/s]\u001b[A\n",
      "Iteration:  85% 591/699 [04:10<00:45,  2.37it/s]\u001b[A\n",
      "Iteration:  85% 592/699 [04:11<00:45,  2.37it/s]\u001b[A\n",
      "Iteration:  85% 593/699 [04:11<00:44,  2.37it/s]\u001b[A\n",
      "Iteration:  85% 594/699 [04:11<00:44,  2.38it/s]\u001b[A\n",
      "Iteration:  85% 595/699 [04:12<00:43,  2.37it/s]\u001b[A\n",
      "Iteration:  85% 596/699 [04:12<00:43,  2.38it/s]\u001b[A\n",
      "Iteration:  85% 597/699 [04:13<00:43,  2.37it/s]\u001b[A\n",
      "Iteration:  86% 598/699 [04:13<00:42,  2.37it/s]\u001b[A\n",
      "Iteration:  86% 599/699 [04:14<00:42,  2.37it/s]\u001b[A\n",
      "Iteration:  86% 600/699 [04:14<00:41,  2.37it/s]\u001b[A\n",
      "Iteration:  86% 601/699 [04:14<00:41,  2.37it/s]\u001b[A\n",
      "Iteration:  86% 602/699 [04:15<00:40,  2.37it/s]\u001b[A\n",
      "Iteration:  86% 603/699 [04:15<00:40,  2.37it/s]\u001b[A\n",
      "Iteration:  86% 604/699 [04:16<00:40,  2.37it/s]\u001b[A\n",
      "Iteration:  87% 605/699 [04:16<00:39,  2.37it/s]\u001b[A\n",
      "Iteration:  87% 606/699 [04:17<00:39,  2.38it/s]\u001b[A\n",
      "Iteration:  87% 607/699 [04:17<00:38,  2.38it/s]\u001b[A\n",
      "Iteration:  87% 608/699 [04:17<00:38,  2.38it/s]\u001b[A\n",
      "Iteration:  87% 609/699 [04:18<00:37,  2.38it/s]\u001b[A\n",
      "Iteration:  87% 610/699 [04:18<00:37,  2.38it/s]\u001b[A\n",
      "Iteration:  87% 611/699 [04:19<00:36,  2.38it/s]\u001b[A\n",
      "Iteration:  88% 612/699 [04:19<00:36,  2.38it/s]\u001b[A\n",
      "Iteration:  88% 613/699 [04:19<00:36,  2.38it/s]\u001b[A\n",
      "Iteration:  88% 614/699 [04:20<00:35,  2.38it/s]\u001b[A\n",
      "Iteration:  88% 615/699 [04:20<00:35,  2.38it/s]\u001b[A\n",
      "Iteration:  88% 616/699 [04:21<00:34,  2.39it/s]\u001b[A\n",
      "Iteration:  88% 617/699 [04:21<00:34,  2.38it/s]\u001b[A\n",
      "Iteration:  88% 618/699 [04:22<00:33,  2.39it/s]\u001b[A\n",
      "Iteration:  89% 619/699 [04:22<00:33,  2.39it/s]\u001b[A\n",
      "Iteration:  89% 620/699 [04:22<00:33,  2.39it/s]\u001b[A\n",
      "Iteration:  89% 621/699 [04:23<00:32,  2.39it/s]\u001b[A\n",
      "Iteration:  89% 622/699 [04:23<00:32,  2.39it/s]\u001b[A\n",
      "Iteration:  89% 623/699 [04:24<00:31,  2.39it/s]\u001b[A\n",
      "Iteration:  89% 624/699 [04:24<00:31,  2.40it/s]\u001b[A\n",
      "Iteration:  89% 625/699 [04:25<00:30,  2.39it/s]\u001b[A\n",
      "Iteration:  90% 626/699 [04:25<00:30,  2.39it/s]\u001b[A\n",
      "Iteration:  90% 627/699 [04:25<00:30,  2.39it/s]\u001b[A\n",
      "Iteration:  90% 628/699 [04:26<00:29,  2.39it/s]\u001b[A\n",
      "Iteration:  90% 629/699 [04:26<00:29,  2.39it/s]\u001b[A\n",
      "Iteration:  90% 630/699 [04:27<00:28,  2.39it/s]\u001b[A\n",
      "Iteration:  90% 631/699 [04:27<00:28,  2.39it/s]\u001b[A\n",
      "Iteration:  90% 632/699 [04:27<00:27,  2.39it/s]\u001b[A\n",
      "Iteration:  91% 633/699 [04:28<00:27,  2.40it/s]\u001b[A\n",
      "Iteration:  91% 634/699 [04:28<00:27,  2.39it/s]\u001b[A\n",
      "Iteration:  91% 635/699 [04:29<00:26,  2.40it/s]\u001b[A\n",
      "Iteration:  91% 636/699 [04:29<00:26,  2.40it/s]\u001b[A\n",
      "Iteration:  91% 637/699 [04:30<00:25,  2.40it/s]\u001b[A\n",
      "Iteration:  91% 638/699 [04:30<00:25,  2.39it/s]\u001b[A\n",
      "Iteration:  91% 639/699 [04:30<00:25,  2.39it/s]\u001b[A\n",
      "Iteration:  92% 640/699 [04:31<00:24,  2.40it/s]\u001b[A\n",
      "Iteration:  92% 641/699 [04:31<00:24,  2.39it/s]\u001b[A\n",
      "Iteration:  92% 642/699 [04:32<00:23,  2.40it/s]\u001b[A\n",
      "Iteration:  92% 643/699 [04:32<00:23,  2.40it/s]\u001b[A\n",
      "Iteration:  92% 644/699 [04:32<00:22,  2.40it/s]\u001b[A\n",
      "Iteration:  92% 645/699 [04:33<00:22,  2.40it/s]\u001b[A\n",
      "Iteration:  92% 646/699 [04:33<00:22,  2.40it/s]\u001b[A\n",
      "Iteration:  93% 647/699 [04:34<00:21,  2.41it/s]\u001b[A\n",
      "Iteration:  93% 648/699 [04:34<00:21,  2.41it/s]\u001b[A\n",
      "Iteration:  93% 649/699 [04:35<00:20,  2.41it/s]\u001b[A\n",
      "Iteration:  93% 650/699 [04:35<00:20,  2.41it/s]\u001b[A\n",
      "Iteration:  93% 651/699 [04:35<00:19,  2.40it/s]\u001b[A\n",
      "Iteration:  93% 652/699 [04:36<00:19,  2.41it/s]\u001b[A\n",
      "Iteration:  93% 653/699 [04:36<00:19,  2.41it/s]\u001b[A\n",
      "Iteration:  94% 654/699 [04:37<00:18,  2.41it/s]\u001b[A\n",
      "Iteration:  94% 655/699 [04:37<00:18,  2.41it/s]\u001b[A\n",
      "Iteration:  94% 656/699 [04:37<00:17,  2.40it/s]\u001b[A\n",
      "Iteration:  94% 657/699 [04:38<00:17,  2.40it/s]\u001b[A\n",
      "Iteration:  94% 658/699 [04:38<00:17,  2.40it/s]\u001b[A\n",
      "Iteration:  94% 659/699 [04:39<00:16,  2.41it/s]\u001b[A\n",
      "Iteration:  94% 660/699 [04:39<00:16,  2.41it/s]\u001b[A\n",
      "Iteration:  95% 661/699 [04:40<00:15,  2.41it/s]\u001b[A\n",
      "Iteration:  95% 662/699 [04:40<00:15,  2.41it/s]\u001b[A\n",
      "Iteration:  95% 663/699 [04:40<00:14,  2.41it/s]\u001b[A\n",
      "Iteration:  95% 664/699 [04:41<00:14,  2.41it/s]\u001b[A\n",
      "Iteration:  95% 665/699 [04:41<00:14,  2.41it/s]\u001b[A\n",
      "Iteration:  95% 666/699 [04:42<00:13,  2.41it/s]\u001b[A\n",
      "Iteration:  95% 667/699 [04:42<00:13,  2.41it/s]\u001b[A\n",
      "Iteration:  96% 668/699 [04:42<00:12,  2.41it/s]\u001b[A\n",
      "Iteration:  96% 669/699 [04:43<00:12,  2.41it/s]\u001b[A\n",
      "Iteration:  96% 670/699 [04:43<00:12,  2.41it/s]\u001b[A\n",
      "Iteration:  96% 671/699 [04:44<00:11,  2.41it/s]\u001b[A\n",
      "Iteration:  96% 672/699 [04:44<00:11,  2.41it/s]\u001b[A\n",
      "Iteration:  96% 673/699 [04:44<00:10,  2.41it/s]\u001b[A\n",
      "Iteration:  96% 674/699 [04:45<00:10,  2.41it/s]\u001b[A\n",
      "Iteration:  97% 675/699 [04:45<00:09,  2.41it/s]\u001b[A\n",
      "Iteration:  97% 676/699 [04:46<00:09,  2.41it/s]\u001b[A\n",
      "Iteration:  97% 677/699 [04:46<00:09,  2.41it/s]\u001b[A\n",
      "Iteration:  97% 678/699 [04:47<00:08,  2.41it/s]\u001b[A\n",
      "Iteration:  97% 679/699 [04:47<00:08,  2.41it/s]\u001b[A\n",
      "Iteration:  97% 680/699 [04:47<00:07,  2.41it/s]\u001b[A\n",
      "Iteration:  97% 681/699 [04:48<00:07,  2.41it/s]\u001b[A\n",
      "Iteration:  98% 682/699 [04:48<00:07,  2.41it/s]\u001b[A\n",
      "Iteration:  98% 683/699 [04:49<00:06,  2.41it/s]\u001b[A\n",
      "Iteration:  98% 684/699 [04:49<00:06,  2.40it/s]\u001b[A\n",
      "Iteration:  98% 685/699 [04:49<00:05,  2.40it/s]\u001b[A\n",
      "Iteration:  98% 686/699 [04:50<00:05,  2.40it/s]\u001b[A\n",
      "Iteration:  98% 687/699 [04:50<00:04,  2.41it/s]\u001b[A\n",
      "Iteration:  98% 688/699 [04:51<00:04,  2.40it/s]\u001b[A\n",
      "Iteration:  99% 689/699 [04:51<00:04,  2.41it/s]\u001b[A\n",
      "Iteration:  99% 690/699 [04:52<00:03,  2.40it/s]\u001b[A\n",
      "Iteration:  99% 691/699 [04:52<00:03,  2.40it/s]\u001b[A\n",
      "Iteration:  99% 692/699 [04:52<00:02,  2.40it/s]\u001b[A\n",
      "Iteration:  99% 693/699 [04:53<00:02,  2.40it/s]\u001b[A\n",
      "Iteration:  99% 694/699 [04:53<00:02,  2.40it/s]\u001b[A\n",
      "Iteration:  99% 695/699 [04:54<00:01,  2.40it/s]\u001b[A\n",
      "Iteration: 100% 696/699 [04:54<00:01,  2.40it/s]\u001b[A\n",
      "Iteration: 100% 697/699 [04:54<00:00,  2.40it/s]\u001b[A\n",
      "Iteration: 100% 698/699 [04:55<00:00,  2.41it/s]\u001b[A\n",
      "Iteration: 100% 699/699 [04:55<00:00,  2.36it/s]\n",
      "Epoch: 100% 1/1 [04:55<00:00, 295.80s/it]\n",
      "05/22/2020 03:42:55 - INFO - __main__ -    global_step = 699, average loss = 3.5057688397228803\n",
      "05/22/2020 03:42:55 - INFO - __main__ -   Saving model checkpoint to output_gpt_text_1\n",
      "05/22/2020 03:42:55 - INFO - transformers.configuration_utils -   Configuration saved in output_gpt_text_1/config.json\n",
      "05/22/2020 03:42:57 - INFO - transformers.modeling_utils -   Model weights saved in output_gpt_text_1/pytorch_model.bin\n",
      "05/22/2020 03:42:57 - INFO - transformers.configuration_utils -   loading configuration file output_gpt_text_1/config.json\n",
      "05/22/2020 03:42:57 - INFO - transformers.configuration_utils -   Model config GPT2Config {\n",
      "  \"activation_function\": \"gelu_new\",\n",
      "  \"architectures\": [\n",
      "    \"GPT2LMHeadModel\"\n",
      "  ],\n",
      "  \"attn_pdrop\": 0.1,\n",
      "  \"bos_token_id\": 50256,\n",
      "  \"embd_pdrop\": 0.1,\n",
      "  \"eos_token_id\": 50256,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"gpt2\",\n",
      "  \"n_ctx\": 1024,\n",
      "  \"n_embd\": 768,\n",
      "  \"n_head\": 12,\n",
      "  \"n_layer\": 12,\n",
      "  \"n_positions\": 1024,\n",
      "  \"resid_pdrop\": 0.1,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"cls_index\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"task_specific_params\": {\n",
      "    \"text-generation\": {\n",
      "      \"do_sample\": true,\n",
      "      \"max_length\": 50\n",
      "    }\n",
      "  },\n",
      "  \"vocab_size\": 50257\n",
      "}\n",
      "\n",
      "05/22/2020 03:42:57 - INFO - transformers.modeling_utils -   loading weights file output_gpt_text_1/pytorch_model.bin\n",
      "05/22/2020 03:43:01 - INFO - transformers.tokenization_utils -   Model name 'output_gpt_text_1' not found in model shortcut name list (gpt2, gpt2-medium, gpt2-large, gpt2-xl, distilgpt2). Assuming 'output_gpt_text_1' is a path, a model identifier, or url to a directory containing tokenizer files.\n",
      "05/22/2020 03:43:01 - INFO - transformers.tokenization_utils -   Didn't find file output_gpt_text_1/added_tokens.json. We won't load it.\n",
      "05/22/2020 03:43:01 - INFO - transformers.tokenization_utils -   loading file output_gpt_text_1/vocab.json\n",
      "05/22/2020 03:43:01 - INFO - transformers.tokenization_utils -   loading file output_gpt_text_1/merges.txt\n",
      "05/22/2020 03:43:01 - INFO - transformers.tokenization_utils -   loading file None\n",
      "05/22/2020 03:43:01 - INFO - transformers.tokenization_utils -   loading file output_gpt_text_1/special_tokens_map.json\n",
      "05/22/2020 03:43:01 - INFO - transformers.tokenization_utils -   loading file output_gpt_text_1/tokenizer_config.json\n",
      "05/22/2020 03:43:02 - INFO - __main__ -   Evaluate the following checkpoints: ['output_gpt_text_1']\n",
      "05/22/2020 03:43:02 - INFO - transformers.configuration_utils -   loading configuration file output_gpt_text_1/config.json\n",
      "05/22/2020 03:43:02 - INFO - transformers.configuration_utils -   Model config GPT2Config {\n",
      "  \"activation_function\": \"gelu_new\",\n",
      "  \"architectures\": [\n",
      "    \"GPT2LMHeadModel\"\n",
      "  ],\n",
      "  \"attn_pdrop\": 0.1,\n",
      "  \"bos_token_id\": 50256,\n",
      "  \"embd_pdrop\": 0.1,\n",
      "  \"eos_token_id\": 50256,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"gpt2\",\n",
      "  \"n_ctx\": 1024,\n",
      "  \"n_embd\": 768,\n",
      "  \"n_head\": 12,\n",
      "  \"n_layer\": 12,\n",
      "  \"n_positions\": 1024,\n",
      "  \"resid_pdrop\": 0.1,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"cls_index\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"task_specific_params\": {\n",
      "    \"text-generation\": {\n",
      "      \"do_sample\": true,\n",
      "      \"max_length\": 50\n",
      "    }\n",
      "  },\n",
      "  \"vocab_size\": 50257\n",
      "}\n",
      "\n",
      "05/22/2020 03:43:02 - INFO - transformers.modeling_utils -   loading weights file output_gpt_text_1/pytorch_model.bin\n",
      "05/22/2020 03:43:06 - INFO - __main__ -   Loading features from cached file gpt2_cached_lm_1024_test_text\n",
      "05/22/2020 03:43:06 - INFO - __main__ -   ***** Running evaluation  *****\n",
      "05/22/2020 03:43:06 - INFO - __main__ -     Num examples = 175\n",
      "05/22/2020 03:43:06 - INFO - __main__ -     Batch size = 1\n",
      "Evaluating: 100% 175/175 [00:22<00:00,  7.84it/s]\n",
      "05/22/2020 03:43:29 - INFO - __main__ -   ***** Eval results  *****\n",
      "05/22/2020 03:43:29 - INFO - __main__ -     perplexity = tensor(28.0279)\n"
     ]
    }
   ],
   "source": [
    "!python run_language_modelling.py --output_dir=output_gpt_text_1 --model_type=gpt2 --model_name_or_path=gpt2 --do_train --train_data_file=train_text --do_eval --eval_data_file=test_text --per_gpu_train_batch_size=1 --per_gpu_eval_batch_size=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 900
    },
    "colab_type": "code",
    "id": "fkW3gdVddDJe",
    "outputId": "a86fb9c6-4ad1-46bd-b0ba-7d47976d8c96"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-05-22 03:47:14.725169: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
      "05/22/2020 03:47:16 - INFO - transformers.tokenization_utils -   Model name 'output_gpt_text_1' not found in model shortcut name list (gpt2, gpt2-medium, gpt2-large, gpt2-xl, distilgpt2). Assuming 'output_gpt_text_1' is a path, a model identifier, or url to a directory containing tokenizer files.\n",
      "05/22/2020 03:47:16 - INFO - transformers.tokenization_utils -   Didn't find file output_gpt_text_1/added_tokens.json. We won't load it.\n",
      "05/22/2020 03:47:16 - INFO - transformers.tokenization_utils -   loading file output_gpt_text_1/vocab.json\n",
      "05/22/2020 03:47:16 - INFO - transformers.tokenization_utils -   loading file output_gpt_text_1/merges.txt\n",
      "05/22/2020 03:47:16 - INFO - transformers.tokenization_utils -   loading file None\n",
      "05/22/2020 03:47:16 - INFO - transformers.tokenization_utils -   loading file output_gpt_text_1/special_tokens_map.json\n",
      "05/22/2020 03:47:16 - INFO - transformers.tokenization_utils -   loading file output_gpt_text_1/tokenizer_config.json\n",
      "05/22/2020 03:47:16 - INFO - transformers.configuration_utils -   loading configuration file output_gpt_text_1/config.json\n",
      "05/22/2020 03:47:16 - INFO - transformers.configuration_utils -   Model config GPT2Config {\n",
      "  \"activation_function\": \"gelu_new\",\n",
      "  \"architectures\": [\n",
      "    \"GPT2LMHeadModel\"\n",
      "  ],\n",
      "  \"attn_pdrop\": 0.1,\n",
      "  \"bos_token_id\": 50256,\n",
      "  \"embd_pdrop\": 0.1,\n",
      "  \"eos_token_id\": 50256,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"gpt2\",\n",
      "  \"n_ctx\": 1024,\n",
      "  \"n_embd\": 768,\n",
      "  \"n_head\": 12,\n",
      "  \"n_layer\": 12,\n",
      "  \"n_positions\": 1024,\n",
      "  \"resid_pdrop\": 0.1,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"cls_index\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"task_specific_params\": {\n",
      "    \"text-generation\": {\n",
      "      \"do_sample\": true,\n",
      "      \"max_length\": 50\n",
      "    }\n",
      "  },\n",
      "  \"vocab_size\": 50257\n",
      "}\n",
      "\n",
      "05/22/2020 03:47:16 - INFO - transformers.modeling_utils -   loading weights file output_gpt_text_1/pytorch_model.bin\n",
      "05/22/2020 03:47:25 - INFO - __main__ -   Namespace(device=device(type='cuda'), k=0, length=20, model_name_or_path='output_gpt_text_1', model_type='gpt2', n_gpu=1, no_cuda=False, num_return_sequences=1, p=0.9, padding_text='', prompt='', repetition_penalty=1.0, seed=42, stop_token=None, temperature=1.0, xlm_language='')\n",
      "Model prompt >>> This game is\n",
      "05/22/2020 03:47:40 - WARNING - transformers.modeling_utils -   Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n",
      "=== GENERATED SEQUENCE 1 ===\n",
      "This game is fun enough for both new and old players alike, but it's not as intense as the original.\n"
     ]
    }
   ],
   "source": [
    "!python run_generation.py --model_type=gpt2 --model_name_or_path=output_gpt_text_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nIHQfJWcdbYz"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_text, test_text = train_test_split(df_0['reviewText'], test_size=0.2)\n",
    "train_text.to_frame().to_csv(r'train_text', header=None, index=None, sep=' ', mode='a')\n",
    "test_text.to_frame().to_csv(r'test_text', header=None, index=None, sep=' ', mode='a')\n",
    "torch.cuda.empty_cache() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 237
    },
    "colab_type": "code",
    "id": "juAsYIhthLXK",
    "outputId": "5871ee49-c3d1-4c8c-ad17-c8933dc97e55"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "194     This is not the first one of these I have had,...\n",
       "1360    and you just became part of it.\\nPros:\\nBrough...\n",
       "489     the cd worked for about 4 days and then...BAM!...\n",
       "925     I thought Red Alert was a pretty fun game. Thi...\n",
       "385     It's a charger, it does what it needs to, that...\n",
       "                              ...                        \n",
       "809     I was hoping the game would be more complete a...\n",
       "1468    I had a positive but more negative experience ...\n",
       "887                                                 great\n",
       "1546    I bought this game in 1997, over a year after ...\n",
       "709     Goldeneye is a classic for a reason! Unfortuna...\n",
       "Name: reviewText, Length: 400, dtype: object"
      ]
     },
     "execution_count": 67,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "obsw6jL9dWSH",
    "outputId": "ef63584e-c889-4c45-fcf2-b11f3e3da248"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-05-22 03:47:53.088670: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
      "05/22/2020 03:47:54 - WARNING - __main__ -   Process rank: -1, device: cuda, n_gpu: 1, distributed training: False, 16-bits training: False\n",
      "05/22/2020 03:47:55 - INFO - transformers.configuration_utils -   loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-config.json from cache at /root/.cache/torch/transformers/4be02c5697d91738003fb1685c9872f284166aa32e061576bbe6aaeb95649fcf.db13c9bc9c7bdd738ec89e069621d88e05dc670366092d809a9cbcac6798e24e\n",
      "05/22/2020 03:47:55 - INFO - transformers.configuration_utils -   Model config GPT2Config {\n",
      "  \"activation_function\": \"gelu_new\",\n",
      "  \"architectures\": [\n",
      "    \"GPT2LMHeadModel\"\n",
      "  ],\n",
      "  \"attn_pdrop\": 0.1,\n",
      "  \"bos_token_id\": 50256,\n",
      "  \"embd_pdrop\": 0.1,\n",
      "  \"eos_token_id\": 50256,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"gpt2\",\n",
      "  \"n_ctx\": 1024,\n",
      "  \"n_embd\": 768,\n",
      "  \"n_head\": 12,\n",
      "  \"n_layer\": 12,\n",
      "  \"n_positions\": 1024,\n",
      "  \"resid_pdrop\": 0.1,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"cls_index\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"task_specific_params\": {\n",
      "    \"text-generation\": {\n",
      "      \"do_sample\": true,\n",
      "      \"max_length\": 50\n",
      "    }\n",
      "  },\n",
      "  \"vocab_size\": 50257\n",
      "}\n",
      "\n",
      "05/22/2020 03:47:57 - INFO - transformers.tokenization_utils -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-vocab.json from cache at /root/.cache/torch/transformers/f2808208f9bec2320371a9f5f891c184ae0b674ef866b79c58177067d15732dd.1512018be4ba4e8726e41b9145129dc30651ea4fec86aa61f4b9f40bf94eac71\n",
      "05/22/2020 03:47:57 - INFO - transformers.tokenization_utils -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-merges.txt from cache at /root/.cache/torch/transformers/d629f792e430b3c76a1291bb2766b0a047e36fae0588f9dbc1ae51decdff691b.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda\n",
      "05/22/2020 03:47:58 - INFO - transformers.modeling_utils -   loading weights file https://cdn.huggingface.co/gpt2-pytorch_model.bin from cache at /root/.cache/torch/transformers/d71fd633e58263bd5e91dd3bde9f658bafd81e11ece622be6a3c2e4d42d8fd89.778cf36f5c4e5d94c8cd9cefcf2a580c8643570eb327f0d4a1f007fab2acbdf1\n",
      "05/22/2020 03:48:03 - INFO - transformers.modeling_utils -   Weights of GPT2LMHeadModel not initialized from pretrained model: ['h.0.attn.masked_bias', 'h.1.attn.masked_bias', 'h.2.attn.masked_bias', 'h.3.attn.masked_bias', 'h.4.attn.masked_bias', 'h.5.attn.masked_bias', 'h.6.attn.masked_bias', 'h.7.attn.masked_bias', 'h.8.attn.masked_bias', 'h.9.attn.masked_bias', 'h.10.attn.masked_bias', 'h.11.attn.masked_bias', 'lm_head.weight']\n",
      "05/22/2020 03:48:07 - INFO - __main__ -   Training/evaluation parameters Namespace(adam_epsilon=1e-08, block_size=1024, cache_dir=None, config_name=None, device=device(type='cuda'), do_eval=True, do_train=True, eval_all_checkpoints=False, eval_data_file='test_text', evaluate_during_training=False, fp16=False, fp16_opt_level='O1', gradient_accumulation_steps=1, learning_rate=5e-05, line_by_line=False, local_rank=-1, logging_steps=500, max_grad_norm=1.0, max_steps=-1, mlm=False, mlm_probability=0.15, model_name_or_path='gpt2', model_type='gpt2', n_gpu=1, no_cuda=False, num_train_epochs=1.0, output_dir='output_gpt_text_0', overwrite_cache=False, overwrite_output_dir=False, per_gpu_eval_batch_size=1, per_gpu_train_batch_size=1, save_steps=500, save_total_limit=None, seed=42, server_ip='', server_port='', should_continue=False, tokenizer_name=None, train_data_file='train_text', warmup_steps=0, weight_decay=0.0)\n",
      "05/22/2020 03:48:07 - INFO - __main__ -   Loading features from cached file gpt2_cached_lm_1024_train_text\n",
      "05/22/2020 03:48:07 - INFO - __main__ -   ***** Running training *****\n",
      "05/22/2020 03:48:07 - INFO - __main__ -     Num examples = 699\n",
      "05/22/2020 03:48:07 - INFO - __main__ -     Num Epochs = 1\n",
      "05/22/2020 03:48:07 - INFO - __main__ -     Instantaneous batch size per GPU = 1\n",
      "05/22/2020 03:48:07 - INFO - __main__ -     Total train batch size (w. parallel, distributed & accumulation) = 1\n",
      "05/22/2020 03:48:07 - INFO - __main__ -     Gradient Accumulation steps = 1\n",
      "05/22/2020 03:48:07 - INFO - __main__ -     Total optimization steps = 699\n",
      "Epoch:   0% 0/1 [00:00<?, ?it/s]\n",
      "Iteration:   0% 0/699 [00:00<?, ?it/s]\u001b[A/pytorch/torch/csrc/utils/python_arg_parser.cpp:756: UserWarning: This overload of add_ is deprecated:\n",
      "\tadd_(Number alpha, Tensor other)\n",
      "Consider using one of the following signatures instead:\n",
      "\tadd_(Tensor other, *, Number alpha)\n",
      "\n",
      "Iteration:   0% 1/699 [00:00<05:14,  2.22it/s]\u001b[A\n",
      "Iteration:   0% 2/699 [00:00<04:58,  2.33it/s]\u001b[A\n",
      "Iteration:   0% 3/699 [00:01<04:50,  2.40it/s]\u001b[A\n",
      "Iteration:   1% 4/699 [00:01<04:47,  2.42it/s]\u001b[A\n",
      "Iteration:   1% 5/699 [00:02<04:41,  2.46it/s]\u001b[A\n",
      "Iteration:   1% 6/699 [00:02<04:40,  2.47it/s]\u001b[A\n",
      "Iteration:   1% 7/699 [00:02<04:38,  2.48it/s]\u001b[A\n",
      "Iteration:   1% 8/699 [00:03<04:36,  2.50it/s]\u001b[A\n",
      "Iteration:   1% 9/699 [00:03<04:36,  2.50it/s]\u001b[A\n",
      "Iteration:   1% 10/699 [00:04<04:35,  2.50it/s]\u001b[A\n",
      "Iteration:   2% 11/699 [00:04<04:34,  2.51it/s]\u001b[A\n",
      "Iteration:   2% 12/699 [00:04<04:34,  2.50it/s]\u001b[A\n",
      "Iteration:   2% 13/699 [00:05<04:33,  2.51it/s]\u001b[A\n",
      "Iteration:   2% 14/699 [00:05<04:33,  2.51it/s]\u001b[A\n",
      "Iteration:   2% 15/699 [00:06<04:33,  2.50it/s]\u001b[A\n",
      "Iteration:   2% 16/699 [00:06<04:32,  2.51it/s]\u001b[A\n",
      "Iteration:   2% 17/699 [00:06<04:33,  2.49it/s]\u001b[A\n",
      "Iteration:   3% 18/699 [00:07<04:33,  2.49it/s]\u001b[A\n",
      "Iteration:   3% 19/699 [00:07<04:32,  2.49it/s]\u001b[A\n",
      "Iteration:   3% 20/699 [00:08<04:33,  2.48it/s]\u001b[A\n",
      "Iteration:   3% 21/699 [00:08<04:32,  2.49it/s]\u001b[A\n",
      "Iteration:   3% 22/699 [00:08<04:32,  2.49it/s]\u001b[A\n",
      "Iteration:   3% 23/699 [00:09<04:31,  2.49it/s]\u001b[A\n",
      "Iteration:   3% 24/699 [00:09<04:31,  2.48it/s]\u001b[A\n",
      "Iteration:   4% 25/699 [00:10<04:31,  2.48it/s]\u001b[A\n",
      "Iteration:   4% 26/699 [00:10<04:31,  2.48it/s]\u001b[A\n",
      "Iteration:   4% 27/699 [00:10<04:31,  2.48it/s]\u001b[A\n",
      "Iteration:   4% 28/699 [00:11<04:31,  2.48it/s]\u001b[A\n",
      "Iteration:   4% 29/699 [00:11<04:30,  2.47it/s]\u001b[A\n",
      "Iteration:   4% 30/699 [00:12<04:30,  2.48it/s]\u001b[A\n",
      "Iteration:   4% 31/699 [00:12<04:29,  2.48it/s]\u001b[A\n",
      "Iteration:   5% 32/699 [00:12<04:29,  2.48it/s]\u001b[A\n",
      "Iteration:   5% 33/699 [00:13<04:28,  2.48it/s]\u001b[A\n",
      "Iteration:   5% 34/699 [00:13<04:28,  2.47it/s]\u001b[A\n",
      "Iteration:   5% 35/699 [00:14<04:28,  2.47it/s]\u001b[A\n",
      "Iteration:   5% 36/699 [00:14<04:28,  2.47it/s]\u001b[A\n",
      "Iteration:   5% 37/699 [00:14<04:28,  2.47it/s]\u001b[A\n",
      "Iteration:   5% 38/699 [00:15<04:27,  2.47it/s]\u001b[A\n",
      "Iteration:   6% 39/699 [00:15<04:28,  2.46it/s]\u001b[A\n",
      "Iteration:   6% 40/699 [00:16<04:28,  2.45it/s]\u001b[A\n",
      "Iteration:   6% 41/699 [00:16<04:27,  2.46it/s]\u001b[A\n",
      "Iteration:   6% 42/699 [00:16<04:26,  2.47it/s]\u001b[A\n",
      "Iteration:   6% 43/699 [00:17<04:25,  2.47it/s]\u001b[A\n",
      "Iteration:   6% 44/699 [00:17<04:25,  2.46it/s]\u001b[A\n",
      "Iteration:   6% 45/699 [00:18<04:24,  2.47it/s]\u001b[A\n",
      "Iteration:   7% 46/699 [00:18<04:24,  2.47it/s]\u001b[A\n",
      "Iteration:   7% 47/699 [00:18<04:23,  2.48it/s]\u001b[A\n",
      "Iteration:   7% 48/699 [00:19<04:23,  2.47it/s]\u001b[A\n",
      "Iteration:   7% 49/699 [00:19<04:22,  2.47it/s]\u001b[A\n",
      "Iteration:   7% 50/699 [00:20<04:22,  2.47it/s]\u001b[A\n",
      "Iteration:   7% 51/699 [00:20<04:22,  2.47it/s]\u001b[A\n",
      "Iteration:   7% 52/699 [00:20<04:21,  2.47it/s]\u001b[A\n",
      "Iteration:   8% 53/699 [00:21<04:21,  2.47it/s]\u001b[A\n",
      "Iteration:   8% 54/699 [00:21<04:21,  2.46it/s]\u001b[A\n",
      "Iteration:   8% 55/699 [00:22<04:21,  2.46it/s]\u001b[A\n",
      "Iteration:   8% 56/699 [00:22<04:20,  2.47it/s]\u001b[A\n",
      "Iteration:   8% 57/699 [00:22<04:20,  2.46it/s]\u001b[A\n",
      "Iteration:   8% 58/699 [00:23<04:20,  2.46it/s]\u001b[A\n",
      "Iteration:   8% 59/699 [00:23<04:19,  2.46it/s]\u001b[A\n",
      "Iteration:   9% 60/699 [00:24<04:19,  2.46it/s]\u001b[A\n",
      "Iteration:   9% 61/699 [00:24<04:19,  2.46it/s]\u001b[A\n",
      "Iteration:   9% 62/699 [00:25<04:19,  2.45it/s]\u001b[A\n",
      "Iteration:   9% 63/699 [00:25<04:19,  2.45it/s]\u001b[A\n",
      "Iteration:   9% 64/699 [00:25<04:19,  2.44it/s]\u001b[A\n",
      "Iteration:   9% 65/699 [00:26<04:19,  2.44it/s]\u001b[A\n",
      "Iteration:   9% 66/699 [00:26<04:18,  2.45it/s]\u001b[A\n",
      "Iteration:  10% 67/699 [00:27<04:19,  2.43it/s]\u001b[A\n",
      "Iteration:  10% 68/699 [00:27<04:18,  2.44it/s]\u001b[A\n",
      "Iteration:  10% 69/699 [00:27<04:18,  2.44it/s]\u001b[A\n",
      "Iteration:  10% 70/699 [00:28<04:18,  2.43it/s]\u001b[A\n",
      "Iteration:  10% 71/699 [00:28<04:17,  2.44it/s]\u001b[A\n",
      "Iteration:  10% 72/699 [00:29<04:17,  2.43it/s]\u001b[A\n",
      "Iteration:  10% 73/699 [00:29<04:17,  2.43it/s]\u001b[A\n",
      "Iteration:  11% 74/699 [00:29<04:17,  2.42it/s]\u001b[A\n",
      "Iteration:  11% 75/699 [00:30<04:17,  2.42it/s]\u001b[A\n",
      "Iteration:  11% 76/699 [00:30<04:17,  2.42it/s]\u001b[A\n",
      "Iteration:  11% 77/699 [00:31<04:17,  2.42it/s]\u001b[A\n",
      "Iteration:  11% 78/699 [00:31<04:16,  2.42it/s]\u001b[A\n",
      "Iteration:  11% 79/699 [00:32<04:16,  2.42it/s]\u001b[A\n",
      "Iteration:  11% 80/699 [00:32<04:16,  2.41it/s]\u001b[A\n",
      "Iteration:  12% 81/699 [00:32<04:16,  2.41it/s]\u001b[A\n",
      "Iteration:  12% 82/699 [00:33<04:15,  2.42it/s]\u001b[A\n",
      "Iteration:  12% 83/699 [00:33<04:14,  2.42it/s]\u001b[A\n",
      "Iteration:  12% 84/699 [00:34<04:14,  2.42it/s]\u001b[A\n",
      "Iteration:  12% 85/699 [00:34<04:14,  2.41it/s]\u001b[A\n",
      "Iteration:  12% 86/699 [00:34<04:14,  2.41it/s]\u001b[A\n",
      "Iteration:  12% 87/699 [00:35<04:13,  2.41it/s]\u001b[A\n",
      "Iteration:  13% 88/699 [00:35<04:13,  2.41it/s]\u001b[A\n",
      "Iteration:  13% 89/699 [00:36<04:14,  2.40it/s]\u001b[A\n",
      "Iteration:  13% 90/699 [00:36<04:13,  2.40it/s]\u001b[A\n",
      "Iteration:  13% 91/699 [00:37<04:13,  2.40it/s]\u001b[A\n",
      "Iteration:  13% 92/699 [00:37<04:13,  2.40it/s]\u001b[A\n",
      "Iteration:  13% 93/699 [00:37<04:13,  2.39it/s]\u001b[A\n",
      "Iteration:  13% 94/699 [00:38<04:13,  2.39it/s]\u001b[A\n",
      "Iteration:  14% 95/699 [00:38<04:12,  2.40it/s]\u001b[A\n",
      "Iteration:  14% 96/699 [00:39<04:12,  2.39it/s]\u001b[A\n",
      "Iteration:  14% 97/699 [00:39<04:12,  2.39it/s]\u001b[A\n",
      "Iteration:  14% 98/699 [00:39<04:11,  2.39it/s]\u001b[A\n",
      "Iteration:  14% 99/699 [00:40<04:11,  2.38it/s]\u001b[A\n",
      "Iteration:  14% 100/699 [00:40<04:10,  2.39it/s]\u001b[A\n",
      "Iteration:  14% 101/699 [00:41<04:10,  2.39it/s]\u001b[A\n",
      "Iteration:  15% 102/699 [00:41<04:10,  2.38it/s]\u001b[A\n",
      "Iteration:  15% 103/699 [00:42<04:10,  2.38it/s]\u001b[A\n",
      "Iteration:  15% 104/699 [00:42<04:09,  2.38it/s]\u001b[A\n",
      "Iteration:  15% 105/699 [00:42<04:09,  2.38it/s]\u001b[A\n",
      "Iteration:  15% 106/699 [00:43<04:09,  2.37it/s]\u001b[A\n",
      "Iteration:  15% 107/699 [00:43<04:09,  2.37it/s]\u001b[A\n",
      "Iteration:  15% 108/699 [00:44<04:08,  2.38it/s]\u001b[A\n",
      "Iteration:  16% 109/699 [00:44<04:08,  2.37it/s]\u001b[A\n",
      "Iteration:  16% 110/699 [00:44<04:07,  2.38it/s]\u001b[A\n",
      "Iteration:  16% 111/699 [00:45<04:07,  2.38it/s]\u001b[A\n",
      "Iteration:  16% 112/699 [00:45<04:08,  2.36it/s]\u001b[A\n",
      "Iteration:  16% 113/699 [00:46<04:07,  2.36it/s]\u001b[A\n",
      "Iteration:  16% 114/699 [00:46<04:07,  2.36it/s]\u001b[A\n",
      "Iteration:  16% 115/699 [00:47<04:06,  2.37it/s]\u001b[A\n",
      "Iteration:  17% 116/699 [00:47<04:06,  2.37it/s]\u001b[A\n",
      "Iteration:  17% 117/699 [00:47<04:06,  2.36it/s]\u001b[A\n",
      "Iteration:  17% 118/699 [00:48<04:05,  2.36it/s]\u001b[A\n",
      "Iteration:  17% 119/699 [00:48<04:05,  2.37it/s]\u001b[A\n",
      "Iteration:  17% 120/699 [00:49<04:04,  2.36it/s]\u001b[A\n",
      "Iteration:  17% 121/699 [00:49<04:04,  2.37it/s]\u001b[A\n",
      "Iteration:  17% 122/699 [00:50<04:03,  2.37it/s]\u001b[A\n",
      "Iteration:  18% 123/699 [00:50<04:03,  2.36it/s]\u001b[A\n",
      "Iteration:  18% 124/699 [00:50<04:03,  2.36it/s]\u001b[A\n",
      "Iteration:  18% 125/699 [00:51<04:02,  2.36it/s]\u001b[A\n",
      "Iteration:  18% 126/699 [00:51<04:02,  2.36it/s]\u001b[A\n",
      "Iteration:  18% 127/699 [00:52<04:02,  2.36it/s]\u001b[A\n",
      "Iteration:  18% 128/699 [00:52<04:01,  2.36it/s]\u001b[A\n",
      "Iteration:  18% 129/699 [00:53<04:01,  2.36it/s]\u001b[A\n",
      "Iteration:  19% 130/699 [00:53<04:00,  2.36it/s]\u001b[A\n",
      "Iteration:  19% 131/699 [00:53<04:01,  2.36it/s]\u001b[A\n",
      "Iteration:  19% 132/699 [00:54<04:00,  2.36it/s]\u001b[A\n",
      "Iteration:  19% 133/699 [00:54<04:00,  2.36it/s]\u001b[A\n",
      "Iteration:  19% 134/699 [00:55<03:59,  2.36it/s]\u001b[A\n",
      "Iteration:  19% 135/699 [00:55<03:59,  2.36it/s]\u001b[A\n",
      "Iteration:  19% 136/699 [00:56<03:59,  2.35it/s]\u001b[A\n",
      "Iteration:  20% 137/699 [00:56<03:58,  2.35it/s]\u001b[A\n",
      "Iteration:  20% 138/699 [00:56<03:57,  2.36it/s]\u001b[A\n",
      "Iteration:  20% 139/699 [00:57<03:57,  2.36it/s]\u001b[A\n",
      "Iteration:  20% 140/699 [00:57<03:57,  2.35it/s]\u001b[A\n",
      "Iteration:  20% 141/699 [00:58<03:56,  2.36it/s]\u001b[A\n",
      "Iteration:  20% 142/699 [00:58<03:56,  2.36it/s]\u001b[A\n",
      "Iteration:  20% 143/699 [00:58<03:55,  2.36it/s]\u001b[A\n",
      "Iteration:  21% 144/699 [00:59<03:55,  2.36it/s]\u001b[A\n",
      "Iteration:  21% 145/699 [00:59<03:55,  2.35it/s]\u001b[A\n",
      "Iteration:  21% 146/699 [01:00<03:54,  2.35it/s]\u001b[A\n",
      "Iteration:  21% 147/699 [01:00<03:53,  2.36it/s]\u001b[A\n",
      "Iteration:  21% 148/699 [01:01<03:53,  2.36it/s]\u001b[A\n",
      "Iteration:  21% 149/699 [01:01<03:53,  2.35it/s]\u001b[A\n",
      "Iteration:  21% 150/699 [01:01<03:53,  2.35it/s]\u001b[A\n",
      "Iteration:  22% 151/699 [01:02<03:52,  2.35it/s]\u001b[A\n",
      "Iteration:  22% 152/699 [01:02<03:52,  2.35it/s]\u001b[A\n",
      "Iteration:  22% 153/699 [01:03<03:51,  2.36it/s]\u001b[A\n",
      "Iteration:  22% 154/699 [01:03<03:51,  2.36it/s]\u001b[A\n",
      "Iteration:  22% 155/699 [01:04<03:50,  2.36it/s]\u001b[A\n",
      "Iteration:  22% 156/699 [01:04<03:50,  2.36it/s]\u001b[A\n",
      "Iteration:  22% 157/699 [01:04<03:49,  2.36it/s]\u001b[A\n",
      "Iteration:  23% 158/699 [01:05<03:49,  2.36it/s]\u001b[A\n",
      "Iteration:  23% 159/699 [01:05<03:49,  2.36it/s]\u001b[A\n",
      "Iteration:  23% 160/699 [01:06<03:48,  2.35it/s]\u001b[A\n",
      "Iteration:  23% 161/699 [01:06<03:48,  2.36it/s]\u001b[A\n",
      "Iteration:  23% 162/699 [01:07<03:47,  2.36it/s]\u001b[A\n",
      "Iteration:  23% 163/699 [01:07<03:46,  2.36it/s]\u001b[A\n",
      "Iteration:  23% 164/699 [01:07<03:46,  2.36it/s]\u001b[A\n",
      "Iteration:  24% 165/699 [01:08<03:45,  2.37it/s]\u001b[A\n",
      "Iteration:  24% 166/699 [01:08<03:45,  2.37it/s]\u001b[A\n",
      "Iteration:  24% 167/699 [01:09<03:44,  2.37it/s]\u001b[A\n",
      "Iteration:  24% 168/699 [01:09<03:43,  2.37it/s]\u001b[A\n",
      "Iteration:  24% 169/699 [01:09<03:43,  2.37it/s]\u001b[A\n",
      "Iteration:  24% 170/699 [01:10<03:43,  2.37it/s]\u001b[A\n",
      "Iteration:  24% 171/699 [01:10<03:42,  2.37it/s]\u001b[A\n",
      "Iteration:  25% 172/699 [01:11<03:42,  2.37it/s]\u001b[A\n",
      "Iteration:  25% 173/699 [01:11<03:41,  2.38it/s]\u001b[A\n",
      "Iteration:  25% 174/699 [01:12<03:41,  2.38it/s]\u001b[A\n",
      "Iteration:  25% 175/699 [01:12<03:41,  2.37it/s]\u001b[A\n",
      "Iteration:  25% 176/699 [01:12<03:40,  2.38it/s]\u001b[A\n",
      "Iteration:  25% 177/699 [01:13<03:39,  2.38it/s]\u001b[A\n",
      "Iteration:  25% 178/699 [01:13<03:38,  2.38it/s]\u001b[A\n",
      "Iteration:  26% 179/699 [01:14<03:38,  2.38it/s]\u001b[A\n",
      "Iteration:  26% 180/699 [01:14<03:37,  2.38it/s]\u001b[A\n",
      "Iteration:  26% 181/699 [01:15<03:38,  2.37it/s]\u001b[A\n",
      "Iteration:  26% 182/699 [01:15<03:37,  2.38it/s]\u001b[A\n",
      "Iteration:  26% 183/699 [01:15<03:36,  2.38it/s]\u001b[A\n",
      "Iteration:  26% 184/699 [01:16<03:36,  2.38it/s]\u001b[A\n",
      "Iteration:  26% 185/699 [01:16<03:35,  2.39it/s]\u001b[A\n",
      "Iteration:  27% 186/699 [01:17<03:35,  2.38it/s]\u001b[A\n",
      "Iteration:  27% 187/699 [01:17<03:34,  2.38it/s]\u001b[A\n",
      "Iteration:  27% 188/699 [01:17<03:34,  2.38it/s]\u001b[A\n",
      "Iteration:  27% 189/699 [01:18<03:34,  2.38it/s]\u001b[A\n",
      "Iteration:  27% 190/699 [01:18<03:33,  2.39it/s]\u001b[A\n",
      "Iteration:  27% 191/699 [01:19<03:33,  2.38it/s]\u001b[A\n",
      "Iteration:  27% 192/699 [01:19<03:32,  2.38it/s]\u001b[A\n",
      "Iteration:  28% 193/699 [01:20<03:32,  2.38it/s]\u001b[A\n",
      "Iteration:  28% 194/699 [01:20<03:31,  2.39it/s]\u001b[A\n",
      "Iteration:  28% 195/699 [01:20<03:30,  2.39it/s]\u001b[A\n",
      "Iteration:  28% 196/699 [01:21<03:30,  2.39it/s]\u001b[A\n",
      "Iteration:  28% 197/699 [01:21<03:29,  2.39it/s]\u001b[A\n",
      "Iteration:  28% 198/699 [01:22<03:29,  2.39it/s]\u001b[A\n",
      "Iteration:  28% 199/699 [01:22<03:28,  2.39it/s]\u001b[A\n",
      "Iteration:  29% 200/699 [01:22<03:28,  2.40it/s]\u001b[A\n",
      "Iteration:  29% 201/699 [01:23<03:28,  2.39it/s]\u001b[A\n",
      "Iteration:  29% 202/699 [01:23<03:27,  2.40it/s]\u001b[A\n",
      "Iteration:  29% 203/699 [01:24<03:27,  2.39it/s]\u001b[A\n",
      "Iteration:  29% 204/699 [01:24<03:26,  2.39it/s]\u001b[A\n",
      "Iteration:  29% 205/699 [01:25<03:26,  2.39it/s]\u001b[A\n",
      "Iteration:  29% 206/699 [01:25<03:26,  2.39it/s]\u001b[A\n",
      "Iteration:  30% 207/699 [01:25<03:25,  2.39it/s]\u001b[A\n",
      "Iteration:  30% 208/699 [01:26<03:24,  2.40it/s]\u001b[A\n",
      "Iteration:  30% 209/699 [01:26<03:24,  2.40it/s]\u001b[A\n",
      "Iteration:  30% 210/699 [01:27<03:23,  2.40it/s]\u001b[A\n",
      "Iteration:  30% 211/699 [01:27<03:23,  2.40it/s]\u001b[A\n",
      "Iteration:  30% 212/699 [01:27<03:22,  2.40it/s]\u001b[A\n",
      "Iteration:  30% 213/699 [01:28<03:22,  2.40it/s]\u001b[A\n",
      "Iteration:  31% 214/699 [01:28<03:21,  2.41it/s]\u001b[A\n",
      "Iteration:  31% 215/699 [01:29<03:21,  2.41it/s]\u001b[A\n",
      "Iteration:  31% 216/699 [01:29<03:20,  2.41it/s]\u001b[A\n",
      "Iteration:  31% 217/699 [01:30<03:20,  2.40it/s]\u001b[A\n",
      "Iteration:  31% 218/699 [01:30<03:20,  2.40it/s]\u001b[A\n",
      "Iteration:  31% 219/699 [01:30<03:19,  2.41it/s]\u001b[A\n",
      "Iteration:  31% 220/699 [01:31<03:19,  2.40it/s]\u001b[A\n",
      "Iteration:  32% 221/699 [01:31<03:18,  2.41it/s]\u001b[A\n",
      "Iteration:  32% 222/699 [01:32<03:18,  2.40it/s]\u001b[A\n",
      "Iteration:  32% 223/699 [01:32<03:17,  2.41it/s]\u001b[A\n",
      "Iteration:  32% 224/699 [01:32<03:17,  2.40it/s]\u001b[A\n",
      "Iteration:  32% 225/699 [01:33<03:16,  2.41it/s]\u001b[A\n",
      "Iteration:  32% 226/699 [01:33<03:16,  2.41it/s]\u001b[A\n",
      "Iteration:  32% 227/699 [01:34<03:15,  2.41it/s]\u001b[A\n",
      "Iteration:  33% 228/699 [01:34<03:15,  2.41it/s]\u001b[A\n",
      "Iteration:  33% 229/699 [01:35<03:15,  2.41it/s]\u001b[A\n",
      "Iteration:  33% 230/699 [01:35<03:14,  2.41it/s]\u001b[A\n",
      "Iteration:  33% 231/699 [01:35<03:13,  2.42it/s]\u001b[A\n",
      "Iteration:  33% 232/699 [01:36<03:13,  2.42it/s]\u001b[A\n",
      "Iteration:  33% 233/699 [01:36<03:13,  2.41it/s]\u001b[A\n",
      "Iteration:  33% 234/699 [01:37<03:12,  2.41it/s]\u001b[A\n",
      "Iteration:  34% 235/699 [01:37<03:12,  2.41it/s]\u001b[A\n",
      "Iteration:  34% 236/699 [01:37<03:11,  2.42it/s]\u001b[A\n",
      "Iteration:  34% 237/699 [01:38<03:11,  2.41it/s]\u001b[A\n",
      "Iteration:  34% 238/699 [01:38<03:10,  2.42it/s]\u001b[A\n",
      "Iteration:  34% 239/699 [01:39<03:10,  2.41it/s]\u001b[A\n",
      "Iteration:  34% 240/699 [01:39<03:10,  2.41it/s]\u001b[A\n",
      "Iteration:  34% 241/699 [01:40<03:10,  2.41it/s]\u001b[A\n",
      "Iteration:  35% 242/699 [01:40<03:09,  2.41it/s]\u001b[A\n",
      "Iteration:  35% 243/699 [01:40<03:09,  2.41it/s]\u001b[A\n",
      "Iteration:  35% 244/699 [01:41<03:08,  2.42it/s]\u001b[A\n",
      "Iteration:  35% 245/699 [01:41<03:08,  2.41it/s]\u001b[A\n",
      "Iteration:  35% 246/699 [01:42<03:08,  2.41it/s]\u001b[A\n",
      "Iteration:  35% 247/699 [01:42<03:08,  2.40it/s]\u001b[A\n",
      "Iteration:  35% 248/699 [01:42<03:07,  2.41it/s]\u001b[A\n",
      "Iteration:  36% 249/699 [01:43<03:06,  2.41it/s]\u001b[A\n",
      "Iteration:  36% 250/699 [01:43<03:06,  2.41it/s]\u001b[A\n",
      "Iteration:  36% 251/699 [01:44<03:06,  2.41it/s]\u001b[A\n",
      "Iteration:  36% 252/699 [01:44<03:05,  2.41it/s]\u001b[A\n",
      "Iteration:  36% 253/699 [01:45<03:05,  2.40it/s]\u001b[A\n",
      "Iteration:  36% 254/699 [01:45<03:04,  2.41it/s]\u001b[A\n",
      "Iteration:  36% 255/699 [01:45<03:04,  2.41it/s]\u001b[A\n",
      "Iteration:  37% 256/699 [01:46<03:03,  2.41it/s]\u001b[A\n",
      "Iteration:  37% 257/699 [01:46<03:03,  2.41it/s]\u001b[A\n",
      "Iteration:  37% 258/699 [01:47<03:02,  2.41it/s]\u001b[A\n",
      "Iteration:  37% 259/699 [01:47<03:02,  2.42it/s]\u001b[A\n",
      "Iteration:  37% 260/699 [01:47<03:01,  2.41it/s]\u001b[A\n",
      "Iteration:  37% 261/699 [01:48<03:01,  2.42it/s]\u001b[A\n",
      "Iteration:  37% 262/699 [01:48<03:01,  2.41it/s]\u001b[A\n",
      "Iteration:  38% 263/699 [01:49<03:00,  2.41it/s]\u001b[A\n",
      "Iteration:  38% 264/699 [01:49<03:00,  2.41it/s]\u001b[A\n",
      "Iteration:  38% 265/699 [01:50<03:00,  2.40it/s]\u001b[A\n",
      "Iteration:  38% 266/699 [01:50<02:59,  2.41it/s]\u001b[A\n",
      "Iteration:  38% 267/699 [01:50<02:58,  2.42it/s]\u001b[A\n",
      "Iteration:  38% 268/699 [01:51<02:58,  2.41it/s]\u001b[A\n",
      "Iteration:  38% 269/699 [01:51<02:57,  2.42it/s]\u001b[A\n",
      "Iteration:  39% 270/699 [01:52<02:58,  2.41it/s]\u001b[A\n",
      "Iteration:  39% 271/699 [01:52<02:57,  2.41it/s]\u001b[A\n",
      "Iteration:  39% 272/699 [01:52<02:56,  2.41it/s]\u001b[A\n",
      "Iteration:  39% 273/699 [01:53<02:56,  2.41it/s]\u001b[A\n",
      "Iteration:  39% 274/699 [01:53<02:56,  2.41it/s]\u001b[A\n",
      "Iteration:  39% 275/699 [01:54<02:56,  2.41it/s]\u001b[A\n",
      "Iteration:  39% 276/699 [01:54<02:55,  2.41it/s]\u001b[A\n",
      "Iteration:  40% 277/699 [01:54<02:55,  2.41it/s]\u001b[A\n",
      "Iteration:  40% 278/699 [01:55<02:54,  2.41it/s]\u001b[A\n",
      "Iteration:  40% 279/699 [01:55<02:54,  2.41it/s]\u001b[A\n",
      "Iteration:  40% 280/699 [01:56<02:54,  2.41it/s]\u001b[A\n",
      "Iteration:  40% 281/699 [01:56<02:53,  2.41it/s]\u001b[A\n",
      "Iteration:  40% 282/699 [01:57<02:53,  2.40it/s]\u001b[A\n",
      "Iteration:  40% 283/699 [01:57<02:52,  2.41it/s]\u001b[A\n",
      "Iteration:  41% 284/699 [01:57<02:52,  2.41it/s]\u001b[A\n",
      "Iteration:  41% 285/699 [01:58<02:52,  2.41it/s]\u001b[A\n",
      "Iteration:  41% 286/699 [01:58<02:51,  2.41it/s]\u001b[A\n",
      "Iteration:  41% 287/699 [01:59<02:51,  2.41it/s]\u001b[A\n",
      "Iteration:  41% 288/699 [01:59<02:50,  2.41it/s]\u001b[A\n",
      "Iteration:  41% 289/699 [01:59<02:50,  2.40it/s]\u001b[A\n",
      "Iteration:  41% 290/699 [02:00<02:50,  2.40it/s]\u001b[A\n",
      "Iteration:  42% 291/699 [02:00<02:50,  2.40it/s]\u001b[A\n",
      "Iteration:  42% 292/699 [02:01<02:49,  2.40it/s]\u001b[A\n",
      "Iteration:  42% 293/699 [02:01<02:49,  2.40it/s]\u001b[A\n",
      "Iteration:  42% 294/699 [02:02<02:48,  2.40it/s]\u001b[A\n",
      "Iteration:  42% 295/699 [02:02<02:48,  2.39it/s]\u001b[A\n",
      "Iteration:  42% 296/699 [02:02<02:47,  2.40it/s]\u001b[A\n",
      "Iteration:  42% 297/699 [02:03<02:47,  2.40it/s]\u001b[A\n",
      "Iteration:  43% 298/699 [02:03<02:47,  2.40it/s]\u001b[A\n",
      "Iteration:  43% 299/699 [02:04<02:46,  2.40it/s]\u001b[A\n",
      "Iteration:  43% 300/699 [02:04<02:46,  2.40it/s]\u001b[A\n",
      "Iteration:  43% 301/699 [02:04<02:45,  2.40it/s]\u001b[A\n",
      "Iteration:  43% 302/699 [02:05<02:45,  2.40it/s]\u001b[A\n",
      "Iteration:  43% 303/699 [02:05<02:45,  2.40it/s]\u001b[A\n",
      "Iteration:  43% 304/699 [02:06<02:44,  2.40it/s]\u001b[A\n",
      "Iteration:  44% 305/699 [02:06<02:44,  2.40it/s]\u001b[A\n",
      "Iteration:  44% 306/699 [02:07<02:44,  2.39it/s]\u001b[A\n",
      "Iteration:  44% 307/699 [02:07<02:43,  2.40it/s]\u001b[A\n",
      "Iteration:  44% 308/699 [02:07<02:43,  2.40it/s]\u001b[A\n",
      "Iteration:  44% 309/699 [02:08<02:43,  2.39it/s]\u001b[A\n",
      "Iteration:  44% 310/699 [02:08<02:42,  2.40it/s]\u001b[A\n",
      "Iteration:  44% 311/699 [02:09<02:42,  2.39it/s]\u001b[A\n",
      "Iteration:  45% 312/699 [02:09<02:41,  2.40it/s]\u001b[A\n",
      "Iteration:  45% 313/699 [02:09<02:41,  2.40it/s]\u001b[A\n",
      "Iteration:  45% 314/699 [02:10<02:41,  2.39it/s]\u001b[A\n",
      "Iteration:  45% 315/699 [02:10<02:40,  2.39it/s]\u001b[A\n",
      "Iteration:  45% 316/699 [02:11<02:40,  2.39it/s]\u001b[A\n",
      "Iteration:  45% 317/699 [02:11<02:39,  2.39it/s]\u001b[A\n",
      "Iteration:  45% 318/699 [02:12<02:38,  2.40it/s]\u001b[A\n",
      "Iteration:  46% 319/699 [02:12<02:38,  2.40it/s]\u001b[A\n",
      "Iteration:  46% 320/699 [02:12<02:38,  2.39it/s]\u001b[A\n",
      "Iteration:  46% 321/699 [02:13<02:37,  2.39it/s]\u001b[A\n",
      "Iteration:  46% 322/699 [02:13<02:37,  2.39it/s]\u001b[A\n",
      "Iteration:  46% 323/699 [02:14<02:36,  2.40it/s]\u001b[A\n",
      "Iteration:  46% 324/699 [02:14<02:36,  2.39it/s]\u001b[A\n",
      "Iteration:  46% 325/699 [02:14<02:36,  2.39it/s]\u001b[A\n",
      "Iteration:  47% 326/699 [02:15<02:36,  2.39it/s]\u001b[A\n",
      "Iteration:  47% 327/699 [02:15<02:35,  2.39it/s]\u001b[A\n",
      "Iteration:  47% 328/699 [02:16<02:34,  2.39it/s]\u001b[A\n",
      "Iteration:  47% 329/699 [02:16<02:34,  2.39it/s]\u001b[A\n",
      "Iteration:  47% 330/699 [02:17<02:34,  2.39it/s]\u001b[A\n",
      "Iteration:  47% 331/699 [02:17<02:34,  2.39it/s]\u001b[A\n",
      "Iteration:  47% 332/699 [02:17<02:33,  2.39it/s]\u001b[A\n",
      "Iteration:  48% 333/699 [02:18<02:33,  2.39it/s]\u001b[A\n",
      "Iteration:  48% 334/699 [02:18<02:32,  2.39it/s]\u001b[A\n",
      "Iteration:  48% 335/699 [02:19<02:32,  2.39it/s]\u001b[A\n",
      "Iteration:  48% 336/699 [02:19<02:31,  2.39it/s]\u001b[A\n",
      "Iteration:  48% 337/699 [02:20<02:31,  2.39it/s]\u001b[A\n",
      "Iteration:  48% 338/699 [02:20<02:30,  2.39it/s]\u001b[A\n",
      "Iteration:  48% 339/699 [02:20<02:30,  2.39it/s]\u001b[A\n",
      "Iteration:  49% 340/699 [02:21<02:29,  2.39it/s]\u001b[A\n",
      "Iteration:  49% 341/699 [02:21<02:29,  2.39it/s]\u001b[A\n",
      "Iteration:  49% 342/699 [02:22<02:29,  2.39it/s]\u001b[A\n",
      "Iteration:  49% 343/699 [02:22<02:28,  2.39it/s]\u001b[A\n",
      "Iteration:  49% 344/699 [02:22<02:28,  2.40it/s]\u001b[A\n",
      "Iteration:  49% 345/699 [02:23<02:27,  2.39it/s]\u001b[A\n",
      "Iteration:  49% 346/699 [02:23<02:27,  2.39it/s]\u001b[A\n",
      "Iteration:  50% 347/699 [02:24<02:27,  2.39it/s]\u001b[A\n",
      "Iteration:  50% 348/699 [02:24<02:26,  2.39it/s]\u001b[A\n",
      "Iteration:  50% 349/699 [02:25<02:26,  2.39it/s]\u001b[A\n",
      "Iteration:  50% 350/699 [02:25<02:26,  2.39it/s]\u001b[A\n",
      "Iteration:  50% 351/699 [02:25<02:26,  2.38it/s]\u001b[A\n",
      "Iteration:  50% 352/699 [02:26<02:25,  2.39it/s]\u001b[A\n",
      "Iteration:  51% 353/699 [02:26<02:24,  2.39it/s]\u001b[A\n",
      "Iteration:  51% 354/699 [02:27<02:24,  2.39it/s]\u001b[A\n",
      "Iteration:  51% 355/699 [02:27<02:24,  2.38it/s]\u001b[A\n",
      "Iteration:  51% 356/699 [02:27<02:23,  2.39it/s]\u001b[A\n",
      "Iteration:  51% 357/699 [02:28<02:23,  2.39it/s]\u001b[A\n",
      "Iteration:  51% 358/699 [02:28<02:22,  2.38it/s]\u001b[A\n",
      "Iteration:  51% 359/699 [02:29<02:22,  2.39it/s]\u001b[A\n",
      "Iteration:  52% 360/699 [02:29<02:22,  2.39it/s]\u001b[A\n",
      "Iteration:  52% 361/699 [02:30<02:21,  2.39it/s]\u001b[A\n",
      "Iteration:  52% 362/699 [02:30<02:21,  2.39it/s]\u001b[A\n",
      "Iteration:  52% 363/699 [02:30<02:20,  2.39it/s]\u001b[A\n",
      "Iteration:  52% 364/699 [02:31<02:20,  2.39it/s]\u001b[A\n",
      "Iteration:  52% 365/699 [02:31<02:19,  2.39it/s]\u001b[A\n",
      "Iteration:  52% 366/699 [02:32<02:19,  2.39it/s]\u001b[A\n",
      "Iteration:  53% 367/699 [02:32<02:18,  2.39it/s]\u001b[A\n",
      "Iteration:  53% 368/699 [02:32<02:18,  2.39it/s]\u001b[A\n",
      "Iteration:  53% 369/699 [02:33<02:17,  2.39it/s]\u001b[A\n",
      "Iteration:  53% 370/699 [02:33<02:17,  2.39it/s]\u001b[A\n",
      "Iteration:  53% 371/699 [02:34<02:17,  2.39it/s]\u001b[A\n",
      "Iteration:  53% 372/699 [02:34<02:16,  2.39it/s]\u001b[A\n",
      "Iteration:  53% 373/699 [02:35<02:16,  2.38it/s]\u001b[A\n",
      "Iteration:  54% 374/699 [02:35<02:16,  2.39it/s]\u001b[A\n",
      "Iteration:  54% 375/699 [02:35<02:16,  2.38it/s]\u001b[A\n",
      "Iteration:  54% 376/699 [02:36<02:15,  2.38it/s]\u001b[A\n",
      "Iteration:  54% 377/699 [02:36<02:14,  2.39it/s]\u001b[A\n",
      "Iteration:  54% 378/699 [02:37<02:14,  2.39it/s]\u001b[A\n",
      "Iteration:  54% 379/699 [02:37<02:13,  2.39it/s]\u001b[A\n",
      "Iteration:  54% 380/699 [02:38<02:13,  2.39it/s]\u001b[A\n",
      "Iteration:  55% 381/699 [02:38<02:13,  2.38it/s]\u001b[A\n",
      "Iteration:  55% 382/699 [02:38<02:13,  2.38it/s]\u001b[A\n",
      "Iteration:  55% 383/699 [02:39<02:12,  2.38it/s]\u001b[A\n",
      "Iteration:  55% 384/699 [02:39<02:11,  2.39it/s]\u001b[A\n",
      "Iteration:  55% 385/699 [02:40<02:11,  2.39it/s]\u001b[A\n",
      "Iteration:  55% 386/699 [02:40<02:11,  2.38it/s]\u001b[A\n",
      "Iteration:  55% 387/699 [02:40<02:10,  2.39it/s]\u001b[A\n",
      "Iteration:  56% 388/699 [02:41<02:10,  2.38it/s]\u001b[A\n",
      "Iteration:  56% 389/699 [02:41<02:09,  2.39it/s]\u001b[A\n",
      "Iteration:  56% 390/699 [02:42<02:09,  2.38it/s]\u001b[A\n",
      "Iteration:  56% 391/699 [02:42<02:09,  2.39it/s]\u001b[A\n",
      "Iteration:  56% 392/699 [02:43<02:08,  2.38it/s]\u001b[A\n",
      "Iteration:  56% 393/699 [02:43<02:08,  2.39it/s]\u001b[A\n",
      "Iteration:  56% 394/699 [02:43<02:07,  2.39it/s]\u001b[A\n",
      "Iteration:  57% 395/699 [02:44<02:07,  2.38it/s]\u001b[A\n",
      "Iteration:  57% 396/699 [02:44<02:06,  2.39it/s]\u001b[A\n",
      "Iteration:  57% 397/699 [02:45<02:06,  2.39it/s]\u001b[A\n",
      "Iteration:  57% 398/699 [02:45<02:06,  2.38it/s]\u001b[A\n",
      "Iteration:  57% 399/699 [02:45<02:05,  2.38it/s]\u001b[A\n",
      "Iteration:  57% 400/699 [02:46<02:05,  2.39it/s]\u001b[A\n",
      "Iteration:  57% 401/699 [02:46<02:04,  2.39it/s]\u001b[A\n",
      "Iteration:  58% 402/699 [02:47<02:04,  2.38it/s]\u001b[A\n",
      "Iteration:  58% 403/699 [02:47<02:03,  2.39it/s]\u001b[A\n",
      "Iteration:  58% 404/699 [02:48<02:03,  2.39it/s]\u001b[A\n",
      "Iteration:  58% 405/699 [02:48<02:02,  2.39it/s]\u001b[A\n",
      "Iteration:  58% 406/699 [02:48<02:02,  2.39it/s]\u001b[A\n",
      "Iteration:  58% 407/699 [02:49<02:02,  2.39it/s]\u001b[A\n",
      "Iteration:  58% 408/699 [02:49<02:01,  2.39it/s]\u001b[A\n",
      "Iteration:  59% 409/699 [02:50<02:01,  2.39it/s]\u001b[A\n",
      "Iteration:  59% 410/699 [02:50<02:00,  2.39it/s]\u001b[A\n",
      "Iteration:  59% 411/699 [02:51<02:00,  2.39it/s]\u001b[A\n",
      "Iteration:  59% 412/699 [02:51<02:00,  2.38it/s]\u001b[A\n",
      "Iteration:  59% 413/699 [02:51<01:59,  2.38it/s]\u001b[A\n",
      "Iteration:  59% 414/699 [02:52<01:59,  2.39it/s]\u001b[A\n",
      "Iteration:  59% 415/699 [02:52<01:58,  2.39it/s]\u001b[A\n",
      "Iteration:  60% 416/699 [02:53<01:58,  2.39it/s]\u001b[A\n",
      "Iteration:  60% 417/699 [02:53<01:58,  2.39it/s]\u001b[A\n",
      "Iteration:  60% 418/699 [02:53<01:57,  2.38it/s]\u001b[A\n",
      "Iteration:  60% 419/699 [02:54<01:57,  2.39it/s]\u001b[A\n",
      "Iteration:  60% 420/699 [02:54<01:56,  2.39it/s]\u001b[A\n",
      "Iteration:  60% 421/699 [02:55<01:56,  2.39it/s]\u001b[A\n",
      "Iteration:  60% 422/699 [02:55<01:55,  2.39it/s]\u001b[A\n",
      "Iteration:  61% 423/699 [02:56<01:55,  2.39it/s]\u001b[A\n",
      "Iteration:  61% 424/699 [02:56<01:54,  2.39it/s]\u001b[A\n",
      "Iteration:  61% 425/699 [02:56<01:54,  2.40it/s]\u001b[A\n",
      "Iteration:  61% 426/699 [02:57<01:54,  2.39it/s]\u001b[A\n",
      "Iteration:  61% 427/699 [02:57<01:53,  2.39it/s]\u001b[A\n",
      "Iteration:  61% 428/699 [02:58<01:53,  2.39it/s]\u001b[A\n",
      "Iteration:  61% 429/699 [02:58<01:52,  2.39it/s]\u001b[A\n",
      "Iteration:  62% 430/699 [02:58<01:52,  2.39it/s]\u001b[A\n",
      "Iteration:  62% 431/699 [02:59<01:51,  2.39it/s]\u001b[A\n",
      "Iteration:  62% 432/699 [02:59<01:51,  2.39it/s]\u001b[A\n",
      "Iteration:  62% 433/699 [03:00<01:51,  2.40it/s]\u001b[A\n",
      "Iteration:  62% 434/699 [03:00<01:50,  2.39it/s]\u001b[A\n",
      "Iteration:  62% 435/699 [03:01<01:50,  2.39it/s]\u001b[A\n",
      "Iteration:  62% 436/699 [03:01<01:49,  2.39it/s]\u001b[A\n",
      "Iteration:  63% 437/699 [03:01<01:49,  2.39it/s]\u001b[A\n",
      "Iteration:  63% 438/699 [03:02<01:49,  2.39it/s]\u001b[A\n",
      "Iteration:  63% 439/699 [03:02<01:48,  2.39it/s]\u001b[A\n",
      "Iteration:  63% 440/699 [03:03<01:48,  2.39it/s]\u001b[A\n",
      "Iteration:  63% 441/699 [03:03<01:47,  2.39it/s]\u001b[A\n",
      "Iteration:  63% 442/699 [03:03<01:47,  2.39it/s]\u001b[A\n",
      "Iteration:  63% 443/699 [03:04<01:47,  2.39it/s]\u001b[A\n",
      "Iteration:  64% 444/699 [03:04<01:46,  2.39it/s]\u001b[A\n",
      "Iteration:  64% 445/699 [03:05<01:46,  2.38it/s]\u001b[A\n",
      "Iteration:  64% 446/699 [03:05<01:46,  2.38it/s]\u001b[A\n",
      "Iteration:  64% 447/699 [03:06<01:45,  2.39it/s]\u001b[A\n",
      "Iteration:  64% 448/699 [03:06<01:45,  2.39it/s]\u001b[A\n",
      "Iteration:  64% 449/699 [03:06<01:44,  2.39it/s]\u001b[A\n",
      "Iteration:  64% 450/699 [03:07<01:43,  2.40it/s]\u001b[A\n",
      "Iteration:  65% 451/699 [03:07<01:43,  2.39it/s]\u001b[A\n",
      "Iteration:  65% 452/699 [03:08<01:43,  2.39it/s]\u001b[A\n",
      "Iteration:  65% 453/699 [03:08<01:42,  2.40it/s]\u001b[A\n",
      "Iteration:  65% 454/699 [03:08<01:42,  2.39it/s]\u001b[A\n",
      "Iteration:  65% 455/699 [03:09<01:41,  2.40it/s]\u001b[A\n",
      "Iteration:  65% 456/699 [03:09<01:41,  2.39it/s]\u001b[A\n",
      "Iteration:  65% 457/699 [03:10<01:41,  2.39it/s]\u001b[A\n",
      "Iteration:  66% 458/699 [03:10<01:40,  2.39it/s]\u001b[A\n",
      "Iteration:  66% 459/699 [03:11<01:40,  2.39it/s]\u001b[A\n",
      "Iteration:  66% 460/699 [03:11<01:39,  2.40it/s]\u001b[A\n",
      "Iteration:  66% 461/699 [03:11<01:39,  2.40it/s]\u001b[A\n",
      "Iteration:  66% 462/699 [03:12<01:38,  2.39it/s]\u001b[A\n",
      "Iteration:  66% 463/699 [03:12<01:38,  2.39it/s]\u001b[A\n",
      "Iteration:  66% 464/699 [03:13<01:38,  2.39it/s]\u001b[A\n",
      "Iteration:  67% 465/699 [03:13<01:37,  2.40it/s]\u001b[A\n",
      "Iteration:  67% 466/699 [03:14<01:37,  2.39it/s]\u001b[A\n",
      "Iteration:  67% 467/699 [03:14<01:36,  2.39it/s]\u001b[A\n",
      "Iteration:  67% 468/699 [03:14<01:36,  2.39it/s]\u001b[A\n",
      "Iteration:  67% 469/699 [03:15<01:35,  2.40it/s]\u001b[A\n",
      "Iteration:  67% 470/699 [03:15<01:35,  2.40it/s]\u001b[A\n",
      "Iteration:  67% 471/699 [03:16<01:35,  2.40it/s]\u001b[A\n",
      "Iteration:  68% 472/699 [03:16<01:34,  2.40it/s]\u001b[A\n",
      "Iteration:  68% 473/699 [03:16<01:34,  2.39it/s]\u001b[A\n",
      "Iteration:  68% 474/699 [03:17<01:33,  2.39it/s]\u001b[A\n",
      "Iteration:  68% 475/699 [03:17<01:33,  2.39it/s]\u001b[A\n",
      "Iteration:  68% 476/699 [03:18<01:33,  2.39it/s]\u001b[A\n",
      "Iteration:  68% 477/699 [03:18<01:32,  2.39it/s]\u001b[A\n",
      "Iteration:  68% 478/699 [03:19<01:32,  2.39it/s]\u001b[A\n",
      "Iteration:  69% 479/699 [03:19<01:32,  2.39it/s]\u001b[A\n",
      "Iteration:  69% 480/699 [03:19<01:31,  2.39it/s]\u001b[A\n",
      "Iteration:  69% 481/699 [03:20<01:31,  2.40it/s]\u001b[A\n",
      "Iteration:  69% 482/699 [03:20<01:30,  2.39it/s]\u001b[A\n",
      "Iteration:  69% 483/699 [03:21<01:30,  2.39it/s]\u001b[A\n",
      "Iteration:  69% 484/699 [03:21<01:29,  2.40it/s]\u001b[A\n",
      "Iteration:  69% 485/699 [03:21<01:29,  2.39it/s]\u001b[A\n",
      "Iteration:  70% 486/699 [03:22<01:29,  2.39it/s]\u001b[A\n",
      "Iteration:  70% 487/699 [03:22<01:28,  2.39it/s]\u001b[A\n",
      "Iteration:  70% 488/699 [03:23<01:28,  2.39it/s]\u001b[A\n",
      "Iteration:  70% 489/699 [03:23<01:27,  2.40it/s]\u001b[A\n",
      "Iteration:  70% 490/699 [03:24<01:27,  2.39it/s]\u001b[A\n",
      "Iteration:  70% 491/699 [03:24<01:26,  2.39it/s]\u001b[A\n",
      "Iteration:  70% 492/699 [03:24<01:26,  2.40it/s]\u001b[A\n",
      "Iteration:  71% 493/699 [03:25<01:26,  2.39it/s]\u001b[A\n",
      "Iteration:  71% 494/699 [03:25<01:25,  2.39it/s]\u001b[A\n",
      "Iteration:  71% 495/699 [03:26<01:25,  2.39it/s]\u001b[A\n",
      "Iteration:  71% 496/699 [03:26<01:24,  2.39it/s]\u001b[A\n",
      "Iteration:  71% 497/699 [03:26<01:24,  2.39it/s]\u001b[A\n",
      "Iteration:  71% 498/699 [03:27<01:24,  2.39it/s]\u001b[A\n",
      "Iteration:  71% 499/699 [03:27<01:23,  2.39it/s]\u001b[A/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:231: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n",
      "05/22/2020 03:51:35 - INFO - transformers.configuration_utils -   Configuration saved in output_gpt_text_0/checkpoint-500/config.json\n",
      "05/22/2020 03:51:37 - INFO - transformers.modeling_utils -   Model weights saved in output_gpt_text_0/checkpoint-500/pytorch_model.bin\n",
      "05/22/2020 03:51:37 - INFO - __main__ -   Saving model checkpoint to output_gpt_text_0/checkpoint-500\n",
      "/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:200: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.\n",
      "  warnings.warn(SAVE_STATE_WARNING, UserWarning)\n",
      "05/22/2020 03:51:42 - INFO - __main__ -   Saving optimizer and scheduler states to output_gpt_text_0/checkpoint-500\n",
      "\n",
      "Iteration:  72% 500/699 [03:34<07:29,  2.26s/it]\u001b[A\n",
      "Iteration:  72% 501/699 [03:34<05:38,  1.71s/it]\u001b[A\n",
      "Iteration:  72% 502/699 [03:35<04:19,  1.32s/it]\u001b[A\n",
      "Iteration:  72% 503/699 [03:35<03:25,  1.05s/it]\u001b[A\n",
      "Iteration:  72% 504/699 [03:36<02:47,  1.17it/s]\u001b[A\n",
      "Iteration:  72% 505/699 [03:36<02:19,  1.39it/s]\u001b[A\n",
      "Iteration:  72% 506/699 [03:36<02:01,  1.59it/s]\u001b[A\n",
      "Iteration:  73% 507/699 [03:37<01:48,  1.78it/s]\u001b[A\n",
      "Iteration:  73% 508/699 [03:37<01:39,  1.93it/s]\u001b[A\n",
      "Iteration:  73% 509/699 [03:38<01:32,  2.05it/s]\u001b[A\n",
      "Iteration:  73% 510/699 [03:38<01:27,  2.16it/s]\u001b[A\n",
      "Iteration:  73% 511/699 [03:38<01:24,  2.23it/s]\u001b[A\n",
      "Iteration:  73% 512/699 [03:39<01:21,  2.28it/s]\u001b[A\n",
      "Iteration:  73% 513/699 [03:39<01:20,  2.32it/s]\u001b[A\n",
      "Iteration:  74% 514/699 [03:40<01:19,  2.34it/s]\u001b[A\n",
      "Iteration:  74% 515/699 [03:40<01:17,  2.37it/s]\u001b[A\n",
      "Iteration:  74% 516/699 [03:40<01:16,  2.38it/s]\u001b[A\n",
      "Iteration:  74% 517/699 [03:41<01:16,  2.39it/s]\u001b[A\n",
      "Iteration:  74% 518/699 [03:41<01:15,  2.40it/s]\u001b[A\n",
      "Iteration:  74% 519/699 [03:42<01:14,  2.40it/s]\u001b[A\n",
      "Iteration:  74% 520/699 [03:42<01:14,  2.41it/s]\u001b[A\n",
      "Iteration:  75% 521/699 [03:43<01:14,  2.40it/s]\u001b[A\n",
      "Iteration:  75% 522/699 [03:43<01:13,  2.41it/s]\u001b[A\n",
      "Iteration:  75% 523/699 [03:43<01:13,  2.40it/s]\u001b[A\n",
      "Iteration:  75% 524/699 [03:44<01:12,  2.40it/s]\u001b[A\n",
      "Iteration:  75% 525/699 [03:44<01:12,  2.40it/s]\u001b[A\n",
      "Iteration:  75% 526/699 [03:45<01:11,  2.41it/s]\u001b[A\n",
      "Iteration:  75% 527/699 [03:45<01:11,  2.40it/s]\u001b[A\n",
      "Iteration:  76% 528/699 [03:45<01:11,  2.40it/s]\u001b[A\n",
      "Iteration:  76% 529/699 [03:46<01:10,  2.40it/s]\u001b[A\n",
      "Iteration:  76% 530/699 [03:46<01:10,  2.39it/s]\u001b[A\n",
      "Iteration:  76% 531/699 [03:47<01:09,  2.40it/s]\u001b[A\n",
      "Iteration:  76% 532/699 [03:47<01:09,  2.40it/s]\u001b[A\n",
      "Iteration:  76% 533/699 [03:48<01:09,  2.40it/s]\u001b[A\n",
      "Iteration:  76% 534/699 [03:48<01:08,  2.39it/s]\u001b[A\n",
      "Iteration:  77% 535/699 [03:48<01:08,  2.39it/s]\u001b[A\n",
      "Iteration:  77% 536/699 [03:49<01:08,  2.39it/s]\u001b[A\n",
      "Iteration:  77% 537/699 [03:49<01:07,  2.39it/s]\u001b[A\n",
      "Iteration:  77% 538/699 [03:50<01:07,  2.39it/s]\u001b[A\n",
      "Iteration:  77% 539/699 [03:50<01:06,  2.39it/s]\u001b[A\n",
      "Iteration:  77% 540/699 [03:50<01:06,  2.38it/s]\u001b[A\n",
      "Iteration:  77% 541/699 [03:51<01:06,  2.38it/s]\u001b[A\n",
      "Iteration:  78% 542/699 [03:51<01:06,  2.38it/s]\u001b[A\n",
      "Iteration:  78% 543/699 [03:52<01:05,  2.38it/s]\u001b[A\n",
      "Iteration:  78% 544/699 [03:52<01:05,  2.37it/s]\u001b[A\n",
      "Iteration:  78% 545/699 [03:53<01:04,  2.38it/s]\u001b[A\n",
      "Iteration:  78% 546/699 [03:53<01:04,  2.37it/s]\u001b[A\n",
      "Iteration:  78% 547/699 [03:53<01:04,  2.37it/s]\u001b[A\n",
      "Iteration:  78% 548/699 [03:54<01:03,  2.37it/s]\u001b[A\n",
      "Iteration:  79% 549/699 [03:54<01:03,  2.37it/s]\u001b[A\n",
      "Iteration:  79% 550/699 [03:55<01:02,  2.37it/s]\u001b[A\n",
      "Iteration:  79% 551/699 [03:55<01:02,  2.37it/s]\u001b[A\n",
      "Iteration:  79% 552/699 [03:56<01:02,  2.36it/s]\u001b[A\n",
      "Iteration:  79% 553/699 [03:56<01:01,  2.36it/s]\u001b[A\n",
      "Iteration:  79% 554/699 [03:56<01:01,  2.36it/s]\u001b[A\n",
      "Iteration:  79% 555/699 [03:57<01:01,  2.36it/s]\u001b[A\n",
      "Iteration:  80% 556/699 [03:57<01:00,  2.35it/s]\u001b[A\n",
      "Iteration:  80% 557/699 [03:58<01:00,  2.35it/s]\u001b[A\n",
      "Iteration:  80% 558/699 [03:58<00:59,  2.36it/s]\u001b[A\n",
      "Iteration:  80% 559/699 [03:59<00:59,  2.35it/s]\u001b[A\n",
      "Iteration:  80% 560/699 [03:59<00:59,  2.35it/s]\u001b[A\n",
      "Iteration:  80% 561/699 [03:59<00:58,  2.36it/s]\u001b[A\n",
      "Iteration:  80% 562/699 [04:00<00:58,  2.35it/s]\u001b[A\n",
      "Iteration:  81% 563/699 [04:00<00:57,  2.35it/s]\u001b[A\n",
      "Iteration:  81% 564/699 [04:01<00:57,  2.35it/s]\u001b[A\n",
      "Iteration:  81% 565/699 [04:01<00:57,  2.35it/s]\u001b[A\n",
      "Iteration:  81% 566/699 [04:01<00:56,  2.35it/s]\u001b[A\n",
      "Iteration:  81% 567/699 [04:02<00:56,  2.35it/s]\u001b[A\n",
      "Iteration:  81% 568/699 [04:02<00:55,  2.35it/s]\u001b[A\n",
      "Iteration:  81% 569/699 [04:03<00:55,  2.35it/s]\u001b[A\n",
      "Iteration:  82% 570/699 [04:03<00:54,  2.35it/s]\u001b[A\n",
      "Iteration:  82% 571/699 [04:04<00:54,  2.35it/s]\u001b[A\n",
      "Iteration:  82% 572/699 [04:04<00:53,  2.35it/s]\u001b[A\n",
      "Iteration:  82% 573/699 [04:04<00:53,  2.35it/s]\u001b[A\n",
      "Iteration:  82% 574/699 [04:05<00:53,  2.35it/s]\u001b[A\n",
      "Iteration:  82% 575/699 [04:05<00:52,  2.35it/s]\u001b[A\n",
      "Iteration:  82% 576/699 [04:06<00:52,  2.35it/s]\u001b[A\n",
      "Iteration:  83% 577/699 [04:06<00:51,  2.35it/s]\u001b[A\n",
      "Iteration:  83% 578/699 [04:07<00:51,  2.35it/s]\u001b[A\n",
      "Iteration:  83% 579/699 [04:07<00:50,  2.35it/s]\u001b[A\n",
      "Iteration:  83% 580/699 [04:07<00:50,  2.36it/s]\u001b[A\n",
      "Iteration:  83% 581/699 [04:08<00:49,  2.36it/s]\u001b[A\n",
      "Iteration:  83% 582/699 [04:08<00:49,  2.36it/s]\u001b[A\n",
      "Iteration:  83% 583/699 [04:09<00:49,  2.37it/s]\u001b[A\n",
      "Iteration:  84% 584/699 [04:09<00:48,  2.37it/s]\u001b[A\n",
      "Iteration:  84% 585/699 [04:10<00:48,  2.37it/s]\u001b[A\n",
      "Iteration:  84% 586/699 [04:10<00:47,  2.37it/s]\u001b[A\n",
      "Iteration:  84% 587/699 [04:10<00:47,  2.37it/s]\u001b[A\n",
      "Iteration:  84% 588/699 [04:11<00:46,  2.37it/s]\u001b[A\n",
      "Iteration:  84% 589/699 [04:11<00:46,  2.37it/s]\u001b[A\n",
      "Iteration:  84% 590/699 [04:12<00:46,  2.37it/s]\u001b[A\n",
      "Iteration:  85% 591/699 [04:12<00:45,  2.37it/s]\u001b[A\n",
      "Iteration:  85% 592/699 [04:13<00:45,  2.38it/s]\u001b[A\n",
      "Iteration:  85% 593/699 [04:13<00:44,  2.38it/s]\u001b[A\n",
      "Iteration:  85% 594/699 [04:13<00:44,  2.37it/s]\u001b[A\n",
      "Iteration:  85% 595/699 [04:14<00:43,  2.37it/s]\u001b[A\n",
      "Iteration:  85% 596/699 [04:14<00:43,  2.37it/s]\u001b[A\n",
      "Iteration:  85% 597/699 [04:15<00:42,  2.37it/s]\u001b[A\n",
      "Iteration:  86% 598/699 [04:15<00:42,  2.37it/s]\u001b[A\n",
      "Iteration:  86% 599/699 [04:15<00:42,  2.37it/s]\u001b[A\n",
      "Iteration:  86% 600/699 [04:16<00:41,  2.37it/s]\u001b[A\n",
      "Iteration:  86% 601/699 [04:16<00:41,  2.37it/s]\u001b[A\n",
      "Iteration:  86% 602/699 [04:17<00:40,  2.37it/s]\u001b[A\n",
      "Iteration:  86% 603/699 [04:17<00:40,  2.38it/s]\u001b[A\n",
      "Iteration:  86% 604/699 [04:18<00:39,  2.38it/s]\u001b[A\n",
      "Iteration:  87% 605/699 [04:18<00:39,  2.37it/s]\u001b[A\n",
      "Iteration:  87% 606/699 [04:18<00:39,  2.38it/s]\u001b[A\n",
      "Iteration:  87% 607/699 [04:19<00:38,  2.38it/s]\u001b[A\n",
      "Iteration:  87% 608/699 [04:19<00:38,  2.38it/s]\u001b[A\n",
      "Iteration:  87% 609/699 [04:20<00:37,  2.38it/s]\u001b[A\n",
      "Iteration:  87% 610/699 [04:20<00:37,  2.38it/s]\u001b[A\n",
      "Iteration:  87% 611/699 [04:20<00:36,  2.38it/s]\u001b[A\n",
      "Iteration:  88% 612/699 [04:21<00:36,  2.39it/s]\u001b[A\n",
      "Iteration:  88% 613/699 [04:21<00:35,  2.39it/s]\u001b[A\n",
      "Iteration:  88% 614/699 [04:22<00:35,  2.40it/s]\u001b[A\n",
      "Iteration:  88% 615/699 [04:22<00:35,  2.39it/s]\u001b[A\n",
      "Iteration:  88% 616/699 [04:23<00:34,  2.39it/s]\u001b[A\n",
      "Iteration:  88% 617/699 [04:23<00:34,  2.39it/s]\u001b[A\n",
      "Iteration:  88% 618/699 [04:23<00:33,  2.39it/s]\u001b[A\n",
      "Iteration:  89% 619/699 [04:24<00:33,  2.39it/s]\u001b[A\n",
      "Iteration:  89% 620/699 [04:24<00:33,  2.39it/s]\u001b[A\n",
      "Iteration:  89% 621/699 [04:25<00:32,  2.39it/s]\u001b[A\n",
      "Iteration:  89% 622/699 [04:25<00:32,  2.39it/s]\u001b[A\n",
      "Iteration:  89% 623/699 [04:26<00:31,  2.39it/s]\u001b[A\n",
      "Iteration:  89% 624/699 [04:26<00:31,  2.39it/s]\u001b[A\n",
      "Iteration:  89% 625/699 [04:26<00:30,  2.40it/s]\u001b[A\n",
      "Iteration:  90% 626/699 [04:27<00:30,  2.39it/s]\u001b[A\n",
      "Iteration:  90% 627/699 [04:27<00:30,  2.39it/s]\u001b[A\n",
      "Iteration:  90% 628/699 [04:28<00:29,  2.39it/s]\u001b[A\n",
      "Iteration:  90% 629/699 [04:28<00:29,  2.39it/s]\u001b[A\n",
      "Iteration:  90% 630/699 [04:28<00:28,  2.39it/s]\u001b[A\n",
      "Iteration:  90% 631/699 [04:29<00:28,  2.40it/s]\u001b[A\n",
      "Iteration:  90% 632/699 [04:29<00:27,  2.40it/s]\u001b[A\n",
      "Iteration:  91% 633/699 [04:30<00:27,  2.40it/s]\u001b[A\n",
      "Iteration:  91% 634/699 [04:30<00:27,  2.40it/s]\u001b[A\n",
      "Iteration:  91% 635/699 [04:31<00:26,  2.40it/s]\u001b[A\n",
      "Iteration:  91% 636/699 [04:31<00:26,  2.40it/s]\u001b[A\n",
      "Iteration:  91% 637/699 [04:31<00:25,  2.40it/s]\u001b[A\n",
      "Iteration:  91% 638/699 [04:32<00:25,  2.40it/s]\u001b[A\n",
      "Iteration:  91% 639/699 [04:32<00:25,  2.39it/s]\u001b[A\n",
      "Iteration:  92% 640/699 [04:33<00:24,  2.40it/s]\u001b[A\n",
      "Iteration:  92% 641/699 [04:33<00:24,  2.39it/s]\u001b[A\n",
      "Iteration:  92% 642/699 [04:33<00:23,  2.40it/s]\u001b[A\n",
      "Iteration:  92% 643/699 [04:34<00:23,  2.40it/s]\u001b[A\n",
      "Iteration:  92% 644/699 [04:34<00:22,  2.40it/s]\u001b[A\n",
      "Iteration:  92% 645/699 [04:35<00:22,  2.40it/s]\u001b[A\n",
      "Iteration:  92% 646/699 [04:35<00:22,  2.40it/s]\u001b[A\n",
      "Iteration:  93% 647/699 [04:36<00:21,  2.40it/s]\u001b[A\n",
      "Iteration:  93% 648/699 [04:36<00:21,  2.41it/s]\u001b[A\n",
      "Iteration:  93% 649/699 [04:36<00:20,  2.41it/s]\u001b[A\n",
      "Iteration:  93% 650/699 [04:37<00:20,  2.41it/s]\u001b[A\n",
      "Iteration:  93% 651/699 [04:37<00:19,  2.40it/s]\u001b[A\n",
      "Iteration:  93% 652/699 [04:38<00:19,  2.41it/s]\u001b[A\n",
      "Iteration:  93% 653/699 [04:38<00:19,  2.39it/s]\u001b[A\n",
      "Iteration:  94% 654/699 [04:38<00:18,  2.41it/s]\u001b[A\n",
      "Iteration:  94% 655/699 [04:39<00:18,  2.41it/s]\u001b[A\n",
      "Iteration:  94% 656/699 [04:39<00:17,  2.41it/s]\u001b[A\n",
      "Iteration:  94% 657/699 [04:40<00:17,  2.41it/s]\u001b[A\n",
      "Iteration:  94% 658/699 [04:40<00:17,  2.41it/s]\u001b[A\n",
      "Iteration:  94% 659/699 [04:41<00:16,  2.41it/s]\u001b[A\n",
      "Iteration:  94% 660/699 [04:41<00:16,  2.41it/s]\u001b[A\n",
      "Iteration:  95% 661/699 [04:41<00:15,  2.41it/s]\u001b[A\n",
      "Iteration:  95% 662/699 [04:42<00:15,  2.41it/s]\u001b[A\n",
      "Iteration:  95% 663/699 [04:42<00:14,  2.41it/s]\u001b[A\n",
      "Iteration:  95% 664/699 [04:43<00:14,  2.41it/s]\u001b[A\n",
      "Iteration:  95% 665/699 [04:43<00:14,  2.41it/s]\u001b[A\n",
      "Iteration:  95% 666/699 [04:43<00:13,  2.41it/s]\u001b[A\n",
      "Iteration:  95% 667/699 [04:44<00:13,  2.42it/s]\u001b[A\n",
      "Iteration:  96% 668/699 [04:44<00:12,  2.41it/s]\u001b[A\n",
      "Iteration:  96% 669/699 [04:45<00:12,  2.41it/s]\u001b[A\n",
      "Iteration:  96% 670/699 [04:45<00:12,  2.41it/s]\u001b[A\n",
      "Iteration:  96% 671/699 [04:45<00:11,  2.42it/s]\u001b[A\n",
      "Iteration:  96% 672/699 [04:46<00:11,  2.42it/s]\u001b[A\n",
      "Iteration:  96% 673/699 [04:46<00:10,  2.42it/s]\u001b[A\n",
      "Iteration:  96% 674/699 [04:47<00:10,  2.42it/s]\u001b[A\n",
      "Iteration:  97% 675/699 [04:47<00:09,  2.41it/s]\u001b[A\n",
      "Iteration:  97% 676/699 [04:48<00:09,  2.42it/s]\u001b[A\n",
      "Iteration:  97% 677/699 [04:48<00:09,  2.41it/s]\u001b[A\n",
      "Iteration:  97% 678/699 [04:48<00:08,  2.42it/s]\u001b[A\n",
      "Iteration:  97% 679/699 [04:49<00:08,  2.41it/s]\u001b[A\n",
      "Iteration:  97% 680/699 [04:49<00:07,  2.41it/s]\u001b[A\n",
      "Iteration:  97% 681/699 [04:50<00:07,  2.41it/s]\u001b[A\n",
      "Iteration:  98% 682/699 [04:50<00:07,  2.40it/s]\u001b[A\n",
      "Iteration:  98% 683/699 [04:50<00:06,  2.41it/s]\u001b[A\n",
      "Iteration:  98% 684/699 [04:51<00:06,  2.41it/s]\u001b[A\n",
      "Iteration:  98% 685/699 [04:51<00:05,  2.41it/s]\u001b[A\n",
      "Iteration:  98% 686/699 [04:52<00:05,  2.41it/s]\u001b[A\n",
      "Iteration:  98% 687/699 [04:52<00:04,  2.41it/s]\u001b[A\n",
      "Iteration:  98% 688/699 [04:53<00:04,  2.41it/s]\u001b[A\n",
      "Iteration:  99% 689/699 [04:53<00:04,  2.40it/s]\u001b[A\n",
      "Iteration:  99% 690/699 [04:53<00:03,  2.41it/s]\u001b[A\n",
      "Iteration:  99% 691/699 [04:54<00:03,  2.41it/s]\u001b[A\n",
      "Iteration:  99% 692/699 [04:54<00:02,  2.41it/s]\u001b[A\n",
      "Iteration:  99% 693/699 [04:55<00:02,  2.40it/s]\u001b[A\n",
      "Iteration:  99% 694/699 [04:55<00:02,  2.41it/s]\u001b[A\n",
      "Iteration:  99% 695/699 [04:55<00:01,  2.41it/s]\u001b[A\n",
      "Iteration: 100% 696/699 [04:56<00:01,  2.40it/s]\u001b[A\n",
      "Iteration: 100% 697/699 [04:56<00:00,  2.41it/s]\u001b[A\n",
      "Iteration: 100% 698/699 [04:57<00:00,  2.41it/s]\u001b[A\n",
      "Iteration: 100% 699/699 [04:57<00:00,  2.35it/s]\n",
      "Epoch: 100% 1/1 [04:57<00:00, 297.60s/it]\n",
      "05/22/2020 03:53:05 - INFO - __main__ -    global_step = 699, average loss = 3.5057688397228803\n",
      "05/22/2020 03:53:05 - INFO - __main__ -   Saving model checkpoint to output_gpt_text_0\n",
      "05/22/2020 03:53:05 - INFO - transformers.configuration_utils -   Configuration saved in output_gpt_text_0/config.json\n",
      "05/22/2020 03:53:06 - INFO - transformers.modeling_utils -   Model weights saved in output_gpt_text_0/pytorch_model.bin\n",
      "05/22/2020 03:53:06 - INFO - transformers.configuration_utils -   loading configuration file output_gpt_text_0/config.json\n",
      "05/22/2020 03:53:06 - INFO - transformers.configuration_utils -   Model config GPT2Config {\n",
      "  \"activation_function\": \"gelu_new\",\n",
      "  \"architectures\": [\n",
      "    \"GPT2LMHeadModel\"\n",
      "  ],\n",
      "  \"attn_pdrop\": 0.1,\n",
      "  \"bos_token_id\": 50256,\n",
      "  \"embd_pdrop\": 0.1,\n",
      "  \"eos_token_id\": 50256,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"gpt2\",\n",
      "  \"n_ctx\": 1024,\n",
      "  \"n_embd\": 768,\n",
      "  \"n_head\": 12,\n",
      "  \"n_layer\": 12,\n",
      "  \"n_positions\": 1024,\n",
      "  \"resid_pdrop\": 0.1,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"cls_index\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"task_specific_params\": {\n",
      "    \"text-generation\": {\n",
      "      \"do_sample\": true,\n",
      "      \"max_length\": 50\n",
      "    }\n",
      "  },\n",
      "  \"vocab_size\": 50257\n",
      "}\n",
      "\n",
      "05/22/2020 03:53:06 - INFO - transformers.modeling_utils -   loading weights file output_gpt_text_0/pytorch_model.bin\n",
      "05/22/2020 03:53:11 - INFO - transformers.tokenization_utils -   Model name 'output_gpt_text_0' not found in model shortcut name list (gpt2, gpt2-medium, gpt2-large, gpt2-xl, distilgpt2). Assuming 'output_gpt_text_0' is a path, a model identifier, or url to a directory containing tokenizer files.\n",
      "05/22/2020 03:53:11 - INFO - transformers.tokenization_utils -   Didn't find file output_gpt_text_0/added_tokens.json. We won't load it.\n",
      "05/22/2020 03:53:11 - INFO - transformers.tokenization_utils -   loading file output_gpt_text_0/vocab.json\n",
      "05/22/2020 03:53:11 - INFO - transformers.tokenization_utils -   loading file output_gpt_text_0/merges.txt\n",
      "05/22/2020 03:53:11 - INFO - transformers.tokenization_utils -   loading file None\n",
      "05/22/2020 03:53:11 - INFO - transformers.tokenization_utils -   loading file output_gpt_text_0/special_tokens_map.json\n",
      "05/22/2020 03:53:11 - INFO - transformers.tokenization_utils -   loading file output_gpt_text_0/tokenizer_config.json\n",
      "05/22/2020 03:53:11 - INFO - __main__ -   Evaluate the following checkpoints: ['output_gpt_text_0']\n",
      "05/22/2020 03:53:11 - INFO - transformers.configuration_utils -   loading configuration file output_gpt_text_0/config.json\n",
      "05/22/2020 03:53:11 - INFO - transformers.configuration_utils -   Model config GPT2Config {\n",
      "  \"activation_function\": \"gelu_new\",\n",
      "  \"architectures\": [\n",
      "    \"GPT2LMHeadModel\"\n",
      "  ],\n",
      "  \"attn_pdrop\": 0.1,\n",
      "  \"bos_token_id\": 50256,\n",
      "  \"embd_pdrop\": 0.1,\n",
      "  \"eos_token_id\": 50256,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"gpt2\",\n",
      "  \"n_ctx\": 1024,\n",
      "  \"n_embd\": 768,\n",
      "  \"n_head\": 12,\n",
      "  \"n_layer\": 12,\n",
      "  \"n_positions\": 1024,\n",
      "  \"resid_pdrop\": 0.1,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"cls_index\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"task_specific_params\": {\n",
      "    \"text-generation\": {\n",
      "      \"do_sample\": true,\n",
      "      \"max_length\": 50\n",
      "    }\n",
      "  },\n",
      "  \"vocab_size\": 50257\n",
      "}\n",
      "\n",
      "05/22/2020 03:53:11 - INFO - transformers.modeling_utils -   loading weights file output_gpt_text_0/pytorch_model.bin\n",
      "05/22/2020 03:53:16 - INFO - __main__ -   Loading features from cached file gpt2_cached_lm_1024_test_text\n",
      "05/22/2020 03:53:16 - INFO - __main__ -   ***** Running evaluation  *****\n",
      "05/22/2020 03:53:16 - INFO - __main__ -     Num examples = 175\n",
      "05/22/2020 03:53:16 - INFO - __main__ -     Batch size = 1\n",
      "Evaluating: 100% 175/175 [00:22<00:00,  7.84it/s]\n",
      "05/22/2020 03:53:38 - INFO - __main__ -   ***** Eval results  *****\n",
      "05/22/2020 03:53:38 - INFO - __main__ -     perplexity = tensor(28.0279)\n"
     ]
    }
   ],
   "source": [
    "!python run_language_modelling.py --output_dir=output_gpt_text_0 --model_type=gpt2 --model_name_or_path=gpt2 --do_train --train_data_file=train_text --do_eval --eval_data_file=test_text --per_gpu_train_batch_size=1 --per_gpu_eval_batch_size=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 900
    },
    "colab_type": "code",
    "id": "8XCI9vz6dWZm",
    "outputId": "3142f939-3c58-45c5-c33d-74c980165a2d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-05-22 03:53:50.648163: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
      "05/22/2020 03:53:52 - INFO - transformers.tokenization_utils -   Model name 'output_gpt_text_0' not found in model shortcut name list (gpt2, gpt2-medium, gpt2-large, gpt2-xl, distilgpt2). Assuming 'output_gpt_text_0' is a path, a model identifier, or url to a directory containing tokenizer files.\n",
      "05/22/2020 03:53:52 - INFO - transformers.tokenization_utils -   Didn't find file output_gpt_text_0/added_tokens.json. We won't load it.\n",
      "05/22/2020 03:53:52 - INFO - transformers.tokenization_utils -   loading file output_gpt_text_0/vocab.json\n",
      "05/22/2020 03:53:52 - INFO - transformers.tokenization_utils -   loading file output_gpt_text_0/merges.txt\n",
      "05/22/2020 03:53:52 - INFO - transformers.tokenization_utils -   loading file None\n",
      "05/22/2020 03:53:52 - INFO - transformers.tokenization_utils -   loading file output_gpt_text_0/special_tokens_map.json\n",
      "05/22/2020 03:53:52 - INFO - transformers.tokenization_utils -   loading file output_gpt_text_0/tokenizer_config.json\n",
      "05/22/2020 03:53:52 - INFO - transformers.configuration_utils -   loading configuration file output_gpt_text_0/config.json\n",
      "05/22/2020 03:53:52 - INFO - transformers.configuration_utils -   Model config GPT2Config {\n",
      "  \"activation_function\": \"gelu_new\",\n",
      "  \"architectures\": [\n",
      "    \"GPT2LMHeadModel\"\n",
      "  ],\n",
      "  \"attn_pdrop\": 0.1,\n",
      "  \"bos_token_id\": 50256,\n",
      "  \"embd_pdrop\": 0.1,\n",
      "  \"eos_token_id\": 50256,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"gpt2\",\n",
      "  \"n_ctx\": 1024,\n",
      "  \"n_embd\": 768,\n",
      "  \"n_head\": 12,\n",
      "  \"n_layer\": 12,\n",
      "  \"n_positions\": 1024,\n",
      "  \"resid_pdrop\": 0.1,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"cls_index\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"task_specific_params\": {\n",
      "    \"text-generation\": {\n",
      "      \"do_sample\": true,\n",
      "      \"max_length\": 50\n",
      "    }\n",
      "  },\n",
      "  \"vocab_size\": 50257\n",
      "}\n",
      "\n",
      "05/22/2020 03:53:52 - INFO - transformers.modeling_utils -   loading weights file output_gpt_text_0/pytorch_model.bin\n",
      "05/22/2020 03:54:01 - INFO - __main__ -   Namespace(device=device(type='cuda'), k=0, length=20, model_name_or_path='output_gpt_text_0', model_type='gpt2', n_gpu=1, no_cuda=False, num_return_sequences=1, p=0.9, padding_text='', prompt='', repetition_penalty=1.0, seed=42, stop_token=None, temperature=1.0, xlm_language='')\n",
      "Model prompt >>> This game is\n",
      "05/22/2020 03:54:04 - WARNING - transformers.modeling_utils -   Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n",
      "=== GENERATED SEQUENCE 1 ===\n",
      "This game is fun enough for both new and old players alike, but it's not as intense as the original.\n"
     ]
    }
   ],
   "source": [
    "!python run_generation.py --model_type=gpt2 --model_name_or_path=output_gpt_text_0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VQtxoKCoduGm"
   },
   "source": [
    "From the aforementioned comparsion, we compared the text generation based on five-star comments and non-five star comments. We would find that the text generation is quite similar among these two inputs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CgzlV-7aZdf7"
   },
   "source": [
    "## <span style=\"color:red\">*Exercise 4*</span>\n",
    "\n",
    "<span style=\"color:red\">Construct cells immediately below this that tune BERT to at least two different textual samples. These could be from different corpora, distinct time periods, separate authors, alternative publishing outlets, etc. Then compare the meaning of words, phrases and sentences to each other across the separate models. What do they reveal about the social worlds inscribed by the distinctive samples?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KF9RRQ5PZPp9"
   },
   "outputs": [],
   "source": [
    "from transformers import RobertaConfig, RobertaModel, RobertaTokenizer\n",
    "com_model_embedding = RobertaModel.from_pretrained('output_gpt_text')\n",
    "com_tokenizer = RobertaTokenizer.from_pretrained('output_gpt_text')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RUu8jPuSanBI"
   },
   "outputs": [],
   "source": [
    "def word_vector(text, word_id, model, tokenizer):\n",
    "    marked_text = \"[CLS] \" + text + \" [SEP]\"\n",
    "    tokenized_text = tokenizer.tokenize(marked_text)\n",
    "    indexed_tokens = tokenizer.convert_tokens_to_ids(tokenized_text)\n",
    "    tokens_tensor = torch.tensor([indexed_tokens])\n",
    "    word_embeddings, sentence_embeddings = model(tokens_tensor)   \n",
    "    vector = word_embeddings[0][word_id].detach().numpy()\n",
    "    return vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-r41Z_jzZvqj"
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "from scipy.spatial.distance import cosine\n",
    "def visualise_diffs(text, model, tokenizer):\n",
    "    word_vecs = []\n",
    "    for i in range(0, len(text.split())):\n",
    "        word_vecs.append(word_vector(text, i, model, tokenizer))\n",
    "    L = []\n",
    "    for p in word_vecs:\n",
    "        l = []\n",
    "        for q in word_vecs:\n",
    "            l.append(1 - cosine(p, q))\n",
    "        L.append(l)\n",
    "    M = np.array(L)\n",
    "    fig = plt.figure()\n",
    "    div = pd.DataFrame(M, columns = list(text.split()), index = list(text.split()))\n",
    "    ax = sns.heatmap(div)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "4hwjifRKaX97",
    "outputId": "076cc081-135e-4121-a092-66ac3fb1e3e9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'This game is a bit hard to get the hang of'"
      ]
     },
     "execution_count": 45,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text1 = train_text[0].split(\",\")[0]\n",
    "text1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 288
    },
    "colab_type": "code",
    "id": "vWoEV0gjZ955",
    "outputId": "4f4f1bbb-b8fa-401d-f3bb-2e93a3778bb2"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "visualise_diffs(text1, com_model_embedding, com_tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 288
    },
    "colab_type": "code",
    "id": "W-a4smciacf8",
    "outputId": "d0102561-fa91-4bee-bf8a-f26a6c19c165"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "com_model_embedding_1 = RobertaModel.from_pretrained('output_gpt_text_1')\n",
    "com_tokenizer_1 = RobertaTokenizer.from_pretrained('output_gpt_text_1')\n",
    "visualise_diffs(text1, com_model_embedding_1, com_tokenizer_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "z5Yhab3LgUot"
   },
   "source": [
    "In this section, we used three models in Section 3: all Amazon reviews, five-star reviews only and non-five-star reviews only. Then, we drew the heatmap respectively. Compared among these three heatmaps, we didn't see so much difference above the forementioned 2 heatmaps, which can be explained that there are a lot of overlapping in these two maps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1HFSUFsRgr6n"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "HM8_YIMIN LI.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "003c583e777045fe8d33b53388e385b2": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "01249c2b1f104082b8070479e4043808": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_bac88cf800394fe98399de3fbb86ea89",
       "IPY_MODEL_b0f683c507c5439bbd8f6e211b752709"
      ],
      "layout": "IPY_MODEL_5d27a0cf2a14477dad73e8b16c5eacbc"
     }
    },
    "02cf8709b60d4e78a5aaf02632c8bddf": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "042f2b5a25e943c9908f106b7b2f355a": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "0a483e7e6f9d49a78912b8b7b328f7c5": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "106ab26ceaab47d187a048fff0f942a6": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_c06dec3f52f64b29919ec556f31cb820",
       "IPY_MODEL_ffc7f9dfdb6d4bb5a3cc2ce368d9fcfe"
      ],
      "layout": "IPY_MODEL_b764d725d93f412eb42a1899b7913487"
     }
    },
    "10b558ce9fb546d8b815d746976cb518": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "11f73023400f463dad2016e31445c5df": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "22b7213535774d479039ee46ea322f08": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2a21231f5026438d949f5d3f00bae86d": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "2c06611729e94f4f9fbeb66b0cd8fcbd": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "2fcbd06b3cc9490b9ffee23acc3b5aa6": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3235bcdf3c004022ac25e5f396c7fbdf": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "33e36b40eae74a3e9a045543a2c9a85b": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_a32069ec91074400b67ff7ccdb4e2215",
       "IPY_MODEL_ee56701c9b124abcbc1d3d60392276b0"
      ],
      "layout": "IPY_MODEL_34cac1b3c51f46eb8a8ed854db59ecaf"
     }
    },
    "33ec2c6e4859464795d9dad4525bfa0c": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6688ea7fa17546329b080db4a5a5b05a",
      "max": 440473133,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_3a75b77536714613afc59b048b5ac2ac",
      "value": 440473133
     }
    },
    "34cac1b3c51f46eb8a8ed854db59ecaf": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3969ea90aed840d38c07c9c33b034908": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3a75b77536714613afc59b048b5ac2ac": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "3b3a32d10f234ddf98ecfc3ada4a8a48": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3b69eeb18bc04a1b8950f4c143553c2d": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3d2b64d475aa489eb57cb7ac602c7357": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3e9653db57f144449df5f991a8d19e13": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "44d4881aca074b5c92322887f716b6dc": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3235bcdf3c004022ac25e5f396c7fbdf",
      "max": 665,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_808972de3dea43d0a42f3e84df3504f2",
      "value": 665
     }
    },
    "45a711b337074edfa2d659bf79223403": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3b3a32d10f234ddf98ecfc3ada4a8a48",
      "max": 231508,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_042f2b5a25e943c9908f106b7b2f355a",
      "value": 231508
     }
    },
    "4bac22afbde74b0396ac78cf1f1f977b": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_02cf8709b60d4e78a5aaf02632c8bddf",
      "max": 230,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_840f0266b9894fac92754e194c9cd9c8",
      "value": 230
     }
    },
    "5d27a0cf2a14477dad73e8b16c5eacbc": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "63ee95f98ea74604847d70e16caeaa1b": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_b4edeb281cc34d1ebdbf17915abd9a04",
       "IPY_MODEL_c8e2d662c05042349743a4da60f43244"
      ],
      "layout": "IPY_MODEL_3969ea90aed840d38c07c9c33b034908"
     }
    },
    "6688ea7fa17546329b080db4a5a5b05a": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6cefd8a091254039a0f85bf7b16d5acc": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "70bf5c6d20a7403c8e6d6bcf396cfa08": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_44d4881aca074b5c92322887f716b6dc",
       "IPY_MODEL_9f961d16dd3d428d8ab7213a44ca9a19"
      ],
      "layout": "IPY_MODEL_0a483e7e6f9d49a78912b8b7b328f7c5"
     }
    },
    "73ddf68494f441ffaca15939d18c0b27": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_eaa71d7c8a8b4cceb6388ecd675eac92",
      "placeholder": "​",
      "style": "IPY_MODEL_79749471cb584160908296eedbd0d8e9",
      "value": " 230/230 [00:00&lt;00:00, 429B/s]"
     }
    },
    "79749471cb584160908296eedbd0d8e9": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "79d2848613fc45b3bb2bc5578266a371": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7ab8aaa2ad464f7eb8219e7368cd534e": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "808972de3dea43d0a42f3e84df3504f2": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "81af3fbef12b401da6c9f0e4111a0479": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "840f0266b9894fac92754e194c9cd9c8": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "868b0da4ab814f7790691602dead75b2": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "8855e8337a244f2d9a01b1c13fb6eb81": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9f961d16dd3d428d8ab7213a44ca9a19": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7ab8aaa2ad464f7eb8219e7368cd534e",
      "placeholder": "​",
      "style": "IPY_MODEL_6cefd8a091254039a0f85bf7b16d5acc",
      "value": " 665/665 [00:01&lt;00:00, 361B/s]"
     }
    },
    "a32069ec91074400b67ff7ccdb4e2215": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f2056f8965f34d10b17609bc40382ac8",
      "max": 456318,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_868b0da4ab814f7790691602dead75b2",
      "value": 456318
     }
    },
    "a3c24acd4ce2402eab3a2d97c1c4f5ad": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "a4accf8171d44d4880e4bd43819aa5d5": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_45a711b337074edfa2d659bf79223403",
       "IPY_MODEL_be79b6d5ba8a48a6bc1026dbc330a4c7"
      ],
      "layout": "IPY_MODEL_e9e6f1a0b59f4fd280aa009f71be3c13"
     }
    },
    "b0f683c507c5439bbd8f6e211b752709": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2fcbd06b3cc9490b9ffee23acc3b5aa6",
      "placeholder": "​",
      "style": "IPY_MODEL_fb48b20987db4618ac9b2e1437834e30",
      "value": " 433/433 [00:00&lt;00:00, 1.39kB/s]"
     }
    },
    "b4edeb281cc34d1ebdbf17915abd9a04": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d9c53452b7394f86ae5b0a3e43ccd7a5",
      "max": 1042301,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_e81d79ad57464ffa8d18e9f7aa683378",
      "value": 1042301
     }
    },
    "b764d725d93f412eb42a1899b7913487": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "bac88cf800394fe98399de3fbb86ea89": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_79d2848613fc45b3bb2bc5578266a371",
      "max": 433,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_a3c24acd4ce2402eab3a2d97c1c4f5ad",
      "value": 433
     }
    },
    "be79b6d5ba8a48a6bc1026dbc330a4c7": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_edcbe40bc41c41d4bcfc747baf0a4425",
      "placeholder": "​",
      "style": "IPY_MODEL_81af3fbef12b401da6c9f0e4111a0479",
      "value": " 232k/232k [00:00&lt;00:00, 255kB/s]"
     }
    },
    "c06dec3f52f64b29919ec556f31cb820": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3e9653db57f144449df5f991a8d19e13",
      "max": 548118077,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_2a21231f5026438d949f5d3f00bae86d",
      "value": 548118077
     }
    },
    "c8e2d662c05042349743a4da60f43244": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e65eb70f47fc4ec5b1c7fde7b3322c6a",
      "placeholder": "​",
      "style": "IPY_MODEL_003c583e777045fe8d33b53388e385b2",
      "value": " 1.04M/1.04M [00:04&lt;00:00, 245kB/s]"
     }
    },
    "d00b9b0a94274ad1a51ef8000939d56f": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_33ec2c6e4859464795d9dad4525bfa0c",
       "IPY_MODEL_da721c98cbee469b8319e3a8bd206e9e"
      ],
      "layout": "IPY_MODEL_3b69eeb18bc04a1b8950f4c143553c2d"
     }
    },
    "d95cfe0845c9467eb472a72fbdd1d007": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_4bac22afbde74b0396ac78cf1f1f977b",
       "IPY_MODEL_73ddf68494f441ffaca15939d18c0b27"
      ],
      "layout": "IPY_MODEL_8855e8337a244f2d9a01b1c13fb6eb81"
     }
    },
    "d9c53452b7394f86ae5b0a3e43ccd7a5": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "da721c98cbee469b8319e3a8bd206e9e": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_10b558ce9fb546d8b815d746976cb518",
      "placeholder": "​",
      "style": "IPY_MODEL_11f73023400f463dad2016e31445c5df",
      "value": " 440M/440M [00:06&lt;00:00, 69.8MB/s]"
     }
    },
    "e65eb70f47fc4ec5b1c7fde7b3322c6a": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e81d79ad57464ffa8d18e9f7aa683378": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "e9e6f1a0b59f4fd280aa009f71be3c13": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "eaa71d7c8a8b4cceb6388ecd675eac92": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ecb79234c3804aaea46daeae18df86a4": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "edcbe40bc41c41d4bcfc747baf0a4425": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ee56701c9b124abcbc1d3d60392276b0": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_22b7213535774d479039ee46ea322f08",
      "placeholder": "​",
      "style": "IPY_MODEL_2c06611729e94f4f9fbeb66b0cd8fcbd",
      "value": " 456k/456k [00:01&lt;00:00, 402kB/s]"
     }
    },
    "f2056f8965f34d10b17609bc40382ac8": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "fb48b20987db4618ac9b2e1437834e30": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "ffc7f9dfdb6d4bb5a3cc2ce368d9fcfe": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3d2b64d475aa489eb57cb7ac602c7357",
      "placeholder": "​",
      "style": "IPY_MODEL_ecb79234c3804aaea46daeae18df86a4",
      "value": " 548M/548M [00:07&lt;00:00, 69.4MB/s]"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
